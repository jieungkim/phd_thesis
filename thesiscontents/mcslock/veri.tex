\section{Verification---Layer by layer}
\label{chapter:mcslock:sec:verification}%

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{figs/mcslock/layer_overview}
\end{center}
\caption{$\mcsname$ Lock Layers.}
\label{fig:chapter:mcslock:layeroverview}
\end{figure}


We build five layers, starting from a base layer which represents the machine model that our compiled code will
run on.
Figure~\ref{fig:chapter:mcslock:layeroverview} shows the overall structure of our development.
For simplicity the figure only includes lock primitives, and
primitives passed through from below are hidden in it.
We also omit the current focused set ($cid$ -- CPU ID) and the environmental context ($\oracle$) in the figure
 as well as the rest (except in lemmas and theorems) of this section for simplification.
The CPU ID will not be changed at all during the whole layers (note that all  layer interfaces in this $\mcsname$ Lock module 
are local layer interfaces), but there is a place that we need a simplification of the global log to guarantee the atomicity of 
acquire/release locks as mentioned in Section~\ref{chapter:ccal:subsec:local-layer-interface}.
We will clearly state that which layer is related to a \textit{log-lift} pattern; 
thus require the change in an environmental context.
Each big and outer rectangle in the figure means each layer in the $\mcsname$ Lock module, 
and small and inner rectangles in each layer implies primitives defined in the layer.
Arrows show dependencies between adjacent layers,
for example the implementation of $\waitlockfunc$ in  $\mmcslockopfull$
uses three primitives ($\mcsswaptailabs$,
$\mcssetnextabs$, and $\mcsgetbusyabs$) from  $\mmcslockabsintrofull$.

Most layers in the figure are related to the \textit{fun-lift} pattern in Section~\ref{chapter:ccal:subsec:local-layer-interface}.
The layers from  $\mmcsbootfull$  through the $\mmcslockabsintro$
introduces getter and setter functions for accessing the memory in the machine
(Section~\ref{chapter:mcslock:subsec:lowestmachinemodel} and
\ref{chapter:mcslock:subsec:abstractoperationlayer}). These layers also
contain logical primitives which record events to the log; we are in
effect manually implementing a model of concurrent execution by
extending a sequential operational semantics for C. 
The layer $\mmcslockopfull$ contains the C code from 
Figure~\ref{fig:chapter:mcslock:mcs_lock}. This layer proves low-level
functional correctness, \ie, it reasons about the C code and
abstracts away details about memory accesses, integer overflows, etc,
to expose an equivalent specification written as a $\coq$
function (Section~\ref{chapter:mcslock:subsec:atomicoperation}).
The two top layers, $\mqmcslockopfull$ and $\mhmcslockopfull$ , do not introduce any new primitives.
They simplify the specifications of 
the release- and acquire lock functions ($\passlockfunc$ and
$\waitlockfunc$), \ie, each layer ascribes a different
specification (with a different log replay function and a set of events)
to the same C function. Those specification names are notated inside the square bracket in Figure~\ref{fig:chapter:mcslock:layeroverview}.

On the other hand, two layers are closely related to the  \textit{log-lift} pattern in Section~\ref{chapter:ccal:subsec:local-layer-interface}.
The layer $\mqmcslockopfull$ adds ghost states, keeping track of a
queue of waiting CPUs.
(Section~\ref{chapter:mcslock:sec:representation-ghost}). This queue is key to the liveness proof but is not explicitly represented in the C implementation.
The top layer $\mhmcslockopfull$ proves starvation freedom and liveness
(Section~\ref{chapter:mcslock:sec:liveness-atomicity}). This lets us ascribe atomic
specifications where taking or releasing a lock generates just a
single event to the log.

\subsection{Memory operations layers}
\label{chapter:mcslock:subsec:lowestmachinemodel}


Although we glossed over this in Figure~\ref{fig:chapter:mcslock:mcs_lock}, our
actual C implementations of $\mcsacquire$ and
$\mcsrelease$ do not access the system's memory directly.  Instead, they call
a collection of helper functions with names like
$\mcssetnext$. The lowest two layers in our proofs
are devoted to implementing these helper functions.
The key concern is to make sure that the events that get appended to the log correspond to the actual actions to the memory. Some of that can be proven, 
but some parts of this layer are trusted as part of the machine model.

We first describe the first and the lowest tuple in our proofs,

\begin{center}
\begin{tabular}{P{0.95\textwidth}}
$\ltyp{\mmcsboot}{R_{(\mmcslockintro, \mmcsboot)}}{\codeinmath{M}_{\mmcslockintro}}{\mmcslockintro}$\\
(precisely, ``$\ltyp{\PLayer{\mmcsboot}{cid}{\oracle^{mcs}_{cid}}}{R_{(\mmcslockintro, \mmcsboot)}}{\codeinmath{M}_{\mmcslockintro}}{\PLayer{\mmcslockintro}{cid}{\oracle^{mcs}_{cid}}}$'' \\
when $cid$ is the focused current CPU ID and\\
 $\oracle^{mcs}_{cid}$ is an instance of environmental contexts for our program.)\\
\end{tabular}
\end{center}

The interface ($\mmcsbootfull$) represents the machine model that our compiled code will run on.
All primitives defined in $\mmcslockintrofull$ are parts of the trusted computing base and correspond to empty functions in our compiled code.

Eight of  primitives in $\mmcsbootfull$  are firmly related to the  $\mcsname$ Lock verification:

\begin{center}
\begin{tabular}{P{0.95\textwidth}}
$\{\atomicmcslog,\  \atomicmcsswap,\ \atomicmcscas,\ \mcsinitnodelog,$\\
$\mcsgetnextlog,\ \mcssetnextlog,\ \mcsgetbusylog,\ \mcssetbusylog\} $\\
\end{tabular}
\end{center}

Two primitives, $\atomicmcsswap$ and $\atomicmcscas$ are for  two atomic instructions {\em fetch-and-store} and {\em compare-and-swap}, and will be further discussed below.

\begin{figure}
\begin{center}
\lstinputlisting[language = Caml]{source_code/mcslock/mcs_set_next_log.v} 
\end{center}
\caption{$\mcssetnextlog$ Specification.}
\label{fig:chapter:mcslock:specification-of-mcssetnextlog}
\end{figure}

The other six are used to update the log.  
Ordinary assembly instructions only modify a physical memory, not
an abstract state, so in order for programs to be able to append events to
the log, we include these six primitives in $\mmcsbootfull$. 
For example, the specification of $\mcssetnextlog$ (in Figure~\ref{fig:chapter:mcslock:specification-of-mcssetnextlog}\newfootnote{Our implementation divides the global log discussed in Chapter~\ref{chapter:ccal} into a collection of logs, which is a partial form the lock identifier to the log designated with the lock ID by using projection functions for each lock ID. Besides, our logs are defined as a part ($\lockmultilogpool$ in the Figure) of our abstract data in our implementation, which is a little bit different from the local layer state definition in Section~\ref{chapter:ccal:subsec:local-layer-interface}, but which is exactly same in its meaning. We show how they are connected together in the next chapter  (Chapter~\ref{chapter:linking}.)})
updates the log by adding one ($\setnext{prev\_id}$) event.
In the compiled code, these primitives appear as empty functions that do nothing, they are only used to modify the logical state.

The code $\codeinmath{M}_{\mmcslockintro}$ in the layer contains  
functions which actually modifies the memory in the way the event announces.
Each function in $\codeinmath{M}_{\mmcslockintro}$ calls the corresponding primitive from
$\mmcsbootfull$ inside the function to add the event to the log.
For example, $\mcssetnext$, one function in $\codeinmath{M}_{\mmcslockintro}$, writes
to $\codeinmath{next}$ and also calls
the empty function $\mcssetnextlog$:
\lstinputlisting [language = Caml]{source_code/mcslock/mcs_set_next.c}


\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{figs/mcslock/getsetrefinement}
\end{center}
\caption{Structure of $\mcsname$ Lock Memory Operations Layer.}
\label{fig:chapter:mcslock:layer-struct-mcs-verification}
\end{figure}

The interface $\mmcslockintrofull$ contains the high level specification for each function defined in $\codeinmath{M}_ {\mmcslockintro}$. 
Those high-level specifications work on the log instead of the exact memory slot $\lockmemloc$.
Therefore, after proving the {\em refinement} between the memory ($\lockmemloc$ in Figure~\ref{fig:chapter:mcslock:layer-struct-mcs-verification})
and the abstract state ($\lockabsloc$ that is calculated by the \emph{log}\newfootnote{$\lockmultilogpool$: a partial map form a lock identifier to the log with the type $\lockmultilog$ associated with the identifier.}
in Figure~\ref{fig:chapter:mcslock:layer-struct-mcs-verification}), we only need to care about the abstract state.

For the refinement proof, we need two more ingredients.
The first one is a \emph{log replay function}.
A log is merely a list of events, but specifications need to know about the log is what the state of the system will look like after those events have executed,
and a replay function calculates that. 
Different layers may define different replay functions in order to interpret the same log in a way that suits their proofs.
Therefore, we have introduced the proper log replay function in several layers, and prove the relationship between the result of them when we introduced the new one.
In $\mmcslockintrofull$, we define $\calmcslock$, which has the following type:\newline
\begin{tabular}{P{0.95\textwidth}}
$ \calmcslock :\ \lockmultilog\ \rightarrow\ \optiondef\ \lockabsloc$
\end{tabular}\newline
where
\lstinputlisting [language = Caml] {source_code/mcslock/lowmcsstruct.v}
The return type of this log replay function closely corresponds to C data structures, which makes it easy to prove the refinement ($\zmapfunc$ is a finite map from $\ztype$ to $\booltype$*$\ztype$.)
The second ingredient is a relation $R_{\mmcslockintro}$ which shows the relationship between the concrete memory in an underlay $\mmcsbootfull$ and the abstract state in an overlay $\mmcslockintrofull$.
As a part of $R$, we define $\matchmcslock$, which is a part related to 
 $\mcsname$ Lock in $R_{(\mmcslockintro, \mmcsboot)}$,  as follows:

\begin{definition}[$\matchmcslock$]
Suppose that `$loc$' is among the proper field accessors for  $\mcsname$ Lock, which are `$\codeinmath{last}$', `$\codeinmath{ndpool[}i\codeinmath{].next}$', or  `$\codeinmath{ndpool[}i\codeinmath{].busy}$' when `$0 \leq i < \invalidmcsval$'.
 And, assuming that `$\codeinmath{lk\_id}$' is a lock identifier satisfies `$0 \leq \codeinmath{lk\_id} < \codeinmath{lock\_range}$' and $\codeinmath{l}$ is a shared log. Then define \newline
  \begin{tabular}{P{0.90\textwidth}}
    $\matchmcslock\ \codeinmath{(l:Log) (}\lockmemloc\codeinmath{ :block) loc}$\\
      iff ($\exists \codeinmath{val},\ \memloadsome{\memintregulartype}{m}{\lockmemloc}{loc}{\codeinmath{val}}$\\
        $\wedge\  \memaccess{m}{\lockmemloc}{loc}$\\
      $\wedge\ \calmcslock \codeinmath{(l) =}\Some\codeinmath{(mcsval)}\rightarrow\codeinmath{loc}_{a}\codeinmath{@mcsval = val)}$\\
\end{tabular}\newline
    when `$\codeinmath{loc}_{a}\codeinmath{@mcsval}$' represents the corresponding 
    value to the `$\codeinmath{loc}_{a}$' in the `$\codeinmath{mcsval}$' 
    and `$\codeinmath{loc}_{a}$' corresponds to the value of `$\codeinmath{loc}$'.
\end{definition}

Intuitively, the definition says that the value that
$\calmcslock$ calculates from the log always corresponds to the value 
in the memory with the same identifiers. The memory access functions $\memloadkwd$ and $\memaccesskwd$ are
from $\compcert$'s operational semantics for C.
Using the definition, we prove one theorem for each primitive, which
shows that the memory refines the shared log. \eg, for $\mcssetnext$ we prove:

\begin{theorem}[Simulation for $\mcssetnext$]
    \label{thm:chapter:mcslock:machine-state-refinement} Let $R_{(\mmcslockintro, \mmcsboot)}$ be the relation defined as $\matchmcslock$
    over $\codeinmath{LK@}mem$ and $\lockabsloc\codeinmath{@}A_{\mmcslockintro}$, 
identity relation for other parts of $mem$, $A_{\mmcsboot}$ and $A_{\mmcslockintro}$. Then\newline
 \begin{tabular}{P{0.95\textwidth}}
$ \forall (\codeinmath{{m}}_{1} \ \codeinmath{{m}}_{1}'\ \codeinmath{{m}}_{0} : mem)\  (\codeinmath{{d}}_{0} \ : A_{\mmcsboot})\ (\codeinmath{{d}}_{1} \ \codeinmath{{d}}_{1}' : A_{\mmcslockintro}). $ \\
$ \mcssetnext_{L_1}(v, \codeinmath{{m}}_1, \codeinmath{{d}}_1) = \Some (\codeinmath{{m}}'_1, \codeinmath{{d}}'_1) \ \rightarrow \
  R_{(\mmcslockintro, \mmcsboot)}\ (\codeinmath{{m}}_1, \codeinmath{{d}}_1)\ (\codeinmath{{m}}_0, \codeinmath{{d}}_0) \ \rightarrow $\\
  $ \exists (\codeinmath{{m}}_{0}' : mem)\ (\codeinmath{{d}}_{0}' : A_0).$ \\
  $  \mcssetnext_{L_0}(v, \codeinmath{{m}}_0, \codeinmath{{d}}_0) = \Some(\codeinmath{{m}}'_0, \codeinmath{{d}}'_0) \ \wedge \
  R_{(\mmcslockintro, \mmcsboot)}\ (\codeinmath{{m}}'_1, \codeinmath{{d}}'_1)\ (\codeinmath{{m}}'_0, \codeinmath{{d}}'_0).$ 
   \end{tabular}
\end{theorem}
Similar to  Theorem~\ref{thm:chapter:mcslock:machine-state-refinement},
proving the refinement property for other primitives between two layers 
are possible, and the generalized theorem for the refinement is as follows:

 \begin{theorem}[Machine State Refinement]
 \label{thm:chapter:mcslock:machine-state-refinement-full} 
Assuming that 
 1) ${\mmcsboot}[cid, \oracle^{mcs}_{cid}]$ and ${\mmcslockintro}[cid, \oracle^{mcs}_{cid}]$ are underlay and overlay layers;
2) and, $A_{\mmcsboot}$ and $A_{\mmcslockintro}$ are abstract datum for $L_{\mmcsboot}$ and $L_{\mmcslockintro}$, respectively.
    With the given $R_{(\mmcslockintro, \mmcsboot)}$, defined as $\matchmcslock$
     over the $\lockmemloc$ block in the memory  (\ie,$\lockmemloc\codeinmath{@}mem$) and 
 $\mcsname$ Lock related data structure in the abstract data of the overlay layer (\ie, $\lockabsloc\codeinmath{@}A_{\mmcslockintro}$), 
 identity relation for other parts of $A_{\mmcsboot}$ and $A_{\mmcslockintro}$, 
 The specification for the function $f$, $\sigma_f$, in $L_{\mmcslockintro}$ refines that in $L_{\mmcsboot}$ when:
 \begin{center}
 \begin{tabular}{P{0.95\textwidth}}
$ \forall (\codeinmath{{m}}_{1} \ \codeinmath{{m}}_{1}'\ \codeinmath{{m}}_{0} : mem)\  (\codeinmath{{d}}_{0} \ : A_{\mmcsboot})\ (\codeinmath{{d}}_{1} \ \codeinmath{{d}}_{1}' : A_{\mmcslockintro}). $ \\
 $ (\mmcslockintro[cid, \oracle^{mcs}_{cid}] \vdash \sigma_f : (\_, \codeinmath{m}_1, \codeinmath{d}_1) \rightarrow (\_, \codeinmath{m}_1', \codeinmath{d}_1'))  \ \rightarrow \
  R_{(\mmcslockintro, \mmcsboot)}\ (\codeinmath{{m}}_1, \codeinmath{{d}}_1)\ (\codeinmath{{m}}_0, \codeinmath{{d}}_0) \ \rightarrow $\\
  $ \exists (\codeinmath{{m}}_{0}' : mem)\ (\codeinmath{{d}}_{0}' : A_0).$ \\
$({\mmcsboot}[cid, \oracle^{mcs}_{cid}]  \vdash \sigma_f : (\_, \codeinmath{m}_0, \codeinmath{d}_0) \rightarrow (\_, \codeinmath{m}_0', \codeinmath{d}_0')) \ \wedge \
  R_{(\mmcslockintro, \mmcsboot)}\ (\codeinmath{{m}}'_1, \codeinmath{{d}}'_1)\ (\codeinmath{{m}}'_0, \codeinmath{{d}}'_0).$  \\
 \end{tabular}
 \end{center}
 \end{theorem}



One interesting variation is the semantics
for fetch-and-store and compare-and-swap. These instructions are not
formalized in the x86 assembly semantics we use, so we cannot prove
that replay function is correctly defined. Instead, we modify the last
(``pretty-printing'') phase of the compiler so that these primitive calls map to assembly
instructions, and one has to trust that they match the specification.


\subsection{Event interleaving layer}
\label{chapter:mcslock:subsec:abstractoperationlayer}

After abstracting memory accesses into the operation on the log, we
then need to model possible interleaving among multiple CPUs. In
our approach, this is done through a new layer which adds \emph{context queries}.

To recall what the environmental (concurrent context) is,
the concurrent context $\oracle^{mcs}_{cid}$ (sometimes called the ``oracle'') is
a function that gets  a CPU ID and a log and returns a log.
It has the type\newline
\begin{tabular}{P{0.95\textwidth}}
    $\oracle^{mcs}_{cid}:\  \codeinmath{Z}\ \rightarrow \ \codeinmath{Z}\ \rightarrow\ \codeinmath{list event}\ \rightarrow\ \codeinmath{list event}.$\\
\end{tabular}\newline
when the first argument is a lock ID, the second argument is a CPU ID, and the third is a current log\newfootnote{Similar to a global log, we divide a single concurrent context into multiple ones for optimization; thus the first parameter (lock ID) is necessary for querying the proper concurrent context. We show how this set of concurrent contexts is connected with a single concurrent context which is discussed in Chapter~\ref{chapter:ccal} in the next Chapter (in Chapter~\ref{chapter:linking}.)} 
It is one component of the abstract state in our implementation, and it represents the specific behavior of \emph{all
the other CPUs}, from the perspective of code running on the current
CPU.  Any time a program does an operation which reads or writes
shared memory, it should first query $\oracle^{mcs}_{cid}$ by giving it the
current log. The oracle will reply with a list of events that other
CPUs have generated since then, and we update the log by appending
those new events to it.

Primitive specifications are provided read-only access to a context
$\oracle^{mcs}_{cid}$ by the verification framework, and the framework also
guarantees that two properties are true of $\oracle^{mcs}_{cid}$: 1) the returned
partial log from the oracle query does not contain any events
generated by the given CPU ID; and 2) if we query the oracle with the
well-formed shared log, the updated log after the oracle query will
be well-formed.
The first assumption is straightforward because the purpose of the oracle is to represent the behavior of others' operation on the shared object.
The second one is also trivial when we prove 1) the initial shared log satisfy the well-formed condition, and 2) all the operations on the shared object with the given well-formed log return a well-formed shared log.
Those two assumptions, however, do not reduce the generality of the oracle, and the oracle can capture the proper interleaving that we hope to achieve in the $\mcsname$ Lock verification.

Similar to Section~\ref{chapter:mcslock:subsec:lowestmachinemodel}, 
we provide primitives in $\mmcsbootfull$ which query $\oracle^{mcs}_{cid}$ and extend the log.
Then in this second layer, we can model abstract operations with interleaving.
For example, $\mcssetnext$ can be re-written as
\lstinputlisting [language = Caml] {source_code/mcslock/mcs_set_next_low_charac.c}
by using the logical primitive which corresponds to the oracle query
(The function $\mcslog$ refines the semantics of $\atomicmcslog$ in the lowest layer by the $\matchmcslock$ relation).
To model the interleaving, all  setter and getter functions defined
in Section~\ref{chapter:mcslock:subsec:lowestmachinemodel} should be combined with the
oracle query.

\subsubsection{Trust in the machine model}
Some of design decisions in  memory access
layers have to be trusted, so the division between the machine model and
the implementation is unfortunately slightly blurred.
Ideally, we would have a generic machine model as proposed in Section~\ref{chapter:ccal:sec:interface-calculus}, where memory is partitioned into a thread-local
memory (no events), a lock-protected memory (accesses generate $\push$/$\pull$
events), and atomic memories (each access
generates one $\codeinmath{READ}$/$\codeinmath{WRITE}$/$\codeinmath{SWAP}$/etc event).  However, our starting point
is  $\compcert$ $\intelmachine$ semantics, which was designed for single-threaded
programs, and does not come with a log, so we add a log and memory access
primitives ourselves.
But because the spinlock module is the only code in the OS that uses
atomic memory, we do not add a generic operation called
read\_word etc. Instead, we take a short-cut and specify the particular
6 memory accesses that the lock code uses: $\mcssetnext$ etc.
For these procedures to correctly express the intended semantics,
there are two trusted parts we must take care to get right. First,
each access to non-thread-local memory must generate an event, so we
must not forget the call to
$\mcssetnextlog$.
Second, to account for
interleavings between CPUs (and not accidentally assume that consecutive
operations execute atomically) we must not forget the call to
$\mcslog$ after each access.



\subsection{Low-level functional specification}
\label{chapter:mcslock:subsec:atomicoperation}

Using the primitives that we have defined in lower layers, we prove the correctness of lock acquire, $\mcsacquire$, and release, $\mcsrelease$.
The target code in this layer is identical to the code in Figure~\ref{fig:chapter:mcslock:mcs_lock} except two aspects. 
First, we replaced all operations on memory with the getters and setters described in Section~\ref{chapter:mcslock:subsec:abstractoperationlayer}.
Second, $\mcsacquire$ has one more
 argument, which is a bound number for the client code of the lock.

Since functions defined in
Section~\ref{chapter:mcslock:subsec:abstractoperationlayer} already abstract interleaving
of multiple CPUs, the proofs in this layers work just like sequential
code verification. We find out the machine state after the function
call by applying the C operational semantics to our function
implementation, and check that it is equal to the desired state
defined in our specification.

However, writing specifications for these functions is slightly subtle, 
because they contain
while-loops without any obviously decreasing numbers. Since our
specifications are $\coq$ functions we need to model this by structural
recursion, in some way that later will let us show the loop is terminating.
So to define the semantics of $\mcswaitlockfunc$,
we define an auxiliary function
$\calmcsacqwait$ which describes the
behavior of the first $n$ iterations of the loop: each iteration
queries the the environment context $\oracle^{mcs(lkid)}_{\mathrm{i}}$ (\ie,  $lkid$ is a lock identifier and $\mathrm{i}$ is a CPU ID), replays a log to see if if $\codeinmath{busy}$ is now $\bfalse$ and appends a $\GETBUSY$ event.
If we do not succeed within $n$ iterations the function is undefined ($\coq$ $\None$).
Then, in  part of the  specification for the  acquire lock 
function ($\calmcsacqwait$ in Figure~\ref{fig:chapter:mcslock:calmcsacqwait}) where we need to talk about the while loop,
we say that it loops for some ``sufficiently large'' 
number of iterations $\CalWaitLockTime$  $\codeinmath{tq}$. 
\begin{figure}
\lstinputlisting[language = Caml]{source_code/mcslock/waitlockloop.v}
\caption{$\calmcsacqwait$ Definition.}
\label{fig:chapter:mcslock:calmcsacqwait}
\end{figure}
The function $\CalWaitLockTime$ computes a suitable 
number of loop iterations based on $\codeinmath{tq}$, time-bounds  which each of the queuing CPUs promised to respect.
We will show how it is defined in Section~\ref{chapter:mcslock:sec:liveness-atomicity}. 
However, in \emph{this part} of the proof, the definition doesn't matter. 
Computations where $n$ reaches 0 are considered crashing, and our
ultimate theorem is about safe programs, so when proving that the C
code matches the specification we only need to 
consider cases when $\calmcsacqwait$ returned $\codeinmath{(}\Some\codeinmath{ l)}$.
It is easy to show in a downward simulation that the C loop can match any such finite run, 
since the C loop can run any number of times.

\subsection{Data representation and ghost state}
\label{chapter:mcslock:sec:representation-ghost}

From here on, we never have to think about C programs again.  All the
subsequent reasoning is done on $\coq$ functions manipulating ordinary
$\coq$ data types, such as lists, finite maps, and unbounded integers.
Verifying functional programs written in $\coq$'s Gallina is exactly the
situation $\coq$ was designed to deal with. However, the data computed
by the replay function in in the previous layer still corresponds
exactly to the array-of-structs that represents the state of the lock
in memory.
In particular, the intuitive reason that the algorithm is fair is that
each CPU has to wait in a queue, but this conceptual queue is not identical with
the linked-list in memory, because the next-pointers may not be set.

In order to keep the data-representation and liveness concerns separate,
we introduce an intermediate layer, which keeps the same sequence of operations and same log of events, 
but manipulates an \emph{abstracted data representation}.
We provide a different replay function ($\QSCalLock$) with the type \newline
\begin{tabular}{P{0.95\textwidth}}
$\QSCalLock :\ \lockmultilog\ \rightarrow\ \optiondef\ (\nattype * \nattype * \codeinmath{head\_status} * \codeinmath{list} \ \ztype *  \set{\ztype} * \codeinmath{list} \ \nattype)$\\
\end{tabular}\newline
The tuple returned by this $\QSCalLock$ replay function provides the information we
need to prove liveness, 
similar to the concepts used in the informal
proof in Section~\ref{chapter:mcslock:sec:overview}. 
The meaning of a tuple $\codeinmath{(c1,c2,b,q,slow,t)}$ is as follows:
\begin{itemize}
\item  $\codeinmath{c1}$ and $\codeinmath{c2}$ are upper bounds on how many more operations 
the CPU which currently holds the lock will generate as part of the critical section and of 
releasing the lock, respectively. They are purely logical ghost states but can be deduced from the complete
history of events in the system.

\item $\codeinmath{b}$ is either  $\mcslempty$ or  $\mcslhold$, 
the lock status of the head of the queue.
They are closely related to $\push$/$\pull$ operations in our memory model discussed in Section~\ref{chapter:ccal:sec:interface-calculus}.
When the $\codeinmath{b}$ value is $\mcslhold$, this implies that one CPU already pulls the value for that shared memory block.
On the other hand, when $\codeinmath{b}$ value is $\mcslempty$, no CPUs pull the value from the block, so the next CPU in the wait list 
can pull the block to enter the critical section.

\item $\codeinmath{q}$ is a list of  CPUs who are currently waiting for the lock, 
and $\codeinmath{t}$ is a list of bound numbers that 
correspond to the related elements in $\codeinmath{q}$.

\item $\codeinmath{slow}$ is a finite set which represents a subset of CPUs in $\codeinmath{q}$ that have not yet executed their \emph{set next} operation.  
\end{itemize}
Our liveness proof is based on the fact that each CPU only needs to wait for CPUs that are ahead of it in $\codeinmath{q}$, which is the waiting queue that guarantees FIFO ordering.

Some of the information are implicit in the state of the memory, while some of it (for example $\codeinmath{c1}$ and $\codeinmath{c2}$) are purely ghost states. But in any case, it can be deduced from the complete history of events in the system, which is what the replay function $\QSCalLock$ does. We define it by recursion on the list $\codeinmath{l}$, computing the new state after each event. A few representative cases of the function are shown in Figure~\ref{fig:chapter:mcslock:QS_CalLock}.  For example, the event
$\setbusy$ indicates that a thread releases the lock. If the CPU $i$ is already the  front of the queue $\codeinmath{q}$, it currently holds the lock ($\mcslhold$), and the bound $\codeinmath{c2}$ has not yet reached zero, and $i$ is not slow, then generating this event will reset the lock status to $\mcslempty$ and remove the head element ($i$) from $\codeinmath{q}$ and $\codeinmath{t}$. In any of those side conditions are not satisfied, on the other hand, the replay function is undefined ($\None$). Similar
considerations hold executing memory operations (you must be in the critical section, and it decrements $\codeinmath{c1}$) and querying the busy flag (you must have executed $\SETNEXT$ first).

\begin{figure}
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/midlogreplay_short.v}
    \caption{$\QSCalLock$ Definition.}
\label{fig:chapter:mcslock:QS_CalLock}
\end{figure}


\subsubsection{Invariant} 

The replay function plays two different roles. When it returns $\Some\codeinmath{ v}$, for some tuple $\codeinmath{v}$, it describes what the current state of the system is, which lets us write  specifications for those primitives. At the same time, the cases where the function is defined to return $\None$ are also important, because this can be read as a description of events that are \emph{not} possible. For example, from inspecting the program, we know that each CPU will create
exactly one $\SETNEXT$  event before it starts generating $\GETBUSY$ events, and this fact will be needed when doing proofs in the later layers (Section~\ref{chapter:mcslock:sec:liveness-atomicity}). By taking advantage of those  side conditions in the replay function, we can express all  invariants about the log in a single statement, ``the replay function is defined'':\newline
\begin{tabular}{P{0.95\textwidth}}
    $\exists \codeinmath{c1}\ \codeinmath{c2}\ \codeinmath{b}\ \codeinmath{q}\ \codeinmath{s} \codeinmath{t}.\ \QSCalLock\codeinmath{(l)=Some(c1,c2,b,q,s,t)}$\\
\end{tabular}

This type for the replay function is optimized to only expose exactly the information needed by the subsequent liveness proof. 
We need to expose the queue and the set of slow CPUs in order to define the termination measure $\mcsmeasure$
 (Section \ref{chapter:mcslock:sec:liveness-atomicity}). 
 On the other hand, this is not enough information to bridge the gap from the low-level functional specification. 
 In order to show that the memory cells for a valid linked-list and therefore respects the queue
ordering, we need to track exactly what the valid state transitions are. So inside the ghost state layer, 
we also introduce a different relation  $\QCalMCSLock$
which is mostly the same as $\QSCalLock$ but written as an (functional) inductive relation 
in $\coq$ instead of a recursive function, and which has even more preconditions for when it is defined. 
We then add one more condition in the layer invariant saying that $\QCalMCSLock$ and $\QSCalLock$ output the same
result. Most of the proofs inside the ghost layer are done using the relation instead of the function.
For simplicity, we will ignore the distinction in the rest of the paper, 
and write the lemma statements about $\QSCalLock$ even if they used $\QCalMCSLock$ in the actual $\coq$ code.


To show that the ghost layer refines the previous layer, we show a
one-step forward-downward refinement: if the method from the higher
layer returns, then method in the lower layer returns a related
value. For this particular layer the log doesn't change, so the
relation in the refinement is just equality (including the relation for the global log and the environmental context ($\oracle^{mcs}_{cid}$) -- \ie, the relation for strategies in the $\oracle^{mcs}_{cid}$), 
and the programmer just
has to show that  lower-level methods are at least as defined and
that they return equal results for equal arguments.


As we prove this, we need lemmas to show that we can satisfy preconditions for operations in the lower layer, by relating the data in $\codeinmath{la}$ to the abstract queue.  For example, when trying to take the lock, the high level specification checks if the current CPU is at the head of $\codeinmath{q}$, which the low specification tests if the $\codeinmath{busy}$ field is true, so we need Lemma~\ref{lem:chapter:mcslock:Q_CalMCSLock_tail_is_busy} to show that they will follow the same path of code. 


\begin{lemma}[tail is busy]
\label{lem:chapter:mcslock:Q_CalMCSLock_tail_is_busy}

    If $CalMCSLock\ \codeinmath{l=}\Some\codeinmath{(tl,la,tq)}$ and 
    $\QSCalLock\ \codeinmath{l=}\Some\codeinmath{(c1,c2,i::q,s,t)}$ and $j \in\codeinmath{q}$, then $\codeinmath{lock\_array[}j\codeinmath{] = (true, \_)}$.
\end{lemma}

\begin{theorem}[simulation for the ghost layer] 
    Let's assume that the abstract data $\codeinmath{d}$ satisfies the invariant of two layers,
    $\mmcslockop$ and $\mqmcslockop$. When 
$\waitqslockspec\codeinmath{(d)=}\Some\codeinmath{d')}$ then 
$\mcsacquirespec\codeinmath{(d)=}\Some\codeinmath{(d')}$.
\end{theorem}


\subsection{Liveness and atomicity}
\label{chapter:mcslock:sec:liveness-atomicity}

The specification in the previous section is still too low-level and
complex to be usable by client code in the rest of the system.  First,
the specification of the $\mcsacquire$ and
$\mcsrelease$ primitives contain loops, with complicated
bounds on the number of iterations, which clients certainly will not
want to reason directly about.  More importantly, since the
specifications generate multiple events, clients would have to show
all interleavings generate equivalent results.

To solve this we use the \textit{log-lift} design
pattern in Section~\ref{chapter:ccal:subsec:local-layer-interface}; build a new layer with \emph{atomic specifications},
\ie, each primitive is specified to generate  a single event.
For an atomic layer there is a
therefore a one-to-one mapping between events and primitives, and the global log
can be seen as a record of which primitives were invoked in which
order. Thus, the refinement proof which ascribes an atomic
specification proves once and for all that overlapping and interleaved
primitive invocations give correct results.
In this layer, the specifications only use three kinds 
of events: taking the lock ($\waitlock{n}$),
releasing it ($\rellock$), and modifications of the shared
memory that the lock protects ($\mcstshared{\ignorechar}$)



\begin{figure}
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/highlogreplay.v}
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/hswaitlockspec.v}
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/hspasslockspec.v}
\caption{Final Atomic Specification of Aquire/Release Lock Functions.}
\label{fig:chapter:mcslock:hswaitlockspec}
\end{figure}

Figure~\ref{fig:chapter:mcslock:hswaitlockspec} shows  final specifications for 
wait and pass primitives. We show them in full details, with no elisions,
because they are the interfaces that clients use. First, the
specification for the lock acquire function itself
($\mcswaithlockspec$) takes  function arguments
$\codeinmath{bound}$, $\codeinmath{index}$, $\codeinmath{ofs}$, and maps an
abstract state ($\mcsabsdata$) to another. When writing this
specification we chose to use two components in the abstract state, a
log ($\lockmultilogpool$) and also a field ($\mcslockabsfield$) which
records for each numbered lock if it is free ($\mcsockfalse$)
or owned by a CPU ($\mcslockown \ \bfalse$). 
The boolean value in ($\mcslockown\ \_$) indicates whether copied/flushed the shared memory value to/from the local memory for the CPU or not.
The $\bfalse$ value in $\mcswaithlockspec$ implies that the CPU already hold the lock but does not pull the shared memory by using the $\pull$ operation yet. 
On the other hand, the  $\bfalse$ value   in $\mcspasshlockspec$ implies that the $\push$ primitive has been invoked already 
to flush the local change to the shared memory, but the CPU still owns the lock.
The $\codeinmath{lock}$ field is
not very important, because the same information can also be computed
from the log, but exposing it directly to clients is sometimes more
convenient.

The specification returns $\None$ in some
cases, and it is the
responsibility of the client to ensure  that does not
happen. So clients must ensure that: the CPU is in a kernel/host
mode (for the memory accesses to work); an index and an offset (used to
compute the lock id) are in range; the CPU did not already hold the
lock ($\mcsockfalse$); and the log is well-formed
($\HCalLock\ \codeinmath{l'}$ is defined, which will always be the case if
$\HCalLock\ \codeinmath{l}$ is defined).  When all these preconditions are
satisfied, the specification queries the context once, and appends a
single new $\WAITLOCK$ event to the log.
Figure~\ref{fig:chapter:mcslock:hswaitlockspec} also shows the replay function
$\HCalLock$.
It has a much simpler type than $\QSCalLock$in the
previous layer, because we have abstracted the internal state of the lock
to just whether it is free ($\LEMPTY$),
held ($\LHOLD$), and if taken, the CPU id ($\Some\ i$)
of the holder of the lock. Unlike the three bound numbers in the
previous layer, here we omit the numbers for the internal lock
operations and only keep the bound $\codeinmath{self\_c}$ for the number
of events generated during the critical section. Again, it's the
client's responsibility to avoid the cases when $\HCalLock$
returns $\None$. In particular, it is only allowed to release
the lock or to generate memory events if it already holds the lock
($\zeqop{i}{i0}$), and each memory event decrements the counter,
which must not reach zero. The client calling $\waitlockfunc$
specifies the initial value $n$ of the counter, promising to take at
most $n$ actions within the critical section.


In the rest of the section, we show how to prove that the function
does in fact satisfy this high-level atomic specification.
Unlike the previous layers we considered, in this case the log in the
upper layer differs from the one in the lower layer. For example, when
a CPU takes the lock, the log in the upper layer just has the one
atomic event ($\waitlock{n}$), while the log in the underlay
has a flurry of activity (swap the tail pointer, set the next-pointer,
repeatedly query the busy-flag).
Because the log represents shared data, our framework requires a
slightly strengthened refinement theorem for the log-component of the
state. Usually a refinement simulation works by specifying some
relation $R_{(\mhmcslockop, \mqmcslockop)}$ between machine state and abstract state, and then
proving that the state transitions preserve the relation. Indeed, for
thread-local data this is exactly what $\certikos$ does also.

Let's recall the contextual refinement property in Definition~\ref{def:chapter:ccal:contextual-refinement}. 
This relation   $R_{(\mhmcslockop, \mqmcslockop)}$ must includes the relation in between 
two strategies of those two layers are relying on; 
thus the relation for two different environmental contexts, which are $\oracle^{lk}_{cid}$ for $\mhmcslockopfull$ and $\oracle^{mcs}_{cid}$ for $\mqmcslockop$.
For example, suppose one particular
execution of the system generates the log $\codeinmath{l}_{\mqmcslockop}$.  A normal simulation
theorem for a CPU 1 would tell us that there \emph{exists} a log $\codeinmath{l}_{\mhmcslockop}$
that meets CPU 1's local specifications and satisfies the relation
($R_{({\mhmcslockop}, {\mqmcslockop})}$). 
Similarly, the local proof for a CPU 2 would say there
exists a some log $\codeinmath{l'}_{\mhmcslockop}$
related to  $\codeinmath{l}_{\mqmcslockop}$. 
But in order to derive a simulation for the
entire system, we need the constraint that that $\codeinmath{l}_{\mhmcslockop}$  is equal to
$\codeinmath{l}_{\mhmcslockop}$. 
The actual definition of the relation is by defining the proper function $f_{(lk, mcs)}$ between two logs.
In other words, when proving the simulation,
we find a function $f_{(lk, mcs)}$ for the logs, such that $f_{(lk, mcs)}(\codeinmath{l}_{\mqmcslockop}) = \codeinmath{l}_{\mhmcslockop}$.


As for  $\mcsname$ Lock, we define a function $\relatemcslogkwd$ from the
implementation log to the atomic log. Figure~\ref{fig:chapter:mcslock:logsequence}
shows by example what it does. It keeps the shared memory events as
they are, discards the events that are generated while a CPU wait for
the lock, and maps just the event that finally takes or releases the
lock into $\WAITLOCK$ and $\rellock$.

\begin{figure}
\includegraphics[width=\textwidth]{figs/mcslock/logsequence}
\caption{Log Sequence and Log Refinement Example.}
\label{fig:chapter:mcslock:logsequence}
\end{figure}

We then prove a one-step refinement theorem from the atomic specification 
to the implementation, in other words, that if a call to the atomic primitive returns a 
value, then a call to its implementation also returns with a related log:

\begin{theorem}[$\mcsname$ Wait Lock Exist]
  \label{thm:chapter:mcslock:mcs_wait_lock_exist}

  Suppose $\codeinmath{d}_{\mhmcslockop}$ and $\codeinmath{d}_{\mqmcslockop}$, abstract datum for two layers ($\mhmcslockop$ and $\mqmcslockop$, respectively),
   satisfy the layer
  invariants and are related by
   $\relatemcslog{\codeinmath{d}_{\mqmcslockop}}{\codeinmath{d}_{\mhmcslockop}}$ for their global logs and identity relations for others.
If $\mcswaithlockspec(\codeinmath{d}_{\mhmcslockop}) = \Some\ \codeinmath{d'}_{\mhmcslockop}$, then there exists some 
$\codeinmath{d'}_{\mqmcslockop}$
  which is $\waitqslockspec(\codeinmath{d}_{\mqmcslockop}) = \codeinmath{d'}_{\mqmcslockop}$ and is related with $\codeinmath{d'}_{\mhmcslockop}$  by
   $\relatemcslog{\codeinmath{d'}_{\mqmcslockop}}{\codeinmath{d'}_{\mhmcslockop}}$.
\end{theorem}


The proof requires a \emph{fairness assumption}.
A CPU cannot take the lock until the previous CPU releases it, 
and the previous CPU cannot release it if it never gets to run. 
At its most fundamental, the $\certikos$ machine model is a non-deterministic 
transition system (which is subsequently viewed as a log of events), 
and there is nothing in the basic model that ensures fairness, 
so we have to add an extra assumption somewhere. In principle, it would be 
possible to modify the machine model itself, and then pass the fairness assumptions 
along in the specification of each layer until we reach the layers related to mutex locks, 
but in our development, we choose a more expedient solution and express
the fairness assumption as an extra axiom talking about the logs 
in the data representation layer (Section~\ref{chapter:mcslock:sec:representation-ghost}). 
By doing that, our framework can use the previous machine 
model as it is, and can reuse most previous proofs.

Specifically, we assume that there exists some constant $F$ (for ``fairness'') such that no CPU that enters the queue has to wait for more than $F$ events until it runs again. 
In $\coq$ we provide a function, $\CalBound:\ \ztype\ \rightarrow\ \lockmultilog\ \rightarrow \ \nattype$,
which ``counts down'' 
until CPU $i$ gets a chance to 
execute. 
The full definition of $\CalBound$ is in Figure~\ref{fig:chapter:mcslock:calbound-definition}.


\begin{figure}
\begin{center}
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/calbound.v}
\end{center}
\caption{$\CalBound$ Definition.}
\label{fig:chapter:mcslock:calbound-definition}
\end{figure}

The fairness assumption, then is that for all logs $\codeinmath{l}$, 
when the low level log replay function returns a 
value ($\QSCalLock\codeinmath{(l)=}\Some\codeinmath{(c1,c2,h,q,s,t)}$) and $j$ is 
in the waiting queue ($j \in \codeinmath{q}$), then we can conclude that $\CalBound\ j\ \codeinmath{l}>0$. 
We then define a natural-number valued termination measure $\mcsmeasure_i\codeinmath{(c1,c2,h,q,s,l)}$.  
This is a bound on how many events the CPU $i$ will
have to wait for in a state represented by the log $\codeinmath{l}$, and where
$\QSCalLock\codeinmath{(l)=}\Some\codeinmath{(c1,c2,h,q++}i\codeinmath{::q}_0\codeinmath{,s,t++n::t}_0)$.
Note that
we partition the waiting queue into two parts $\codeinmath{q}$ 
and $i\codeinmath{::q}_0$, where $\codeinmath{q}$
represents the waiting CPUs that were ahead of $i$ in the queue.
The function $\mcsmeasure$ has two cases that depend on the head status.
\begin{center}
\begin{tabular}{p{0.95\linewidth}}
$\mcsmeasure_i\codeinmath{(c1,c2,}\LEMPTY\codeinmath{,q,s,l)=}\CalBound_{\mathsf{hd}(q)}\codeinmath{(l)+(}K_1\codeinmath{(}\Sigma\codeinmath{t)+}|\codeinmath{q}\cup\codeinmath{s}|\codeinmath{)}\times K_2\codeinmath{)}$\\
$\mcsmeasure_i\codeinmath{(c1,c2,}\LHOLD\codeinmath{,q,s,l)=}\CalBound_{\mathsf{hd}(q)}\codeinmath{(l)+}\BoundValAux\times K_2$ \\
\hfill	 where $\BoundValAux\codeinmath{=(c1+c2+(}\Sigma\codeinmath{(}\mathsf{tl}\codeinmath{(t))}\times K_1\codeinmath{+}|\mathsf{tl}\codeinmath{(q)}\cup\codeinmath{s}|\codeinmath{)}$\\
\end{tabular}
\end{center}

In short, if the lock is not taken, the bound $\mcsmeasure$ is the sum of the
maximum time until the first thread in the queue gets scheduled again
($\CalBound_{\mathsf{hd}(q)}(\codeinmath{l})$), plus a constant times
the sum of the number of operations to be done
by the CPUs ahead of $i$ in the queue ($\Sigma\codeinmath{t}$) 
and the number of CPUs ahead of $i$ which has
yet to execute $\SETNEXT$ operation 
$\codeinmath{(}|\codeinmath{q}\cup\codeinmath{s}|\codeinmath{)}$. If the lock is currently
held, then $\codeinmath{{c1+c2}}$ is a bound of the number of operations it will
do
(and we can ignore the first element of $\codeinmath{q}$ and $\codeinmath{t}$, since they are
accounted for).
The constants and fairness assumption is general enough to handle the cases which takes a slightly longer execution than it is expected to.
The constants ($K_1 = F+5$ and $K_2 = F+4$) are chosen somewhat
arbitrary, and certainly $\mcsmeasure$ is not the tightest possible bound. It
does not need to be, since it does not occur in our final theorem
statement.

The definition of $\mcsmeasure$ is justified by the following two
lemmas. First, we prove that M decreases if CPU $i$ is waiting and some other CPU
$j$ executes an event $\codeinmath{e}_{j}$.

\begin{lemma}[Decreasing measure for other CPUs]
\label{lem:chapter:mcslock:MCS_CalLock_progress_onestep}
Assuming that $\QSCalLock\codeinmath{(l)=}\Some\codeinmath{(c1,c2,h,q}_1\codeinmath{++}i\codeinmath{::q}_2\codeinmath{,s,t}_1\codeinmath{++c::t}_2\codeinmath{)}$, where
$|\codeinmath{q}_1|\codeinmath{=}|\codeinmath{t}_1|$ and $\QSCalLock\codeinmath{(e}_j\codeinmath{::l)=}\Some\codeinmath{(c1',c2',h',q',s',t')} $
for some $j\neq i$ and 
 $\CalBound\codeinmath{(e}_j\codeinmath{::l)}\codeinmath{>}0$.
Then we can split the queue $\codeinmath{q'}$ with satisfying the following properties:
$\codeinmath{q'=q}_{1}'\codeinmath{++}i\codeinmath{::q}_{2}'$ as well as
$\mcsmeasure_i\codeinmath{(c1',c2',h',q}_{1}'\codeinmath{,s',t}_{1}'\codeinmath{,e}_j\codeinmath{::l)}<\mcsmeasure_i\codeinmath{(c1,c2,h,q}_1\codeinmath{,s,t}_1\codeinmath{,l)}$.
\end{lemma}

\begin{proof}
 We consider all possible events
$\codeinmath{e}_j$ which could make $\QSCalLock$ returns $\Some$. If $j$ is not the 
CPU at the head of the queue gets scheduled, it will not be
able to make any progress, so the abstract state of the queue remains the same,
but the counter $\CalBound$ decreases.
Otherwise, the counter $\CalBound$ will reset to the upper bound we assumed on fairness, $F$. 
However, in this case the algorithm will make some progresses that change $\codeinmath{c1}$, $\codeinmath{c2}$, $\codeinmath{q}$, or $\codeinmath{s}$.
For example, a CPU $j$ may execute  $\SETNEXT$ (which decreases the size of
$\codeinmath{s}$), it may enter the critical section (which moves some measure from
the head of $\codeinmath{q}$ to the counters $\codeinmath{c1+c2}$) or it may exit the section
(and that event will decrement $\codeinmath{c2}$).
\end{proof}


The second lemma ensures that the waiting loop will eventually
terminate (The preconditions that $i$ is somewhere in the waiting queue,
and that it has already left the set $\codeinmath{s}$, correspond the set-up
which $\waitlockfunc$ does before it starts looping).

\begin{lemma}[Loop termination]
\label{lem:chapter:mcslock:CalWaitGet_exist'}
Suppose that $\QSCalLock\codeinmath{(l)=}\Some\codeinmath{(c1,c2,h,q}_1\codeinmath{++}i\codeinmath{::q}_2\codeinmath{,s,t}_1\codeinmath{++c::t}_2\codeinmath{)}$, where
$|\codeinmath{q}_1|\codeinmath{=}|\codeinmath{t}_1|$, with $i \not\in\codeinmath{q}_1$ and $i \not\in\codeinmath{s}$ and suppose $\oracle^{mcs}_{cid}$ and $\oracle^{lk}_{cid}$  are valid
contexts (which are matched by the relation based on the function $f_{(l, mcs)}$.) Then, if $k>\mcsmeasure_i\codeinmath{(c1,c2,h,q}_1\codeinmath{,s,t}_1\codeinmath{)}$; thus there exists $\codeinmath{l'}$ such
that $CalWaitGet\codeinmath{(}k\codeinmath{,}i\codeinmath{,l)=}\Some\codeinmath{(l')}$.
\end{lemma}


\begin{proof}
The proof is by induction on $k$, the number of loop iterations. The
most interesting part of the proof is to show that each event
generated by the function will decrease the measure.
As it pulls more event to the log form the context, we appeal to
Lemma~\ref{lem:chapter:mcslock:MCS_CalLock_progress_onestep}, which says that the metric decreases. 
Then, there are two cases in the proof depending on whether $i$ has
arrived at the head of the queue (so $\codeinmath{q=}\nil$) or not. If it has,
$\waitqslockspec$ will generate a $\getbusy{false}$
event and return, so we are good. 
Otherwise, it will generate a $\getbusy{true}$ event, and
start another loop iteration. That event does not change the state of
the lock, but it does decrement the $\CalBound$ on when the head CPU
will get scheduled next, so the measure decreases as required.

The proof (for the termination of the loop in $\waitqslockspec$) also relies on the termination property of the busy-loop in $\passqslockspec$.
That proof, on the contrary, is easier. A CPU holding the lock will set
the next pointer before it does anything else, so we are only waiting
for the CPU at the head of the queue to get scheduled at all.
Now, to prove that the loop in $\mcsacquire$ specification
is defined, we just have to pick the function $\CalWaitLockTime$
so that $\CalWaitLockTime\codeinmath{(t)}$ is greater than $mcsmeasure$ at that
point. The rest of the simulation proof for Theorem~\ref{thm:chapter:mcslock:mcs_wait_lock_exist} is straightforward.
Except the waiting loop, other operations in the wait lock function are deterministic and finite. 
\end{proof}

With Lemma~\ref{lem:chapter:mcslock:CalWaitGet_exist'}, 
the simulation proof between $\mcswaithlockspec$ and $\waitqslockspec$ are straightforward.
\begin{theorem}
There is a one-step simulation from $\mcswaithlockspec$ to
$\waitqslockspec$, with the simulation on logs given by $\relatemcslogkwd$.
\end{theorem}


\subsection{From downwards- to upwards-simulation}
\label{chapter:mcslock:sec:downwards-to-upwards}

When moving from sequential to concurrent programs we must
re-visit some fundamental facts about refinement proofs.  Ultimately,
the correctness theorem we want to prove is ``all behaviors of the
machine satisfy the specification''. If we model the machine and the
specification as two transition systems $\codeinmath{M}$ and $\codeinmath{S}$, then this
corresponds to \emph{upwards simulation}: if $\codeinmath{S} \sim \codeinmath{M}$ and 
$\codeinmath{M} \Longrightarrow^* \codeinmath{M}'$, then $\exists \codeinmath{S}'. \codeinmath{S}' \sim \codeinmath{M}'$ and
 $\codeinmath{S} \Longrightarrow^* \codeinmath{S}'$, and if $\codeinmath{M}$ is stuck then $\codeinmath{S}$ is stuck also.
But directly proving an upwards simulation is difficult. You are given
a long sequence of low-level steps, and have to somehow reconstruct
the high-level steps and high-level ghost state corresponding to
it. One of the insights that made the $\compcert$ project
possible~\cite{Leroy-backend} is that as long as $\codeinmath{M}$ is deterministic
and $\codeinmath{S}$ is not stuck, it suffices to prove a \emph{downward
  simulation}: if $\codeinmath{S} \sim \codeinmath{M}$ and $\codeinmath{S} \Longrightarrow \codeinmath{S}'$, then $\exists
\codeinmath{M}'. \codeinmath{S}' \sim \codeinmath{M}'$ and $\codeinmath{M} \Longrightarrow^* \codeinmath{M}'$. (The assumption that $\codeinmath{S}$
is not stuck is standard, it corresponds to only proving refinement
for ``safe'' clients regarding to the specifications.)

Unfortunately, concurrent programs are \emph{not} deterministic: we
want to prove that every interleaving of operations from
different CPUs in the low-level machine results in correct
behavior. So if we had directly modeled the implementation as a
non-deterministic transition system, then we would have to work
directly with upwards simulations, which would be intractable when
reasoning about the low-level details of C programs.

In our approach, all the non-determinism is isolated to the concurrent
context $\oracle$. Any possible interleavings of  threads can be
modelled by initializing the abstract state with a particular
$\oracle^{mcs}_{cid}$, and the execution proceeds deterministically from
there. Therefore we can still use the $\compcert$ method of first
proving a downward simulation and then concluding the existence of a
upward simulation as a corollary.
The context-formalism is also helpful because $\oracle^{mcs}_{cid}$ contains
the entire execution of all other threads, both past and future, so we
have enough information to directly prove a \emph{forward}
simulation. Otherwise it may not be clear if a given low-level
operation can really ``commit'' (and generate a high-level event)
until we see what the other cores do, so proofs about fine-grained
concurrency can require a difficult backwards-simulation
from the end-state of the program.~\cite{DGLMQueue}

There is still an obligation to show that for every $\oracle^{mcs}_{cid}$, there
in fact exists an $\oracle^{lk}_{cid}$ with the right
properties. (Specifically, it should the always output logs which
respect the program invariants, \ie, the replay function is defined,
and also it should respect the refinement relation $f_{(lk, mcs)}$.) But this can
be managed by the framework in a generic way, which we discussed in Chapter~\ref{chapter:ccal}. When
verifying a particular layer, the programmer only needs to define $f_{(lk, mcs)}$.

