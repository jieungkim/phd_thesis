\section{Events, Logs, and  Contexts for MCS Lock}
\label{chapter:mcslock:sec:eventlogandoracle}

As discussed in Chapter~\ref{chapter:ccal}, 
modeling a shared state among CPUs is 
closely related to define a set of events, a concurrent context, and a replay function that are suitable for
the state.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\begin{minipage}{\linewidth}
\lstinputlisting[numbers = left, language = C]{source_code/mcslock/lockeventtype.v}
\end{minipage}
\caption{Event set for MCS Lock}
\label{fig:chapter:mcslock:lock_event_type}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Again, an \emph{event} is any action which has observable consequences for
other CPUs. Each specification must define events for all the points
in the program where it reads or writes to shared memory (but not for
accesses to thread-local memory). The \emph{global log} is a list of
events, representing all actions that have happened in the system
since it began running. Actions from different CPUs are interleaved in
the list.
When we write a specification we can chose the set of events, as long
as it is fine-grained enough to capture all scheduling interleavings
that may happen.
Figure~\ref{fig:chapter:mcslock:lock_event_type} shows the event definition used to
model lock acquire and release. They correspond to the part of the MCS lock source code in Figure~\ref{fig:chapter:mcslock:mcs_lock}
and acquiring/releasing the lock after we show starvation freedom. 


Followed by the assumptions in our machine models in Section~\ref{chapter:ccal:sec:interface-calculus},  we again assumes that the
machine is sequentially consistent (all CPUs see a single linear log). 
This rules out 
Even with this assumption,
verifying the MCS algorithm is not easy (the other proofs we are aware
of assume sequential consistency too), so we leave weak memory models
to future work.

\begin{itemize}

\item \textbf{{\swaptail{bound}{success}}} event is for the
operations from line 5 to 7 in Figure~\ref{fig:chapter:mcslock:mcs_lock} and takes
two arguments. The second argument is a boolean flag indicating
whether the previous ``last'' value of MCS lock was \invalidmcsval,
which means it records whether the if-statement at line 9 took the fast path or not.
The first argument is the \emph{bound number}, which is a key idea in
our development. Every client that invokes \code{mcs$\_$acquire} has
to promise a bound for the critical section. This number
does not influence the compiled code in any way, but the
\emph{specification} says that it is invalid to hold the critical
section for longer than that (c.f. the counter $c_1$ in
Section~\ref{chapter:mcslock:sec:representation-ghost}).
This bound number enables \emph{local} reasoning about liveness.
For the thread waiting for acquiring or releasing a lock,
its wait time can be estimated based on other threads' bound number. For the lock holder, it has to guarantee
to exit the critical section within its own bound. 
Thus, by showing that each thread follows this protocol,
we can derive the liveness property for the whole system.

To be precise, the bound number is a limit on the number of events
that can get appended to the log, see the counter \code{c1} in
Section~\ref{chapter:mcslock:sec:representation-ghost}.
Every CPU adds at least
one event every time it "does something", e.g. each loop iteration in \code{mcs$\_$release} appends a \code{GET$\_$NEXT}
event, so
as we will see in
Section~\ref{chapter:mcslock:sec:liveness-atomicity} this sufficies to give a bound of
the number of loop iterations in the lock acquire function. In the following we often speak of
``number of operations'', which does not mean single CPU instructions,
but instead whatever operation is represented by particular events.


\item \textbf{\setnext{prev$\_$last}} event corresponds to the code at line 10. 
the \code{prev$\_$last} represents the \code{prev$\_$id} in the code.

\item\textbf{\getbusy{busy}} event shows the busy waiting in the acquire lock function.
The first argument will be true when the last value is same with the current CPU ID that calls the primitive which generates this event.
It will be false when the last value is not same with the current CPU ID that calls the primitive.
\end{itemize}

Next, other threes are enough to represent release lock in Figure~\ref{fig:chapter:mcslock:mcs_lock}.

\begin{itemize}

\item \textbf{\castail{busy}} represents the atomic expression at line 21  in Figure~\ref{fig:chapter:mcslock:mcs_lock}. 
In addition, the ``busy'' corresponds to the result of the \code{CAS} operation in Figure~\ref{fig:chapter:mcslock:mcs_lock}.

\item  \textbf{\getnext} corresponds to the primitive that try to get the next value of the current CPU's node, and abstracts busy waiting in release lock function.

\item  \textbf{\setbusy} represents the last three lines in \code{mcs$\_$release}.
\end{itemize}

Those six events are used to show the functional correctness of
an MCS Lock. However, for clients that use the MCS Lock to build shared
objects they expose too much implementation details.
In Section~\ref{chapter:mcslock:sec:liveness-atomicity} we will prove linearizability and
starvation freedom,  to replace them
with just two events.


\begin{itemize} 
\item \textbf{\waitlock{bound}} corresponds to lock acquire. The ``bound'' number in here is exactly same with the ``bound'' number in \swaptail{bound}{success} event.

\item \textbf{\rellock} corresponds to the lock release.
\end{itemize}

In addition to the above eight events, which are generated by the lock
acquire and release functions, the clients of the lock will also
generate events while they are in the critical section. Mutex locks in
CertiKOS are used to protect blocks of shared memory, so we call the
events generated by the client code \textbf{shared memory events}. The
final specification we prove will entail that a shared memory event
from CPU $i$ can only happen in the interval between a lock acquire
event for $i$ and a lock release event for $i$, which is how we
express the mutual exclusion property.

\section{Verification---Layer by layer}
\label{chapter:mcslock:sec:verification}%

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{figs/mcslock/layer_overview}
\end{center}
\caption{MCS Lock Layers}
\label{fig:chapter:mcslock:layeroverview}
\end{figure}

We build five layers, starting from a base
layer which represents the machine model that our compiled code will
run on.
Figure~\ref{fig:chapter:mcslock:layeroverview} shows the overall structure of our development.
For simplicity the figure only includes lock primitives, and
primitives passed through from below are hidden in it.
We also omits the current focused set ($cid$ -- CPU ID) and the environmental context ($\oracle$) in the figure
as well as the rest of this section for simplification.
The CPU ID will not be changed at all during the whole layers (note that all  layer interfaces in this MCS Lock module 
are local layer interfaces), but there is a place that we need a simplification of the global log to guarantee the atomicity of 
acquire/release locks as mentioned in Section~\ref{chapter:ccal:subsec:local-layer-interface}.
We will clearly state that which layer is related to the \textit{log-lift} pattern; 
thus require the change in the environmental context.
Each big and outer rectangle in the figure means each layer in the MCS Lock Module, 
and small and inner rectangles in each layer implies the primitives defined in the layer.
The arrows show dependencies between adjacent layers,
for example the definition of \code{wait$\_$lock} in \code{MMCSLockOp}
uses three primitives (\code{mcs$\_$swap$\_$tail},
$\codeinmath{mcs$\_$set$\_$next}$, and $\codeinmath{mcs$\_$get$\_$busy}$) from  \code{MMCSLockAbsIntro}.

Most layers in the figure are related to the \textit{fun-lift} pattern in Section~\ref{chapter:ccal:subsec:local-layer-interface}.
The layers \code{MCSMBoot} through \code{MMCSLockAbsIntro}
introduces getter and setter functions for accessing memory
(Section~\ref{chapter:mcslock:subsec:lowestmachinemodel} and
\ref{chapter:mcslock:subsec:abstractoperationlayer}). These layers also
contain logical primitives which record events to the log; we are in
effect manually implementing a model of concurrent execution by
extending a sequential operational semantics for C. 
The layer \code{MMCSLockOp} contains the C code from 
Figure~\ref{fig:chapter:mcslock:mcs_lock}. This layer proves low-level
functional correctness, \ie, it reasons about the C code and
abstracts away details about memory accesses, integer overflows, etc,
to expose an equivalent specification written as a $\coq$
function (Section~\ref{chapter:mcslock:subsec:atomicoperation}).
The two top layers, \code{MQCSLockOp} and \code{MHMCSLockOp}, do not introduce any new primitives.
They simplify the specifications of 
the release- and acquire lock functions (\code{pass$\_$lock} and
\code{wait$\_$lock}), \ie, each layer ascribes a different
specification (with a different log replay function and a set of events)
to the same C function. Those specification names are notated inside the square bracket in Figure~\ref{fig:chapter:mcslock:layeroverview}.

On the other hand, two layers are closely related to the  \textit{log-lift} pattern in Section~\ref{chapter:ccal:subsec:local-layer-interface}.
The layer \code{MQMCSLockOp} adds ghost state, keeping track of a
queue of waiting CPUs.
(Section~\ref{chapter:mcslock:sec:representation-ghost}). This queue is key to the liveness proof but is not explicitly represented in the C implementation.
The top layer \code{MHMCSLockOp} proves starvation freedom and liveness
(Section~\ref{chapter:mcslock:sec:liveness-atomicity}). This lets us ascribe atomic
specifications where taking or releasing a lock generates just a
single event to the log.




\subsection{Memory operations layers}
\label{chapter:mcslock:subsec:lowestmachinemodel}

Although we glossed over this in Figure~\ref{fig:chapter:mcslock:mcs_lock}, our
actual C implementations of \code{msc$\_$acquire} and
\code{msc$\_$release} do not access memory directly.  Instead, they call
a collection of helper functions with names like
\code{mcs$\_$set$\_$next}. The lowest two layers in our proofs
are devoted to implementing these helper functions.
The key concern is to make sure that the events that get appended to the log
correspond to the actual actions to the memory. Some of that can be proven, 
but some parts of this layer are trusted as a part of the machine model.

We first describe the first and the lowest tuple in our proofs,

\begin{center}
\begin{tabular}{P{0.95\textwidth}}
$\ltyp{\codeinmath{MMCSBoot}}{R_{mcsintro}}{\codeinmath{M}_{\codeinmath{MMCSLockIntro}}}{\codeinmath{MMCSLockIntro}}$\\
(precisely, ``$\ltyp{\PLayer{\codeinmath{MMCSBoot}}{cid, \oracle_{mcs}}{}}{R_{mcsintro}}{\codeinmath{M}_{\codeinmath{MMCSLockIntro}}}{\PLayer{\codeinmath{MMCSLockIntro}}{cid, \oracle_{mcs}}{}}$'' \\
when $cid$ is the focused current CPU ID and\\
 $\oracle_{mcs}$ is an instance of environmental contexts for our program.)\\
\end{tabular}
\end{center}

The interface (\code{MMCSBoot}) represents the machine model that our compiled code will run on.
All primitives defined in $\codeinmath{MMCSLockIntro}$ are part of the trusted computing base, and correspond to empty functions in our compiled code.

Eight of the primitives in $MMCSBoot$  are closely related to the MCS Lock verification:
\begin{center}
\begin{tabular}{P{0.95\textwidth}}
$\{\codeinmath{atomic\_mcs\_log},\ \codeinmath{atomic\_mcs\_SWAP},\ \codeinmath{atomic\_mcs\_CAS},\ \codeinmath{mcs\_init\_node\_log},$\\
$\codeinmath{mcs\_GET\_NEXT\_log},\ \codeinmath{mcs\_SET\_NEXT\_log},\ \codeinmath{mcs\_GET\_BUSY\_log},\ \codeinmath{mcs\_SET\_BUSY\_log}\} $\\
\end{tabular}
\end{center}

Two primitives, \code{atomic$\_$mcs$\_$SWAP} and \code{atomic$\_$mcs$\_$CAS} are for the two atomic instructions {\em fetch-and-store} and {\em compare-and-swap}, and will be further discussed below.

The other six are used to update the log.  As we noted in
Section~\ref{chapter:mcslock:sec:eventlogandoracle}, the log is part of the abstract
state in our implementation to match the state definition of our local layer interface (in $\ccalname$) with 
that of $\calname$, while abstract data (private abstract data and shared abstract data) and the global log are 
different components in our local layer interface state definition stated in Section~\ref{chapter:ccal:subsec:local-layer-interface}.
Ordinary assembly instructions only modify physical memory, not
abstract state, so in order for programs to be able to append events to
the log we include these six primitives in \code{MMCSBoot}. 
For example, the specification of \code{mcs$\_$SET$\_$NEXT$\_$log} updates the log by adding one (\setnext{prev$\_$id}) event as follows:
\lstinputlisting[language = Caml]{source_code/mcslock/mcs_set_next_log.v} 
In the compiled code, these primitives appear as empty functions that do nothing, they are only used to modify the logical state.


The code $\codeinmath{M}_{\codeinmath{MMCSLockIntro}}$ in the layer contains the 
functions which actually modifies the memory in the way the event announces.
Each function in $\codeinmath{M}_{\codeinmath{MMCSLockIntro}}$ calls the corresponding primitive from
\code{MCSMCurID} inside the function to add the event to the log.
For example, \code{mcs$\_$SET$\_$NEXT}, one function in $\codeinmath{M}_{\codeinmath{MMCSLockIntro}}$, writes
to \code{next} and also calls
the empty function \code{mcs$\_$SET$\_$NEXT$\_$log}:
\lstinputlisting [language = Caml]{source_code/mcslock/mcs_set_next.c}

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{figs/mcslock/layer3}
\end{center}
\caption{The structure of the memory operations layer}
\label{fig:chapter:mcslock:layer-struct-mcs-verification}
\end{figure}

The interface \code{MMCSLockIntro} contains the high level specification for each function defined in $\codeinmath{M}_ {\codeinmath{MMCSLockIntro}}$. 
The high level specifications work on the log instead of the exact memory slot $\codeinmath{LK}$.
Therefore, after proving the {\em refinement} between the memory ($\codeinmath{LK}$ in Figure~\ref{fig:chapter:mcslock:layer-struct-mcs-verification})
and the abstract state (\emph{log} in Figure~\ref{fig:chapter:mcslock:layer-struct-mcs-verification}), we only need to care about the abstract state.

For the refinement proof, we need two more ingredients.
The first one is a \emph{log replay function}.
A log is merely a list of events, but what specifications need to know is what the state of the system will look like after those events have executed,
and a replay function calculates that. 
Different layers may define different replay functions in order to interpret the same log in a way that suits their proofs.
Therefore, we have introduced the proper log replay function in several layers, and prove the relationship between the result of them when we introduced the new one.
In $\codeinmath{MMCSLockIntro}$, we define \code{CalMCSLock}, which has the following type:
\lstinputlisting [language = Caml] {source_code/mcslock/lowreplaytype.v}
where
\lstinputlisting [language = Caml] {source_code/mcslock/lowmcsstruct.v}
The return type of this log replay function closely corresponds to C data structures, which makes it easy to prove the refinement. (\code{ZMap} is a finite map from \code{Z} to \code{bool*Z}.)
The second ingredient is a relation $R_{\codeinmath{MMCSLockIntro}}$ which shows the relationship between the concrete memory in underlay $\codeinmath{MMCSBoot}$ and the abstract state in overlay $\codeinmath{MMCSLockIntro}$.
As a part of $R$, we define \code{match$\_$MCSLOCK}, which is a part related to 
the MCS lock in $R_{MCSLockIntro}$,  as follows:

\begin{definition}[\code{match$\_$MCSLOCK}]
Suppose that `\code{loc}' is among the proper field accessors for the MCS Lock, which are
`\code{last}', `\code{ndpool[$i$].next}', or  `\code{ndpool[$i$].busy}' when `$0 \leq i <$  \code{TOTAL$\_$CPU}'.
 And, assuming that `\code{lk\_id}' is a lock identifier satisfies `$0 \leq$ \code{lk\_id} $<$ \code{lock$\_$range}' and \code{l} is a shared log. Then define \newline
  \begin{tabular}{P{0.90\textwidth}}
    \code{match$\_$MCSLOCK (l:Log) (b:block) loc}\\
    %$\forall$ \code{(l: Log) (b: block) lk_id loc,}\\
      iff \code{(}$\exists$ \code{val}, \code{Mem.load Mint32 m b loc=Some(val)}\\
       $\wedge$  \code{Mem.valid$\_$access m b loc}\\
      $\wedge$ \code{(CalMCSLock(l)=Some(mcsval)} $\rightarrow$ \code{loc$_{a}$}\code{@mcsval = val})
\end{tabular}\newline
    when `\code{loc$_{a}$}\code{@mcsval}' represents the corresponding 
    value to the `\code{loc$_{a}$}' in the `\code{mcsval}' 
    and `\code{loc$_{a}$}' corresponds to the value of `\code{loc}'.
\end{definition}

Intuitively, the definition says that the value that
\code{CalMCSLock} calculates from the log always corresponds to the value 
in the memory with the same identifiers. The memory access functions \code{Mem.load} and \code{Mem.valid$\_$access} are
from $\compcert$'s operational semantics for C.
Using the definition, we prove one theorem for each primitive, which
shows that the memory refines the shared log. E.g., for \code{mcs$\_$SET$\_$NEXT} we prove:

\jieung{Need to modify the following theorem. The current notations are not quite correct}
\begin{theorem}[Simulation for $\codeinmath{{mcs}}\_\codeinmath{{SET}}\_\codeinmath{{NEXT}}$]
    \label{thm:chapter:mcslock:machine-state-refinement} Let $R_{\codeinmath{MMCSLockIntro}}$ be the relation defined as \code{match$\_$MCSLOCK}
    over \code{LK@}$mem$ and \code{LOG@}$A_1$, 
identity relation for other parts of $mem$, $A_0$ and $A_1$. Then\newline
 \begin{tabular}{P{0.95\textwidth}}
$ \forall (\codeinmath{{m}}_{1} \ \codeinmath{{m}}_{1}'\ \codeinmath{{m}}_{0} : mem)\  (\codeinmath{{d}}_{0} \ : A_0)\ (\codeinmath{{d}}_{1} \ \codeinmath{{d}}_{1}' : A_1),$ \\
$ \mbox{if } \codeinmath{{mcs\_SET\_NEXT}}_{L_1}(v, \codeinmath{{m}}_1, \codeinmath{{d}}_1) = \codeinmath{{Some}}(\codeinmath{{m}}'_1, \codeinmath{{d}}'_1) \mbox{ and }
  R_{\codeinmath{MMCSLockIntro}}\ (\codeinmath{{m}}_1, \codeinmath{{d}}_1)\ (\codeinmath{{m}}_0, \codeinmath{{d}}_0),$\\
  $ \mbox{ then there exists } (\codeinmath{{m}}_{0}' : mem)\ (\codeinmath{{d}}_{0}' : A_0), \mbox{ such that}$\\
$  \codeinmath{{mcs\_SET\_NEXT}}_{L_0}(v, \codeinmath{{m}}_0, \codeinmath{{d}}_0) = \codeinmath{{Some}}(\codeinmath{{m}}'_0, \codeinmath{{d}}'_0) \mbox{ and}
  R_{\codeinmath{MMCSLockIntro}}\ (\codeinmath{{m}}'_1, \codeinmath{{d}}'_1)\ (\codeinmath{{m}}'_0, \codeinmath{{d}}'_0).$ 
   \end{tabular}
\end{theorem}


 \begin{theorem}[Machine State Refinement]
 \label{thm:chapter:mcslock:machine-state-refinement-full} Let's assume the following conditions:\newline
\begin{tabular}{ll}
1)&\code{MMCSBoot} and\code{MMCSLockIntro} are underlay and overlay layers;\\
2)&$mem_{\codeinmath{MMCSBoot}}$ and $mem_{\codeinmath{MMCSLockIntro}}$ are memories for \code{MMCSBoot} and \code{MMCSLockIntro};\\
3& and, $A_{\codeinmath{MMCSBoot}}$ and $A_{\codeinmath{MMCSLockIntro}}$ are abstract datum for  \code{MMCSBoot} and \code{MMCSLockIntro},\\ &respectively.
\end{tabular}\newline
    With the given $R_{\codeinmath{MMCSLockIntro}}$, defined as \code{match\_MCSLOCK} 
     over \code{MCS$\_$LOC} in the underlay layer  (\ie, \code{MCS$\_$LOC@}$mem_{\codeinmath{MMCSBoot}}$) and 
the log in the overlay layer (\ie, \code{LOG@}$A_{\codeinmath{MMCSLockIntro}}$), 
 identity relation for other parts of $mem_{\codeinmath{MMCSBoot}}$ and $mem_{\codeinmath{MMCSLockIntro}}$, and $A_{\codeinmath{MMCSBoot}}$ and $A_{\codeinmath{MMCSLockIntro}}$, 
 The specification for the function $f$, $\sigma_f$, in $\codeinmath{MMCSLockIntro}$ refines that in $\codeinmath{MMCSBoot}$ when:
 \begin{center}
 \begin{tabular}{P{0.95\textwidth}}
     $\forall ($\code{m}$_{0} \ $\code{m}$_{0}' : mem_{\codeinmath{MMCSBoot}})\ ($\code{m}$_{1} \ $\code{m}$_{1}' : mem_{\codeinmath{MMCSLockIntro}})
      ($\code{s}$_{0} \ $\code{s}$_{0}' : A_{\codeinmath{MMCSBoot}})\ ($\code{s}$_{1} \ $\code{s}$_{1}' : A_{\codeinmath{MMCSLockIntro}}),$\\
     $(L_{\codeinmath{MMCSBoot}} \vdash \sigma_f : (\_, $\code{m}$_0, $\code{s}$_0) \rightarrow (\_, $\code{m}$_0', $\code{s}$_0')) \wedge\
     (L_{\codeinmath{MMCSLockIntro}} \vdash \sigma_f : (\_, $\code{m}$_1, $\code{s}$_1) \rightarrow (\_, $\code{m}$_1', $\code{s}$_1')) \wedge$\\
     $(R_{{\codeinmath{MMCSLockIntro}}}\ ($\code{m}$_1, $\code{s}$_1)\ ($\code{m}$_0, $\code{s}$_0) \rightarrow R_{{\codeinmath{MMCSLockIntro}}}\ ($\code{m}$_1', $\code{s}$_1')\ ($\code{m}$_0', $\code{s}$_0'))$\\
 \end{tabular}
 \end{center}
 \end{theorem}

%
%The log in $adt$, however, requires the way to infer the current state about the shared object. 
%To do that, log replay functions are introduced to interpret the current state with the given shared log.
%Those functions gets the well-formed shared log and returns the value of the defined data structure that can represent the current state.
%
%For several purpose, we have introduced three log replay functions during the verification. 
%First, \code{CalMCSLock} is the replay function that we have used until we show the functional correctness. 
%The next one, \code{QS$\_$CalLock} evaluates the shared log and establish the queue data structure to show the FIFO and starvation freedom properties of the MCS Lock. 
%The last log replay function is \code{H$\_$CalLock}, which can be used after we wrapped the all the lock acquire and release events as one events. 
%Those functions essentially have the same meaning with the well-formed shared log inputs, but we always have to show that the result generated by those log replay functions are satisfied by refinement relationship. 
%To do them, we have introduced logical layers.
%Figure~\ref{fig:chapter:mcslock:layer-struct-mcs-verification} (b) shows the example of building a logical layer.
%In the layer, no additional primitives are introduced, but the we have proved that the new abstract state in the {\em overlay} layer generated by the new replay function refines the abstract state in the {\em underlay} layer with the previous replay function.

One interesting variation is the semantics
for fetch-and-store and compare-and-swap. These instructions are not
formalized in the x86 assembly semantics we use, so we cannot prove
that replay function is correctly defined. Instead we modify the last
(``pretty-printing'') phase of the compiler so that these primitive calls map to assembly
instructions, and one has to trust that they match the specification.

\subsection{Event interleaving layer}
\label{chapter:mcslock:subsec:abstractoperationlayer}

After abstracting memory accesses into the operation on the log, we
then need to model possible interleaving among multiple CPUs. In
our approach, this is done through a new layer which adds \emph{context queries}.

To recall what the environmental (concurrent context) is,
the concurrent context $\oracle_{mcs}$ (sometimes called the ``oracle'') is
a function of the CPU-id and the log which has the type\newline
\begin{tabular}{P{0.95\textwidth}}
    $\oracle_{mcs}: \codeinmath{Z}\rightarrow\codeinmath{list event}\rightarrow \codeinmath{list event}.$\\
\end{tabular}\newline
It is one component of the abstract state in our implementation, and it represents the specific behavior of \emph{all
the other CPUs}, from the perspective of code running on the current
CPU.  Any time a program does an operation which reads or writes
shared memory, it should first query $\oracle_{mcs}$ by giving it the
current log. The oracle will reply with a list of events that other
CPUs have generated since then, and we update the log by appending
those new events to it.

Primitive specifications are provided read-only access to a context
$\oracle_{mcs}$ by the verification framework, and the framework also
guarantees that two properties are true of $\oracle_{mcs}$: 1) the returned
partial log from the oracle query does not contain any events
generated by the given CPU ID; and 2) if we query the oracle with the
well-formed shared log, the updated log after the oracle query will
be well-formed.
The first assumption is straightforward because the purpose of the oracle is to represent the behavior of others' operation on the shared object.
The second one is also trivial when we prove 1) the initial shared log satisfy the well-formed condition, and 2) all the operations on the shared object with the given well-formed log return a well-formed shared log.
Those two assumptions, however, do not reduce the generality of the oracle, and the oracle can capture the proper interleaving that we hope to achieve in the MCS Lock verification.

Similar to Section~\ref{chapter:mcslock:subsec:lowestmachinemodel}, 
we provide primitives in $L_{\codeinmath{MMCSBoot}}$ which query $\oracle_{mcs}$ and extend the log.
Then in this second layer, we can model abstract operations with interleaving.
For example, \code{mcs$\_$SET$\_$NEXT} can be re-written as
\lstinputlisting [language = Caml] {source_code/mcslock/mcs_set_next_low_charac.c}
by using the logical primitive which corresponds to the oracle query
(The function \code{mcs$\_$log} refines the semantics of \code{atomic$\_$mcs$\_$log} in the lowest layer by the \code{match$\_$MCSLOCK} relation).
To model the interleaving, all the setter and getter functions defined
in Section~\ref{chapter:mcslock:subsec:lowestmachinemodel} should be combined with the
oracle query.

\paragraph{Trust in the machine model}
Some of the design decisions in the memory access
layers have to be trusted, so the division between machine model and
implementation is unfortunately slightly blurred.
Ideally, we would have a generic machine model as proposed in Section~\ref{chapter:ccal:sec:interface-calculus}, where memory is partitioned into thread-local
memory (no events), lock-protected memory (accesses generate $\push$/$\pull$
events), and atomic memories (each access
generates one \code{READ}/\code{WRITE}/\code{SWAP}/etc event).  However, our starting point
is the $\compcert$ $\intelmachine$ semantics, which was designed for single-threaded
programs, and does not come with a log, so we add a log and memory access
primitives ourselves.
But because the spinlock module is the only code in the OS that uses
atomic memory, we do not add a generic operation called
read\_word etc. Instead we take a short-cut and specify the particular
6 memory accesses that the lock code uses: \code{mcs$\_$get$\_$next} etc.
For these procedures to correctly express the intended semantics,
there are two trusted parts we must take care to get right. First,
each access to non-thread-local memory must generate an event, so we
must not forget the call to
\code{mcs$\_$SET$\_$NEXT$\_$log}. 
Second, to account for
interleavings between CPUs (and not accidentally assume that consecutive
operations execute atomically) we must not forget the call to
\code{mcs$\_$log} after each access.


\subsection{Low-level functional specification}
\label{chapter:mcslock:subsec:atomicoperation}

Using the primitives that we have defined in lower layers, we prove the correctness of lock acquire, \code{mcs$\_$acquire}, and release, \code{mcs$\_$release}.
The target code in this layer is identical to the code in Figure~\ref{fig:chapter:mcslock:mcs_lock} except two aspects. 
First, we replaced all operations on memory with the getters and setters described in Section~\ref{chapter:mcslock:subsec:abstractoperationlayer}.
Second, \code{mcs$\_$acquire} has one more
 argument, which is the bound number for the client code of the lock.

Since the functions defined in
Section~\ref{chapter:mcslock:subsec:abstractoperationlayer} already abstract interleaving
of multiple CPUs, the proofs in this layers work just like sequential
code verification. We find out the machine state after the function
call by applying the C operational semantics to our function
implementation, and check that it is equal to the desired state
defined in our specification.

However, writing the specifications for these functions is slightly subtle, 
because they contain
while-loops without any obviously decreasing numbers. Since our
specifications are $\coq$ functions we need to model this by structural
recursion, in some way that later will let us show the loop is terminating.
So to define the semantics of \code{mcs$\_$wait$\_$lock},
we define an auxiliary function
\code{CalMCS$\_$AcqWait} which describes the
behavior of the first $n$ iterations of the loop: each iteration
queries the the environment context $\oracle_{mcs}$, replays the log to see if if \code{busy} is now \code{false}, and appends a \code{GET\_BUSY} event.
If we do not succeed within $n$ iterations the function is undefined ($\coq$ \code{None}).
Then, in the part of the  specification for the  acquire lock 
function (\code{CalMCS$\_$AcqWait}) where we need to talk about the while loop,
we say that it loops for some ``sufficiently large'' 
number of iterations \code{CalWaitLockTime tq}. 
\lstinputlisting[language = Caml]{source_code/mcslock/waitlockloop.v}
The function \code{CalWaitLockTime} computes a suitable 
number of loop iterations based on \code{tq}, the time-bounds  which each of the queuing CPUs promised to respect.
We will show how it is defined in Section~\ref{chapter:mcslock:sec:liveness-atomicity}. 
However, in \emph{this part} of the proof, the definition doesn't matter. 
Computations where $n$ reaches 0 are considered crashing, and our
ultimate theorem is about safe programs, so when proving that the C
code matches the specification we only need to 
consider cases when \code{CalMCS$\_$AcqWait} returned \code{(Some l)}.
It is easy to show in a downward simulation that the C loop can match any such finite run, 
since the C loop can run any number of times.

\subsection{Data representation and ghost state}
\label{chapter:mcslock:sec:representation-ghost}

From here on, we never have to think about C programs again.  All the
subsequent reasoning is done on $\coq$ functions manipulating ordinary
$\coq$ data types, such as lists, finite maps, and unbounded integers.
Verifying functional programs written in $\coq$'s Gallina is exactly the
situation $\coq$ was designed to deal with. However, the data computed
by the replay function in in the previous layer still corresponds
exactly to the array-of-structs that represents the state of the lock
in memory.
In particular, the intuitive reason that the algorithm is fair is that
each CPU has to wait in a queue, but this conceptual queue is not identical with
the linked-list in memory, because the next-pointers may not be set.

In order to keep the data-representation and liveness concerns separate,
we introduce an intermediate layer, which keeps the same sequence of operations and same log of events, 
but manipulates an \emph{abstracted data representation}.
We provide a different replay function (\code{QS$\_$CalLock}) with the type \newline
\begin{tabular}{P{0.95\textwidth}}
\code{QS$\_$CalLock : Multi$\_$Log $\rightarrow$} \\
\code{option (nat * nat * head$\_$status * list Z * ZSet.t * list nat)}
\end{tabular}\newline
The tuple returned by this replay function provides the information we
need to prove liveness, 
similar to the concepts used in the informal
proof in Section~\ref{chapter:mcslock:sec:overview}. 
The meaning of a tuple \code{c1, c2, b, q, slow, t} is as follows:
\begin{itemize}
\item  \code{c1} and \code{c2} are upper bounds on how many more operations 
the CPU which currently holds the lock will generate as part of the critical section and of 
releasing the lock, respectively. They are purely logical ghost state but can be deduced from the complete
history of events in the system.

\item \code{b} is either  \code{LEMPTY} or \code{LHOLD}, 
the lock status of the head of the queue.
They are closely to $\push$/$\pull$ operations in our memory model discussed in Section~\ref{chapter:ccal:sec:interface-calculus}.
When the \code{b} value is $\code{LHOLD}$, this implies that one CPU already pulls the value for that shared memory block.
On the other hand, when \code{b} value is \code{LEMPTY}, no CPUs pull the value from the block, so the next CPU in the wait list 
can pull the block to enter the critical section.

\item \code{q} is the list of the CPUs currently waiting for the lock, 
and \code{t} is the list of bound numbers that 
corresponds to each element in \code{q}.

\item \code{slow} is a finite set which represents the subset of CPUs in \code{q} that have not yet executed their \emph{set next} operation.  
\end{itemize}
Our liveness proof is based on the fact that each CPU only needs to wait for CPUs that are ahead of it in \code{q}, which is the waiting queue that guarantees FIFO ordering.

Some of this information is implicit in the state of the memory, while some of it (for example \code{c1} and \code{c2}) is purely ghost state. But in any case, it can be deduced from the complete history of events in the system, which is what the replay function \code{QS$\_$calLock} does. We define it by recursion on the list \code{l}, computing the new state after each event. A few representative cases of the function are shown in Figure~\ref{fig:chapter:mcslock:QS_CalLock}.  For example, the event
\code{SET$\_$BUSY} indicates that a thread releases the lock. If the CPU $i$ is already the  front of the queue \code{q}, it currently holds the lock (\code{LHOLD}), and the bound \code{c2} has not yet reached zero, and $i$ is not slow, then generating this event will reset the lock status to \code{LEMPTY} and remove the head element ($i$) from \code{q} and \code{t}. In any of those side conditions are not satisfied, on the other hand, the replay function is undefined (\code{None}). Similar
considerations hold executing memory operations (you must be in the critical section, and it decrements \code{c1}) and querying the busy flag (you must have executed \code{SET$\_$NEXT} first).

\begin{figure}
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/midlogreplay_short.v}
    \caption{The replay function \code{QS$\_$CalLock}}
\label{fig:chapter:mcslock:QS_CalLock}
\end{figure}


\paragraph*{Invariant} The replay function plays two different roles. When it returns \code{Some v}, for some tuple \code{v}, it describes what the current state of the system is, which lets us write the specifications for the primitives. At the same time, the cases where the function is defined to return \code{None} are also important, because this can be read as a description of events that are \emph{not} possible. For example, from inspecting the program, we know that each CPU will create
exactly one \code{SET$\_$NEXT} event before it starts generating \code{GET$\_$BUSY} events, and this fact will be needed when doing the proofs in the later layers (Section~\ref{chapter:mcslock:sec:liveness-atomicity}). By taking advantage of  the side conditions in the replay function, we can express all the invariants about the log in a single statement, ``the replay function is defined'':\newline
\begin{tabular}{P{0.95\textwidth}}
    $\exists$ \code{c1 c2 b q s t$.$ QS$\_$CalLock(l)=Some(c1, c2, b, q, s, t)}
\end{tabular}

This type for the replay function is optimized to only expose exactly the information needed by the subsequent liveness proof. 
We need to expose the queue and the set of slow CPUs in order to define the termination measure $\codeinmath{Msr}$
 (Section \ref{chapter:mcslock:sec:liveness-atomicity}). 
 On the other hand, this is not enough information to bridge the gap from the low-level functional specification. 
 In order to show that the memory cells for a valid linked-list and therefore respects the queue
ordering, we need to track exactly what the valid state transitions are. So inside the ghost state layer, 
we also introduce a different relation  \code{Q$\_$CalMCSLock} 
which is mostly the same as \code{QS$\_$CalLock} but written as an (functional) inductive relation 
in $\coq$ instead of a recursive function, and which has even more preconditions for when it is defined. 
We then add one more condition in the layer invariant saying that \code{Q$\_$CalMCSLock} and \code{QS$\_$CalLock} output the same
result. Most of the proofs inside the ghost layer are done using the relation instead of the function.
For simplicity, we will ignore the distinction in the rest of the paper, 
and write the lemma statements about \code{QS$\_$CalLock} even if they used \code{Q$\_$CalMCSLock} in the actual $\coq$ code.


To show that the ghost layer refines the previous layer, we show a
one-step forward-downward refinement: if the method from the higher
layer returns, then method in the lower layer returns a related
value. For this particular layer the log doesn't change, so the
relation in the refinement is just equality (including the relation for the global log and the environmental context ($\oracle_{mcs}$) -- \ie, the relation for the strategies in the $\oracle_{mcs}$), 
and the programmer just
has to show that the lower-level methods are at least as defined and
that they return equal results for equal arguments.


As we prove this, we need lemmas to show that we can satisfy the preconditions for the operations in the lower layer, by relating the data in \code{la} to the abstract queue.  For example, when trying to take the lock, the high level specification checks if the current CPU is at the head of \code{q}, which the low specification tests if the \code{busy} field is true, so we need Lemma~\ref{lem:chapter:mcslock:Q_CalMCSLock_tail_is_busy} to show that they will follow the same path of code. 


\begin{lemma}[tail is busy]
\label{lem:chapter:mcslock:Q_CalMCSLock_tail_is_busy}

    If \code{CalMCSLock l=Some (tl,la,tq)} and 
    \code{QS$\_$CalLock=Some (c1,c2,i::q,s,t)} and $j \in$\code{q}, then \code{lock$\_$array[}$j$\code{] = (true, $\_$)}.
\end{lemma}

\begin{theorem}[simulation for the ghost layer] 
    Let's assume that  \code{d} satisfies the invariant of two layers,
    \code{MMCSLockOp} and \code{MQMCSLockOp}. When 
\code{wait$\_$qslock$\_$spec(d)=Some(d')}, then \code{mcs$\_$acquire$\_$spec(d)=Some(d')}.
\end{theorem}


\subsection{Liveness and atomicity}
\label{chapter:mcslock:sec:liveness-atomicity}

The specification in the previous section is still too low-level and
complex to be usable by client code in the rest of the system.  First,
the specification of the \code{mcs$\_$acquire} and
\code{mcs$\_$release} primitives contain loops, with complicated
bounds on the number of iterations, which clients certainly will not
want to reason directly about.  More importantly, since the
specifications generate multiple events, clients would have to show
all interleavings generate equivalent results.

To solve this we use the \textit{log-lift} design
pattern in Section~\ref{chapter:ccal:subsec:local-layer-interface}; build a new layer with \emph{atomic specifications},
\ie, each primitive is specified to generate  a single event.
For an atomic layer there is a
therefore a one-to-one mapping between events and primitives, and the global log
can be seen as a record of which primitives were invoked in which
order. Thus, the refinement proof which ascribes an atomic
specification proves once and for all that overlapping and interleaved
primitive invocations give correct results.
In this layer, the specifications only use three kinds 
of events: taking the lock (\code{WAIT$\_$LOCK n}),
releasing it (\code{PASS$\_$LOCK}), and modifications of the shared
memory that the lock protects (\code{TSHARED $\_$}).



\begin{figure}
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/highlogreplay.v}
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/hswaitlockspec.v}
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/hspasslockspec.v}
\caption{The final, atomic, specification of the aquire lock function and the release lock function.}
\label{fig:chapter:mcslock:hswaitlockspec}
\end{figure}

Figure~\ref{fig:chapter:mcslock:hswaitlockspec} shows the final specification for 
wait and pass primitives. We show this one in full detail, with no elisions,
because this is the interface that clients use. First, the
specification for the lock acquire function itself
(\code{mcs$\_$wait$\_$hlock$\_$spec}) takes the function arguments
\code{bound}, \code{index}, \code{ofs}, and maps an
abstract state (\code{RData}) to another. When writing this
specification we chose to use two components in the abstract state, the
log (\code{multi$\_$log}) and also a field (\code{lock}) which
records for each numbered lock if it is free (\code{LockFalse})
or owned by a CPU (\code{LockOwn false}). 
The boolean value in (\code{LockOwn $\_$}) indicates whether copied/flushed the shared memory value to/from the local memory for the CPU or not.
The \code{false} value in (\code{mcs$\_$wait$\_$hlock$\_$spec} implies that the CPU already hold the lock but does not pull the shared memory by using the $\pull$ operation yet. 
On the other hand, the  \code{false} value   in (\code{mcs$\_$pass$\_$hlock$\_$spec} implies that the $\push$ primitive has been invoked already 
to flush the local change to the shared memory, but the CPU still owns the lock.
The \code{lock} field is
not very important, because the same information can also be computed
from the log, but exposing it directly to clients is sometimes more
convenient.

The specification returns \code{None} in some
cases, and it is the
responsibility of the client to ensure  that does not
happen. So clients must ensure that: the CPU is in kernel/host
mode (for the memory accesses to work); the index/offset (used to
compute the lock id) are in range; the CPU did not already hold the
lock (\code{LockFalse}); and the log is well-formed
(\code{H$\_$CalLock l'} is defined, which will always be the case if
\code{H$\_$CalLock l} is defined).  When all these preconditions are
satisfied, the specification queries the context once, and appends a
single new \code{WAIT$\_$LOCK} event to the log.
Figure~\ref{fig:chapter:mcslock:hswaitlockspec} also shows the replay function
\code{H$\_$CalLock}.
It has a much simpler type than \code{QS$\_$CalLock} in the
previous layer, because we have abstracted the internal state of the lock
to just whether it is free (\code{LEMPTY}),
held (\code{LHOLD}), and if taken, the CPU id (\code{Some $i$})
of the holder of the lock. Unlike the three bound numbers in the
previous layer, here we omit the numbers for the internal lock
operations and only keep the bound \code{self$\_$c} for the number
of events generated during the critical section. Again, it's the
client's responsibility to avoid the cases when \code{H$\_$CalLock}
returns \code{None}. In particular, it is only allowed to release
the lock or to generate memory events if it already holds the lock
(\code{zeq $i$ $i0$}), and each memory event decrements the counter,
which must not reach zero. The client calling \code{wait$\_$lock}
specifies the initial value $n$ of the counter, promising to take at
most $n$ actions within the critical section.


In the rest of the section, we show how to prove that the function
does in fact satisfy this high-level atomic specification.
Unlike the previous layers we considered, in this case the log in the
upper layer differs from the one in the lower layer. For example, when
a CPU takes the lock, the log in the upper layer just has the one
atomic event (\code{WAIT$\_$LOCK $n$}), while the log in the underlay
has a flurry of activity (swap the tail pointer, set the next-pointer,
repeatedly query the busy-flag).
Because the log represents shared data, our framework requires a
slightly strengthened refinement theorem for the log-component of the
state. Usually a refinement simulation works by specifying some
relation $R_{\codeinmath{MHMCSLockOp}}$ between machine state and abstract state, and then
proving that the state transitions preserve the relation. Indeed, for
thread-local data this is exactly what CertiKOS does also.

Let's recall the contextual refinement property in Definition~\ref{def:chapter:ccal:contextual-refinement}. 
This relation  $R_{\codeinmath{MHMCSLockOp}}$ must includes the relation in between 
two strategies of that two layers are relying on; 
thus the relation for two different environmental contexts, which are $\oracle_{lock}$ for \code{MHMCSLockOp} and $\oracle_{mcs}$ for \code{MQMCSLockOp}.
For example, suppose one particular
execution of the system generates the log $\codeinmath{l}_{\codeinmath{MQMCSLockOp}}$.  A normal simulation
theorem for CPU 1 would tell us that there \emph{exists} a log \code{l$_H$}
that meets CPU 1's local specification and satisfies the relation
($R_{\strat{\codeinmath{MHMCSLockOp}}, \strat{\codeinmath{MQMCSLockOp}}}$). 
Similarly, the local proof for CPU 2 would say there
exists some log \code{l'}$_{\codeinmath{MHMCSLockOp}}$. But in order to derive a simulation for the
entire system, we need the constraint that that \code{l}$_{\codeinmath{MHMCSLockOp}}$  is equal to
\code{l'}$_{\codeinmath{MHMCSLockOp}}$. The actual definition of the relation is by defining the proper function $f_{mcslog}$ between two logs.
In other words, when proving the simulation,
we find a function $f_{mcslog}$ for the logs, such that $f_{mcslog}(\codeinmath{l}_{\codeinmath{MQMCSLockOp}}) = \codeinmath{l}_{\codeinmath{MQMCSLockOp}}$.


As for the MCS Lock, we define a function \code{relate$\_$mcs$\_$log} from the
implementation log to the atomic log. Figure~\ref{fig:chapter:mcslock:logsequence}
shows by example what it does. It keeps the shared memory events as
they are, discards the events that are generated while a CPU wait for
the lock, and maps just the event that finally takes or releases the
lock into \code{WAIT$\_$LOCK} and \code{REL$\_$LCOK}.
\begin{figure*}
\includegraphics[width=\textwidth]{figs/mcslock/logsequence}
\caption{Log Sequence and Log Refinement Example}
\label{fig:chapter:mcslock:logsequence}
\end{figure*}

We then prove a one-step refinement theorem from the atomic specification 
to the implementation, in other words, that if a call to the atomic primitive returns a 
value, then a call to its implementation also returns with a related log:

\jieung{Let's simplify this theorem by simplify notations}
\begin{theorem}[MCS Wait Lock Exist]
  \label{thm:chapter:mcslock:mcs_wait_lock_exist}

  Suppose $\codeinmath{{d}}_{\codeinmath{{MHMCSLockOp}}}$ and $\codeinmath{{d}}_{\codeinmath{{MQMCSLockOp}}}$ satisfy the layer
  invariants and are related by\\
   $\codeinmath{{relate\_mcs\_log}}(\codeinmath{{d}}_{\codeinmath{{{MQMCSLockOp}}}}) = 
  \codeinmath{{d}}_{\codeinmath{{MHMCSLockOp}}}$.\\
If $\codeinmath{{wait\_hlock\_spec}}(\codeinmath{{d}}_{\codeinmath{{MHMCSLockOp}}}) = \codeinmath{{Some}}(\codeinmath{{d}}'_{\codeinmath{{MHMCSLockOp}}})$, then there exists some $\codeinmath{{d}}'_{\codeinmath{{MQMCSLockOp}}}$\\
  which is $\codeinmath{{wait\_qslock\_spec}}(\codeinmath{{d}}_{\codeinmath{{MQMCSLockOp}}}) = \codeinmath{{d}}'_{\codeinmath{{MQMCSLockOp}}}$ and is related with $\codeinmath{{d}}'_{\codeinmath{{MHMCSLockOp}}}$
   by\\
 $\codeinmath{{relate\_mcs\_log}}(\codeinmath{{d}}'_{\codeinmath{{MQMCSLockOp}}}) = \codeinmath{{d}}'_{\codeinmath{{MHMCSLockOp}}}$.

\end{theorem}

The proof  requires a \emph{fairness assumption}.
A CPU cannot take the lock until the previous CPU releases it, 
and the previous CPU cannot release it if it never gets to run. 
At its most fundamental, the $\certikos$ machine model is a nondeterministic 
transition system (which is subsequently viewed as a log of events), 
and there is nothing in the basic model that ensures fairness, 
so we have to add an extra assumption somewhere. In principle it would be 
possible to modify the machine model itself, and then pass the fairness assumptions 
along in the specification of each layer until we reach the layers related to mutex locks, 
but in our development we choose a more expedient solution, and express
the fairness assumption as an extra axiom talking about the logs 
in the data representation layer (Section~\ref{chapter:mcslock:sec:representation-ghost}). 
By doing that, our framework can use the previous machine 
model as it is, and can reuse most previous proofs.

Specifically, we assume that there exists some constant $F$ (for ``fairness'') such that no CPU that enters the queue has to wait for more than $F$ events until it runs again. 
In $\coq$ we provide a function \code{CalBoun} which ``counts down'' 
until CPU $i$ gets a chance to 
execute (\code{CalBound : Z$\rightarrow$MultiLog$\rightarrow$nat}).
\lstinputlisting [language = Caml, firstline=1] {source_code/mcslock/calbound.v}

The fairness assumption, then is that for all logs \code{l}, 
when the low level log replay function returns a 
value (\code{QS$\_$CalLock(l)=Some(c1,c2,h,q,s,t)}) and $j$ is 
in the waiting queue (\code{$j \in$q}), then we can conclude that \code{CalBound $j$ l$>$0}. 
We then define a natural-number valued termination measure \code{Msr$_i$(c1,c2,h,q,s,l)}.  
This is a bound on how many events the CPU $i$ will
have to wait for in a state represented by the log \code{l}, and where
\code{QS$\_$CalLock(l)=Some(c1,c2,h,q++$i$::q$_0$,s,t++n::t$_0$)}.
Note that
we partition the waiting queue into two parts \code{q} 
and \code{$i$::q$_0$}, where \code{q}
represents the waiting CPUs that were ahead of $i$ in the queue.
The function $\codeinmath{Msr}$ has two cases that depend on the head status.

\begin{tabular}{p{0.9\linewidth}}
\code{Msr$_i$(c1,c2,LEMPTY,q,s,l)=CalBound$_{\mathsf{hd}(q)}$(l)+($K_1$($\Sigma$t)+$|$q$\cup$s$|$)$\times K_2$)}\\
\code{Msr$_i$(c1,c2,LHOLD,q,s,l)=CalBound$_{\mathsf{hd}(q)}$(l)+BoundValAux$\times K_2$} \\
\hfill	 where \code{BoundValAux=(c1+c2+($\Sigma$($\mathsf{tl}$(t))$\times K_1$+$|\mathsf{tl}$(q)$\cup$s$|$)}\\
\end{tabular}

In short, if the lock is not taken, the bound $\codeinmath{Msr}$ is the sum of the
maximum time until the first thread in the queue gets scheduled again
(\code{CalBound$_{\mathsf{hd}(q)}$(l))}, plus a constant times
the sum of the number of operations to be done
by the CPUs ahead of $i$ in the queue (\code{$\Sigma$t}) 
and the number of CPUs ahead of $i$ which has
yet to execute $\SETNEXT$ operation 
\code{($|$q$\cup$s$|$)}. If the lock is currently
held, then \code{c1+c2} is a bound of the number of operations it will
do
(and we can ignore the first element of \code{q} and \code{t}, since they are
accounted for).
The constants and fairness assumption is general enough to handle the cases which takes a slightly longer execution than it is expected to.
The constants ($K_1 = F+5$ and $K_2 = F+4$) are chosen somewhat
arbitrary, and certainly $\codeinmath{Msr}$ is not the tightest possible bound. It
does not need to be, since it does not occur in our final theorem
statement.

The definition of $\codeinmath{Msr}$ is justified by the following two
lemmas. First, we prove that M decreases if CPU $i$ is waiting and some other CPU
$j$ executes an event \code{e$_j$}.

\begin{lemma}[Decreasing measure for other CPUs]
\label{lem:chapter:mcslock:MCS_CalLock_progress_onestep}
Assuming that \code{QS$\_$CalLock(l)=Some(c1,c2,h,q$_1$++$i$::q$_2$,s,t$_1$++c::t$_2$)}, where
\code{$|$q$_1|$=$|$t$_1|$} and \code{QS$\_$CalLock(e$_j$::l)=Some(c1',c2',h',q',s',t')} 
for some $j\neq i$ and
 \code{CalBound(e$_j$::l)$>$0} .
Then we can split 
\code{$M_i$(c1',c2',h',q$_{1}$',s',t$_{1}$',e$_j$::l)$<$Msr$_i$(c1,c2,h,q$_1$,s,t$_1$,l)}
and\\ \code{q'=q$_{1}$'++$i$::q$_{2}$'}.
\end{lemma}

\begin{proof}
 We consider all possible events
\code{e$_j$} which could make \code{QS$\_$CalLock} return \code{Some}. If $j$ is not the 
CPU at the head of the queue gets scheduled, it will not be
able to make any progress, so the abstract state of the queue remains the same,
but the counter \code{CalBound} decreases.
Otherwise, the counter \code{CalBound} will reset to the upper bound we assumed on fairness, $F$. 
However, in this case the algorithm will make some progress that changes \code{c1}, \code{c2}, \code{q}, or \code{s}.
For example, CPU $j$ may execute a $\SETNEXT$ (which decreases the size of
\code{s}), it may enter the critical section (which moves some measure from
the head of \code{q} to the counters \code{c1+c2}) or it may exit the section
(and that event will decrement \code{c2}).
\end{proof}


The second lemma ensures that the waiting loop will eventually
terminate (The preconditions that $i$ is somewhere in the waiting queue,
and that it has already left the set \code{s}, correspond the set-up
which \code{wait$\_$lock} does before it starts looping).

\begin{lemma}[Loop termination]
\label{lem:chapter:mcslock:CalWaitGet_exist'}
Let's assume that \code{QS$\_$CalLock(l)=Some(c1,c2,h,q$_1$++$i$::q$_2$,s,t$_1$++c::t$_2$)}, where
\code{$|$q$_1|=|$t$_1|$}, with \code{$i \not\in$q$_1$} and \code{$i \not\in$s} and suppose $\oracle_{mcs}$ and $\oracle_{lock}$  are valid
contexts (which are matched by the relation based on the function $f_{mcslock}$.) Then, if \code{$k$>Msr$_i$(c1,c2,h,q$_1$,s,t$_1$)}; thus there exists \code{l'} such
that \code{CalWaitGet($k$,$i$,l)=Some(l')}
\end{lemma}


\begin{proof}
The proof is by induction on $k$, the number of loop iterations. The
most interesting part of the proof is to show that each event
generated by the function will decrease the measure.
As it pulls more event to the log form the context, we appeal to
Lemma~\ref{lem:chapter:mcslock:MCS_CalLock_progress_onestep}, which says that the metric decreases. 
Then, there are two cases in the proof depending on whether $i$ has
arrived at the head of the queue (so \code{q = nil}) or not. If it has,
\code{wait$\_$qslock$\_$spec} will generate a \code{GET$\_$BUSY false}
even and return, so we are good. 
Otherwise, it will generate a \code{GET$\_$BUSY true} event, and
start another loop iteration. That event does not change the state of
the lock, but it does decrement the $\CalBound$ on when the head CPU
will get scheduled next, so the measure decreases as required.
\end{proof}

To prove the termination of the loop in \code{wait$\_$qslock$\_$spec}, 
we also need to show that the busy-loop in \code{pass$\_$qslock$\_$spec} terminates, 
but that proof is easier. A CPU holding the lock will set
the next pointer before it does anything else, so we are only waiting
for the CPU at the head of the queue to get scheduled at all.
Now, to prove that the loop in \code{mcs$\_$acquire} specification
is defined, we just have to pick the function \code{CalWaitLockTime}
so that \code{CalWaitLockTime(t)} is greater than $\codeinmath{Msr}$ at that
point. The rest of the simulation proof for Theorem~\ref{thm:chapter:mcslock:mcs_wait_lock_exist} is straightforward.
Except the waiting loop, other operations in the wait lock function are deterministic and finite. 


\begin{theorem}
There is a one-step simulation from \code{mcs$\_$wait$\_$hslock$\_$spec} to
\code{mcs$\_$wait$\_$qslock$\_$spec}, with the simulation on logs given by \code{relate$\_$mcs$\_$log}.
\end{theorem}


\subsection{From downwards- to upwards-simulation}
\label{chapter:mcslock:sec:downwards-to-upwards}

When moving from sequential to concurrent programs we must
re-visit some fundamental facts about refinement proofs.  Ultimately,
the correctness theorem we want to prove is ``all behaviors of the
machine satisfy the specification''. If we model the machine and the
specification as two transition systems $\codeinmath{M}$ and $\codeinmath{S}$, then this
corresponds to \emph{upwards simulation}: if $\codeinmath{S} \sim \codeinmath{M}$ and 
$\codeinmath{M} \Longrightarrow^* \codeinmath{M}'$, then $\exists \codeinmath{S}'. \codeinmath{S}' \sim \codeinmath{M}'$ and
 $\codeinmath{S} \Longrightarrow^* \codeinmath{S}'$, and if $\codeinmath{M}$ is stuck then $\codeinmath{S}$ is stuck also.
But directly proving an upwards simulation is difficult. You are given
a long sequence of low-level steps, and have to somehow reconstruct
the high-level steps and high-level ghost state corresponding to
it. One of the insights that made the $\compcert$ project
possible~\cite{Leroy-backend} is that as long as $\codeinmath{M}$ is deterministic
and $\codeinmath{S}$ is not stuck, it suffices to prove a \emph{downward
  simulation}: if $\codeinmath{S} \sim \codeinmath{M}$ and $\codeinmath{S} \Longrightarrow \codeinmath{S}'$, then $\exists
\codeinmath{M}'. \codeinmath{S}' \sim \codeinmath{M}'$ and $\codeinmath{M} \Longrightarrow^* \codeinmath{M}'$. (The assumption that $\codeinmath{S}$
is not stuck is standard, it corresponds to only proving refinement
for ``safe'' clients regarding to the specifications.)

Unfortunately, concurrent programs are \emph{not} deterministic: we
want to prove that every interleaving of operations from
different CPUs in the low-level machine results in correct
behavior. So if we had directly modeled the implementation as a
nondeterministic transition system, then we would have to work
directly with upwards simulations, which would be intractable when
reasoning about the low-level details of C programs.

In our approach, all the nondeterminism is isolated to the concurrent
context $\oracle$. Any possible interleaving of the threads can be
modelled by initializing the abstract state with a particular
$\oracle_{mcs}$, and the execution proceeds deterministically from
there. Therefore we can still use the $\compcert$ method of first
proving a downward simulation and then concluding the existence of a
upward simulation as a corollary.
The context-formalism is also helpful because $\oracle_{mcs}$ contains
the entire execution of the other threads, both past and future, so we
have enough information to directly prove a \emph{forward}
simulation. Otherwise it may not be clear if a given low-level
operation can really ``commit'' (and generate a high-level event)
until we see what the other cores do, so proofs about fine-grained
concurrency can require a difficult backwards-simulation
from the end-state of the program.~\cite{DGLMQueue}

There is still an obligation to show that for every $\oracle_{mcs}$, there
in fact exists an $\oracle_{lock}$ with the right
properties. (Specifically, it should the always output logs which
respect the program invariants, \ie, the replay function is defined,
and also it should respect the refinement relation $f_{mcslock}$.) But this can
be managed by the framework in a generic way, which we discussed in Chapter~\ref{chapter:ccal}. When
verifying a particular layer, the programmer only needs to define $f_{mcslock}$.

