\section{Supporting Concurrency}
\label{chapter:ccal:sec:ccal-overview}

\subsection{Concurrent Layer with Environment}
\label{chapter:ccal:subsec:concurrent-layer-with-environment}

To support concurrency, 
we extend the layer definition in Chapter~\ref{chapter:ccal:sec:cal},
by parameterizing it with a set $A$, 
a focused set for the layer, which is always a subset of the set $D$ for all participants of the concurrent system (usually the set contains all CPUs/threads).
Then, the concurrent layer interface $L[A]$ is a state transition machine
that defines the execution for all members in $A$. 
Transitions of other members outside $A$  ($\forall \ i . \ i \in\ (D - A)$)
is treated as the environment of $L[A]$. 
In most circumstances, we only focus on a singleton set; 
thus we often abbreviate $L[\{i\}]$ as $L[i]$ where $i\in{}D$ for readability in those cases.

A concurrent layer interface also extends the representation of states and primitive specifications in $\calname$ to handle shared resources in the system. 
Instead of only having thread-local primitives and a private abstract state in $\calname$, 
a concurrent layer is extended adding abstract \textit{shared} primitives, 
and a global log. 
Previous thread local primitive (in $\calname$) calls are not observable by other threads; thus it only updates their private states (that are disjoint from other threads' private states) which are not visible from other threads. 
On the other hands, each shared primitive call and the related information (\ie, arguments passed to the call) 
need to be recorded as an event to the end of the global log that
is observable in all members of the system.

These newly added ingredients are core parts to form the operational semantics of a concurrent program 
\code{P} in a generic way with achieving  compositionality based on
ideas from game semantics~\cite{gsinvite}. 
In our semantics, 
each program execution of \code{P} over 
$L[D]$ is considered as a game play with all members of $D$ 
(and a scheduler for $D$ -- the key component to hide interleaving):
Each round play of each participant $i$ ($i\in{}D$) contributes the game 
by adding events into the global log $l$; its {\em strategy}
$\strat{i}$ is a deterministic partial function from
the current log $l$ to its next move $\strat{i}(l)$ whenever
the last event in $l$ transfers control back to $i$. 

\begin{figure}
\begin{center}
\includegraphics[scale=.8]{figs/ccal/faiexample}
\end{center}%
\caption{Game for Fetch-and-Increase Primitive Calls.}
\label{fig:chapter:ccal:game-for-fetch-and-increase-primitive-call}
\end{figure}

Figure~\ref{fig:chapter:ccal:game-for-fetch-and-increase-primitive-call} illustrates 
a part of the game between two participants $1$ and $2$ (when $D = \set{1, 2}$), together with a scheduler,
when participants only can call one single atomic fetch-and-increase primitive.
In the example, thread $1$ achieves the control for the first round,
and the strategy  $\strat{1}$ transfers the global log $l$  to thread $1$. 
Then, thread $1$ can generate a move which represented as a pair consists of one event and the result value of the game,
$1.\incticket$ (that implies \textbf{F}etch-\textbf{A}nd-\textbf{I}ncrease) and $res_1$, respectively.
After that move of thread $1$, thread $1$ gives the control to the scheduler (the circles in the middle low).
For the next movement, the strategy of the scheduler  ($\strat{sched}$)  transfers the control 
to thread 2 with recording the scheduling event ($1 \switch 2$) in the log,
and the strategy  $\strat{2}$ at that moment will transfer the global log ``$l \cons (1.\incticket) \cons (1 \switch 2)$'' ($\cons$ implies ''cons-ing'' an event to the log)
which is exactly same with the global log generated by the previous thread $1$'s movement.
Similar to the case of thread $1$, fetch-and-increase calls from thread 2 also return $(2.\incticket, res_2)$ of the first round of thread $2$
and $(2.\incticket, res_3)$ during the second round of thread $2$. 
More complex games also follow a similar structure with this example and the interaction among all components in the system 
can be expressed via the interaction among multiple strategies.

Some moves such as fetch-and-increase primitive calls in this game have to return values as their result,
and deriving them is available by interpreting the global log. 
For instance, finding out result values ($res_1$, $res_2$, and $res_3$) in Figure~\ref{fig:chapter:ccal:game-for-fetch-and-increase-primitive-call}
requires the function that can calculate the ticket number from the log.
The function counts the number of fetch-and-increase events ($\incticket$) in (\eg. $l$ for $res_1$) that
also corresponds to the current value of the next serving ticket number of the shared data for the ticket lock.
Such reconstruct functions for the current shared state from the log are called \emph{replay} functions and we notate it with $\replay$.

The strategy of the scheduler ($\strat{sched}$) acts as a judge of the game to abstract away complex interleavings, 
and it picks up one thread at each round using its strategy. 
The selected thread then makes a move  (and generate events)  as we have seen in Figure~\ref{fig:chapter:ccal:game-for-fetch-and-increase-primitive-call}.
The \emph{behavior} of the \emph{whole} layer machine (denoted as ``$\sem{L[D]}{\cdot}$'') 
is then the set of  logs generated by playing the game under all possible schedulings, and it can represent all non-deterministic behaviors of concurrent programs 
while they are hidden in our concurrent abstraction layers via the strategy of the scheduler.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
\centering
\includegraphics[scale=0.6]{figs/ccal/pcomp}
\caption{Environment Context.}
\label{fig:chapter:ccal:env-contexs}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

When focusing on a subset of threads $A$, the semantics (or execution) of the (concurrent) layer machine based on an
interface $L[A]$ is defined over its set of \emph{valid environment
contexts}. 
The definition of each  environment context (denoted as $\oracle$) is
a composition  of strategies for other components outside of the focused set($D - A$) in the 
system (plus scheduler).
This gives us the ability to address observable behaviors of the
execution of those threads/CPUs in the environment under one possible
interleaving (specified by the strategy of the scheduler).

For example, 
the system with two threads
(thread $1$ and thread $2$) and a scheduler (in Figure~\ref{fig:chapter:ccal:env-contexs})
shows how
an environment context for thread $1$ works with $L[1]$
and how it is related to the execution of  $L[\set{1,2}]$.
On the right, it shows the interleaved execution of
two invocations to $\incticket$ over $L[\set{1, 2}]$
where the environment context $\oracle$ is just the scheduler
strategy $\strat{sched}$.
On the left, it shows one execution
of method $\incticket$ over the layer machine $L[1]$ under a specific
environment context $\oracle_1$, when $\oracle_1$ is the union of
the strategy $\strat{sched}$ for the scheduler and $\strat{2}$ for
thread $2$. 

To enforce the safety of environmental moves,
each layer interface also specifies its set of valid environment contexts.
The semantics for the (globally) observable operations of $\sem{L[A]}{P}$ is then a set of global logs
generated from running $P$ over $L[A]$ under all valid
environment contexts. 
The validity definition depends on each layer interface which is stated as invariants over the global log. 
At each layer, we assume (thus ``rely'' on) the validity of environmental contexts based on the ``guarantee'' about the validity of the current global log and the local update of it. 
This is a generalized version of the rely-guarnatee-idea in previous works ~\cite{feng07:sagl,vafeiadis:marriage,LRG,fu10:roch,sergey15}. 
Those rely and guarantee conditions
are thus also parts of our extended layer definition. 


\subsection{Local Layer and Linking}
\label{chapter:ccal:subsec:local-layer-with-environmental-context-and-local-layer-linking}
 
When the focused set is a singleton set $\set{i}$,
the environmental executions (including the interleavings) for all other components except $i$ are all encapsulated into the environment
context.
Therefore,  $L[i]$ is actually a sequential-like (or \emph{local}) interface parameterized over $\oracle_i$. 
Before each move of a client program $P$ over this local interface, 
the layer machine first repeatedly asks $\oracle$ for environmental events until the control is transferred to $i$. 
For example, the fetch-and-increase primitive call from thread $i$ can be represented as an automaton 
\begin{center}
\includegraphics[scale=0.8]{figs/ccal/faiexamplewithcontext}
\end{center}
when the initial log of the primitive call is $l$. 

Building layers using this sequential-like local layer interfaces has a considerable similarity with 
the layer building in $\calname$; thus 
our extended layered framework facilitates
majority properties provided in $\calname$ with almost free cost;
thus all layer linking properties in $\calname$ including horizontal and vertical compositions also can 
easily be adapted to the local layer interface with environmental context.
Basically, the contextual refinement property for two layers, however, needs modification to address the newly added components. 
The contextual refinement property in here is similarly using forward simulation technique as shown in the 
Section~\ref{chapter:ccal:sec:cal}.
On the other hand, one challenge in defining the refinement property in here is the relation is not only related to layer definitions but also related to different environmental contexts over two layers. 
\begin{figure}
\begin{center}
\includegraphics[width=0.5\textwidth]{figs/ccal/locallayerrefinement}
\end{center}
\caption{Simulation Relation Between Two Local Layers.}
\label{fig:chapter:ccal:refinement-between-two-layers}
\end{figure}
Figure~\ref{fig:chapter:ccal:refinement-between-two-layers} shows the key simulation relation for 
the contextual refinement relation 
\begin{definition}[Contextual Refinement]
$$
\forall \ i\  \codeinmath{Ctxt} \ \oracle_i \ \oracle_i' .\ \sem{L_{low}[i]}{\codeinmath{M}_{high} \oplus \codeinmath{Ctxt}}_{\oracle_i} \refines_R \sem{L_{high}[i]}{\codeinmath{Ctxt}}_{\oracle_i'}
$$
\end{definition}
The contextual refinement definition is informally expressed as follows:
{\quote
``For every thread $i$,  code modules $\codeinmath{M}_{high}$ and  $\codeinmath{Ctxt}$,  and environmental contexts
  $\oracle_i$ and $\oracle_i'$ (for thread $i$), we say the underlay system   $\sem{L_{low}[i]}{\codeinmath{M}_{high} \oplus \codeinmath{Ctxt}}_{\oracle_i}$
     \textit{contextually
 refines} the overlay system $ \sem{L_{high}[i]}{\codeinmath{Ctxt}}_{\oracle_i'}$ when there always exists 
 multiple  transition steps in the underlay system for every the single  transition step
  in the overlay system that can be associated with the relation $R$,
which contains the relation between strategies ($R_{\strat{}}$)
 of two layer systems that satisfies the property:
$\forall \ \strat{i} . \ \strat{i} \in \oracle_i \rightarrow \exists \ \stratp{i} . \ \stratp{i} \in \oracle_i' \wedge R_{\strat{}}(\stratp{i}, \strat{i})$.''}

{\noindent}Section~\ref{chapter:ccal:sec:interface-calculus} provides formal rules for the layer linking that contains this refinement property in it. 

\subsection{Concurrent Linking and Compilation for Local Layer}
\label{chapter:ccal:subsec:concurrent-linking-and compilation-for-local-layer}

The layer interface $L[1]$ and $L[2]$ are  {\em compatible} and can be linked together if the guarantee (notated them with $L[1].\Guard$ and $L[2].\Guard$) of
each interface implies the other interface's rely conditions (notated them with $L[2].\Rely$ and $L[1].\Rely$) based on
the idea discussed in Section~\ref{chapter:ccal:subsec:concurrent-layer-with-environment}
We then can compose two partial layers to form 
$L[1, 2]$ by canceling out rely conditions in one partial machine with the others' guarantee conditions.
Also, we can adapt the $\compcertx$ compiler~\cite{deepspec} that we used in $\calname$
for the local layer interface because it is sequential-like.

Both, however, require us to solve multiple challenges. 
For example, providing a linking theorem  
implies that we need to define the behavior of a full machine model (for $L[D]$), a partial machine (for $L[A]$ when $A \subseteq D$), and 
a machine for a singleton set (for $L[i]$), as well as mechanically prove simulation theorems for the same layer (but possibly with different focused sets) among those machines. 
providing the proper compilation also requires 
us to reflect appropriate changes affected by other components to each sequential-like machine.
In multithreaded programs, for instance, a parent thread usually assigns a dynamic initial private state for its children,
and the compiler needs to address multiple issues including this challenge. 
Those challenges are out of scope in this chapter, but Chapter~\ref{chapter:linking} in this dissertation explains how we handle them.
