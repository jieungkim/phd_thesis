
\section{Certified Abstraction Layers}
\label{chatper:related:sec:certified-abstraction-laayers}


Our $\ccalname$ toolkit follows the layer-based compositional proof approach proposed by Gu \etal~\cite{deepspec}.
They proposed certified abstraction layers (CAL) for sequential programs and 
verified certified system software to show the applicability of the approach.
CAL has many different aspects with
 hoare-style program verification~\cite{hoare69,reynolds02,boogie05,nanevski06}.

First, $\calname$ proves a contextual correctness property by using the termination-sensitive forward simulation 
techniques~\cite{Lynch95,compcert}, 
which is stronger than simple partial or total correctness properties guaranteed by Hoare logic style verification.
Besides, its overlay interface of a certified object thoroughly disables 
the concrete memory block (of the object)  for  future usage 
and replaces the memory with an abstract state;
this abstract state is suitable for high-level reasoning such as proving security properties and progress properties (when it is extended to support
concurrency as $\ccalname$ does). 
It also differs from ghost or auxiliary states in Hoare-style program verification in terms of 
its usage.
The abstract state is a part of an entire state of the transition machine; 
thus it can be used to define the semantics of the overlay abstract machine
as well as the corresponding contextual refinement property.
Lastly,  building layers enable us to provide a new state transition machine and a new programming language that gets close to the specification language. 
Higher layers replace more low-level memory blocks and function implementations with 
the corresponding abstract states and primitives,
and can call primitives at higher abstraction levels while  
supporting general-purpose
programs written in C and assembly.

Those differences are also the same in the comparison between $\ccalname$ in Chapter~\ref{chapter:ccal} and 
Hoare-style program verification. 
When introducing a new concrete concurrent object implementation in our layers, 
we always replace a set of events generated by the object with an atomic event; thus we replace the implementation with an abstract atomic object in its overlay interface. 
In $\ccalname$,
all shared abstract states are represented as a single global log,
and atomic method calls always have to 
replay the entire global state and find the return value to refer to the current status of shared abstract states.
This global log approach treats all shared atomic objects with a single log.
Thus this is seemingly an inefficient way of treating multiple shared atomic objects,
but it is excellent for providing compositionality. 
It allows us to apply game semantics ideas, so it
is required for supporting parallel layer composition.





\section{Linearizability}
\label{chatper:related:sec:linearizability}


Linearizabilty~\cite{herlihy90}  is a well-known safety condition for concurrent objects 
and has been studied for decades. 
Developing concurrent software using a stack of shared atomic objects has since
become the best practice in the system
community~\cite{Herlihy08book,ospp11}. 
The original definition of ``linearizability'' instrumented programs
to record a global history of method-invocation and method-return
events. However, that's not a convenient theorem statement when
verifying client code.
In this sense,
linearizability is considered as a quite 
difficult problem to reason about, and it is until 20 years when 
Filipovic \etal~\cite{filipovic10} showed that linearizability is actually equivalent
to a termination-insensitive version of the contextual refinement.
Following that work, methodologies to simplify linearizability have been
proposed mostly in a concurrent programming context~\cite{Elmas10tacas,
Liang13pldi,Gotsman12concur,Viktor10CAV}.
Among them, Gotsman \etal~\cite{Gotsman12concur} showed that the equivalence between linearizability and a termination-insensitive version of the contextual refinement property also
holds for concurrent languages with ownership transfers~\cite{ohearn:concur04}.  
Liang \etal~\cite{liang13,lili16} also showed that linearizability with various
progress properties~\cite{Herlihy08book} for concurrent objects is
equivalent to multiple termination-sensitive versions of the contextual refinement property. 
These results convinced us that 
termination-sensitive (contextual) simulation is the proper property to show
when building certified
concurrent layers as well.

Some
authors have presented mechanized verification of linearizability
(\eg, \cite{DGLMQueue,DerrickSW11}).
They, however, are not directly on executable
code, but rather on abstract transition system models.
The formulation in $\ccalname$  is closer to Derrick \etal~\cite{DerrickSW11}, who prove a simulation
to a history of single atomic actions that modify an abstract state.  
Some mechanized proofs in the distributed system area show 
the linearizability of Raft and
multi-Paxos~\cite{cppraft, ironfleet}.
%
% Linearizability for distributed systems - let's decide weather adding that part or not after finish chapter witnesspassing
Linearizability
and leader-soundness proofs in Chapter~\ref{chapter:witness-passing} build on existing work on
linearizability: the key insight for the proof is to base the reasoning on
an atomic step of each operation. 
% Yet we generalize the reasoning of linearizability
%to the leader-based distributed system and create a reusable proof template.
%The template extracts
%necessary states from the witness that is created by the lower-level
%specification of concrete systems
%of a generic leader-based distributed system and provides a proof template based on
%abstract states which are represented as the witness.
The witness encodes atomic steps backed by a quorum--which approves state
changes--and the validity of the leader who is initiating the atomic actions.
%Our template guarantees the linearizability of any leader-based system that
%satisfies the constraints of the witness. Using a similar witness structure, our
%model automatically verifies the soundness of the leader based on
%the linearizability of leader election.




\section{Program Logics for Shared-Memory Concurrency}
\label{chatper:related:sec:program-logics-for-shared-memory-concurrency}

Multiple program  logics~
\cite{cap10, ohearn:concur04,brookes:concur04,feng07:sagl,vafeiadis:marriage,LRG,verifast,gotsman13,Turon13popl,Turon13icfp,nanevski13,nanevski14,
sergey15,sergey15pldi,pinto14,iris15,civl15,pinto16,xu16}
have been proposed for 
modular verification of shared-memory concurrent programs. 
Among them, most modern separation-style concurrent logics~
\cite{cap10,Turon13popl,sergey15pldi,pinto14,iris15,pinto16} do
not prove the same strong termination-sensitive contextual simulation
properties  our work does,
while very few of them (e.g.,~\cite{pinto16})
can reason about progress properties.
On the other hand,
$\rgsimname$~\cite{RGSim} as well as our layered framework prove the same strong contextual simulation properties.

Many of these program logics~\cite{Turon13popl,iris15}, however, support 
higher-order functions 
and sophisticated non-blocking synchronization,
which our work does not address.
Both of which will be
useful for verifying specific concurrent objects within our layered
framework. 
Our use of a global log is similar to the use of compositional
subjective history traces; a history trace specifies past events, proposed by Sergey \etal~\cite{sergey15}.
Our environmental context, however, can talk about both past and future events rather than only past events.
Total-TaDA~\cite{pinto16} can be used to prove
the total correctness of concurrent programs but it has not been
mechanized in any proof assistant and there is no formal proof that
its notion of liveness is precisely equivalent to Helihy's notion of
linearizability and progress properties for concurrent
objects~\cite{Herlihy08book}. 
Going
beyond safety, one also wants to prove a progress property such as
wait-freedom~\cite{herlihy91:waitfree} or (in our case)
starvation-freedom~\cite{Herlihy08book}.

Two previous works, CIVL~\cite{civl15} and FCSL~\cite{sergey15pldi},
propose the way to build and prove concurrent programs in a \textit{layered} way like $\ccalname$ does. 
However, their layers differ from $\ccalname$ layers in three aspects;
1) their approaches do not support contextual refinement proofs of linearizability like Filipovic \etal~\cite{filipovic10} and Liang \etal~\cite{liang13} do;
2) they are lack of connections with any verified compilers; and
3) they do not address liveness properties as we have shown in MCS Lock verification.



\section{Parallel Composition in Concurrent Program Verification}
\label{chatper:related:sec:parallel-composition-in-concurrent-program-verification}

\para{RGSim and LiLi.}
Building contextual refinement proofs for concurrent programs and supporting parallel composition for concurrent program proofs 
are challenging.
Liang \etal~\cite{RGSim,Liang14lics,lili16, liang:2017} 
proposed several approaches from Rely-Guarantee-based Simulation ($\rgsimname$) 
that support the parallel
composition and  contextual refinement of concurrent
objects.
The contextual simulation proof between two concurrent layers in $\ccalname$ is an instance of RGSim variance--the extended version of RGSim achieved by adding auxiliary states including environmental contexts and shared logs. 
They are the main ingredients of our $\ccalname$ framework 
to build our new  compositional
layered model.
All existing RGSim systems are limited to reasoning
about atomic objects at one layer.
Because their client program context cannot 
be the method body of another concurrent object, 
they cannot
support the vertical layer composition that our $\ccalname$ toolkit supports.
Their recent work~\cite{liang:2017} presents a way to specify and verify the progress of concurrent objects with partial methods, but the mechanized proof is out of their research scope. 


LiLi (Linearizability and Liveness) is a program logic based on RGSim
that can
directly prove both the linearizability and starvation freedom (or
deadlock-freedom) properties together. 
Their ``rely'' conditions are specified
over shared states only, so they cannot express temporal properties. 
To prove progress, they have to introduce a separate temporal ``rely''
condition called {\em definite actions}.  This made it difficult to
provide a standalone (total) specification for each lock-acquire
method.  Indeed, all examples in their paper are code fragments that
must first acquire a lock, then perform critical-section tasks, and then release the
lock. In contrast, our environmental context can specify the full
strategies (i.e., both the past and the future events) of all
environment threads and a scheduler, so we can readily impose
temporal invariants over the environment. Within each thread-modular
layer $L[t]$, we can show that each lock-acquire primitive (\eg, for
ticket locks) always returns as long as its environment is cooperative
(\eg, always releases its acquired lock), even if $t$ itself may not
be cooperative.
In other words, the termination of $t$'s lock-acquire
operation does not depend on whether $t$ itself will release the lock
after first acquiring it.


Most concurrent languages use a
parallel composition command, $(C_1 \| C_2)$, to create and terminate
new threads.  
Our approach is slightly different from most previous works.
We provide thread spawn and assign every new thread a unique ID $t$,
which is not reusable and must be a member of the full thread-ID domain set $D$.
As we have shown in Chapter~\ref{chapter:linking},
our parallel layer composition happens in specific layers and is
always done over the whole program $P$ and over
all members of $D$. 
This difference allows us to reason about the current
thread's behaviors over the environment's full strategies (\ie, both
past and future events).
Our composition treats the semantics for running $P$ over $L[t]$ as still well
defined even if a thread $t$ is never
created, because it will always query its environmental context to
construct a global log.

\jieung{Do we also need to add View paper?}

\para{Extending CompCert and Verified Compilation.} 

Compositional $\compcert$~\cite{stewart15} extends the original $\compcert$ compiler~\cite{compcert}  
to support the compositional thread-safe compilation of concurrent Clight programs. 
They introduced their interaction semantics followed by the approach proposed by Beringer \etal~\cite{beringer14}, which treats
synchronization-primitive calls as external calls.
They, however, did not support a layered ClightX language as we support in our $\compcertx$.  
Thus, building concurrent layers is impossible based on their work.
In addition, they did not investigate  supporting concurrency in the paper even though 
their interaction model is designed to support shared-memory concurrency.
Kang \etal~\cite{hur16} and Ramananandro \etal~\cite{ramananandro:2015} also modified $\compcert$ compiler to support separate compilation and composition, 
but they did not support concurrency.  
Other works on the verified compilation~\cite{Lochbihler10esop, Sevcik11popl, zhao:2013, kang:2018} did not support concurrent and/or compositionality. 

\para{Game Semantics.} 

We have used
game-semantic concepts such as strategies to describe our
compositional semantics, 
but $\ccalname$ still uses traditional small-step semantics for its concurrent machine and layer simulation, which differs from 
past works~\cite{ghica08,nishimura13,rideau11,abramsky99}  for concurrency modeling in the game-semantics community.
They use games to
define the semantics of a complete language, 
and modeling higher-order sequential features as games is excellent for proving a full abstraction. 
However, it is unclear how it is applied to the large-scale verification in the certified software community.


\section{Verification on the MCS Algorithm}
\label{chatper:related:sec:verification-on-the-mcs-algorithm}

As far as we know, two other efforts apply formal verification methods
to the MCS algorithm.  Ogata and Futatsugi~\cite{ogata:mcs-lock} used the UNITY program logic to develop a mechanized proof for the MCS algorithm.
Their work, however, is not with executable code but with an abstract transition system. Their correctness proof works by refinement like we do (between a fine-grained and a more atomic spec), but they directly proved backward simulation.

One difference is that Ogata and Futatsugi's proof is
done using a weaker fairness assumption.
Their assumption is, ``every CPU gets
scheduled infinitely often'', while we require a maximum scheduling
period,  cause we write our specification of \lstinline$wait_lock$ as a $\coq$ function defined by recursion on a natural number, and all $\coq$ functions must be total (\ie, all $\coq$ functions must terminate). 
So although our ultimate theorem only states that the method
terminates ``eventually'' as an intermediate lemma, we need to prove an explicit natural number bound on when a given call to
\lstinline$wait_lock$ will finish.  
We could avoid this by using
$\coq$'s well-founded recursion and
making the termination measure take ordinal instead of number
values, but in practice assuming a fixed termination number seems like a reasonable
model of multicore concurrency.

The other MCS Lock verification we know of is by Liang and
Feng~\cite{lili16}. 
They use their program logic LiLi to prove
liveness and linearizability properties and verify the MCS algorithm
as one of their examples.  
The LiLi proofs are done on paper, so they
can omit many ``obvious'' steps what we have to handle in the mechanized proof, 
and they work with a simple
while-loop language instead of C-like languages, which we have used to implement our MCS Lock.
Many of the concepts in our proof, however, 
are also recognizable in theirs. 
The state of their concrete
  programs includes a pointer \texttt{tail} and nodes
 \texttt{Node}(\texttt{busy}, texttt{next}, \texttt{ThrdID}).
In their invariant and precondition they use specificational variables
\textit{ta} and \textit{tb}, \textit{tl} and $S$. Their
  ``well-formed lock'' predicate \textsf{lls} includes our
  tail-soundness and next-correctness properties.
In addition, their
termination measure $f(\mathrm{G})$ includes the length of
$\mathit{tl}$ and the size of $S$ which is similar to our termination measure function. 
On the other hand, the fairness
constant makes no appearance in $f(\mathrm{G})$, because fairness
assumptions are implicit in their inference rules.


One big difference between our work and LiLi is our emphasis on
modularity.  
LiLi requires users to prove all the different invariants, down to low-level data representation in memory, between every two lines of code of a program.
The specification takes the form of a single
pre- and post-condition, which involves concepts at multiple levels of
abstraction. For example, unfolding the definition of the measure $f$,
we find not only \textit{tl}, but also the tail-pointer $p$, and
eventually the lock-array  \textit{ta}. In our development, these
concerns are in different modules which can be completed by different
programmers.  Similarly, we aim to produce a stand-alone specification
of the lock operations. In the LiLi example, the program being
verified is an entire ``increment'' operation, which takes a lock,
increments a variable and releases the lock. The pre/post-conditions
of the code in the critical section include the low-level
implementation invariants of the lock and the fact the lock will
eventually be released is proved for the ``increment'' operation as a
whole. Our locks are specified using \emph{bound} numbers so they can be used by many different methods.

In addition to the modularity, one can see a more philosophical difference
between our $\ccalname$ approach and program logics including LiLi.  
Liang and Feng are constructing a program logic which is tailor-made
precisely to reason about liveness properties under fair
scheduling. 
Getting a complete mechanized proof for a program in that
setting would require mechanizing not only the proof of the program
itself but also the soundness proof for the logic, which is a big
undertaking. 
Other parts of the program will favor different kinds of
reasoning; for example, many researchers have studied program logics
with inference rules for reasoning about code \emph{using} locks. One
of the achievements of the $\ccalname$ style of specification is its flexibility because the same model works throughout the entire software stack such as the OS kernel. When
we encountered a feature that required thinking about liveness and
fairness, we were able to do that reasoning without changing the
underlying logical framework.


\section{OS Kernel Verification} 
\label{chatper:related:sec:os-kernel-verification}

A significant body
of  work including
seL4~\cite{klein2009sel4,klein14},
Verve~\cite{hawblitzel10}, Hyperkernel~\cite{hyperkernel}, and Komodo~\cite{komodo}
addressed OS kernel verification.
None of these works, however, support concurrency (either with multicore or with multithreaded)  with fine-grained locking.
Xu \etal~\cite{xu16} developed a new verification framework by facilitating RGSim
and Feng~\etal's program logic~\cite{feng08:aim} for reasoning
about interrupts.
They verified multiple  key modules (written in C) 
in the $\mu$C/OS-II, a preemptive kernel,
 but progress and proof linking properties are out of the scope of their work. 
Others~\cite{klein2009sel4,hawblitzel10, hyperkernel, komodo},
are aiming to prove several properties based on the model of single-threaded, or limited concurrency supports using a per-core big kernel lock.

There is another hypervisor verification work done by the Verisoft team by using VCC~\cite{leinenbach09}.
The team verifies spinlocks in a hypervisor by directly postulating a Hoare logic rather than building
on an operational semantics for C.
However, their work is limited to proofs about properties of the low-level primitives 
instead of showing the full functionality of
the hypervisor.
Our work, on the other hand, 
is an end-to-end verified concurrent system showing that its
assembly code indeed ``implements'' (contextually simulates) the
high-level specification by using $\ccalname$.

\section{Distributed System Verification}
\label{chatper:related:sec:distributed-system-verification}

Approaches to verify distributed systems have been explored actively over the
past few years. 
IronFleet~\cite{ironfleet} aims to verify multi-Paxos by using annotated functions with pre- and
post-conditions to automatically prove the correctness of the code with an SMT (satisfiability
modulo theories) solver.
It also proves a refinement relation between the code and
protocol proofs (including immutability and liveness) in different layers. 

Verdi~\cite{verdi} is a distributed system verification toolchain
where developers specify and implement a system using a functional language
embedded in $\coq$ while assuming a perfect network model. 
The system can then automatically convert
it into a system that handles a more realistic network and failure model
and provides the refinement property of the system behavior on different network and failure models.
Woos \etal~ presents the mechanical verification of Raft~\cite{cppraft} by facilitating Verdi. The properties
verified for Raft include linearizability and the soundness of the leader and
the code written in $\coq$ translates to executable OCaml code. 
Our work delegates verification of such Raft properties common to leader-based distributed systems to the template.
Besides, the final executable code extracted from
our verification is in assembly, which is generated from $\compcert$ C compiler and is more
optimized than the OCaml code.


DISEL~\cite{disel}
studies how to verify and horizontally compose different distributed protocols.
It verifies the protocols in separation and uses send-hooks to restrict the
interference among protocols. Our work assumes a realistic network to begin with
and  not only allows both the horizontal and vertical composition of verified distributed
protocols but also supports the combined reasoning of protocols by using witnesses.

Taube et al.~\cite{modular}, followed by the previous work~\cite{paxosepr}, studied adding
decidability for verifying distributed systems using SMT solvers.
The work surrounding SMT solvers has a philosophical difference from our distributed system verification approach.
We use high-order logic and $\ccalname$, which have higher expressiveness but less automation,
while SMT-solver-based work requires encoding higher-order concepts into
first-order logic for better automation. While a relatively large portion of the
verification can be automated, the SMT-solver-based approach has some limitations.
For example, some higher-order properties (\eg, network reduction
in IronFleet) are not always encodable or verifiable in first-order logic.

\section{Paxos Verification and Deconstruction}
\label{chatper:related:sec:paxos-verification-and-decomposition}

A substantial body of work exists on verifying the Paxos protocol~\cite{paxos}.
Lamport provided a proof sketch at the time of proposing the protocol~\cite{paxosmadesimple}.
Lampson also attempted to distill Paxos into its core components by creating a very
high-level Abstract Paxos~\cite{Lampson2001} and showing how variants of
Paxos can be derived from it. 
Additional efforts were made to divide Paxos
into simpler components~\cite{dpaxos, sdpaxos} to find a reusable framework for
proving its variants. Our approach also attempts
to find a reusable framework for these proofs,
but our approach chooses to pass around the information (by logically exposing the key implicit invariant as the explicit one)
 that is needed to prove the fundamental properties of distributed protocols instead of decomposing Paxos further. 

Padon et al.~\cite{paxosepr} verified high-level specifications of many variants of Paxos
and multi-Paxos while proposing a method to specify the protocols using
a decidable first-order logic. Verification of Paxos
variants was made possible by reusing the specification and proof of vanilla
Paxos. 
On the other hand, our approach can reuse the proof of a Paxos instance
via using $\ccalname$. 


Within the category of distributed system verification,
a significant amount of work focuses on Paxos.
Lamport's first paper on the protocol~\cite{paxos}, and his second attempt to explain it more clearly~\cite{paxosmadesimple}
present the underlying algorithm and give paper-and-pencil proofs of safety properties of the algorithm.
Since then, many variations have been developed such as Disk Paxos~\cite{diskpaxos}, Egalitarian Paxos~\cite{epaxos},
and Vertical Paxos~\cite{vertpaxos} to extend the applicability of Paxos by adding additional features. 
Often, although these variations seem similar to the original protocol, 
it is not possible to reuse the original
proof of the safety properties and a significant amount of work is required to re-prove them.
Lampson attempted to distill Paxos into its core components by creating a very high-level Abstract Paxos~\cite{Lampson2001}
and showing how other variants can be derived from it.
Some still felt that this did not get at the essence of the algorithm because at least two works since then \cite{dpaxos, sdpaxos}
have studied other ways of dividing Paxos into simpler components such that  proofs of the protocol can be made more modular.
Our witness-passing approach also attempts to find a reusable framework for these proofs,
but instead of decomposing Paxos further, we make the critical implicit invariants more explicit by passing around
the information needed to prove them.

It enables proofs to be done in a thread-local (or node-local) manner using an environmental context to
capture the behavior of the rest of the world.
These proofs can then be linked together to obtain a strong correctness theorem for the entire system.

Our witness benefits significantly from using $\ccalname$.
By decomposing distributed systems into layers, we reduce the amount of time and effort needed to
prove functional correctness.
By treating each distributed node as a separate thread, we can use the environmental context to
prove properties in a local context.
Combining this with the witness then allows us to bring in information about the global state when necessary.
We also use the environmental context to model a realistic and non-deterministic network.
Another advantage afforded by $\ccalname$ is that we can lift our safety proofs to higher layers via using a contextual refinement property.
It allows us to implement and verify a system once and then reuse it as a component in various distributed applications.



\section{Model of Leader-based Distributed Systems}
\label{chatper:related:sec:model-of-leader-based-distributed-systems}

Distributed system verification in this thesis focuses on a leader-based distributed system model, 
which is based on the two functions,
leader election and update functions. 
The model itself is inspired by CASPaxos~\cite{caspaxos},
which implements an atomic shared object. 
CASPaxos uses prepare and accept
phases similar to those in Paxos, but it can repeatedly apply a compare-and-swap
function to the stored state instead of setting it just once. 
CASPaxos is a system implementation
to atomically update a distributed object, but our work differs from CASPaxos 
because we use the implementation style of
CASPaxos to build a generic specification for leader-based distributed systems.
Our specification also resembles the high-level specification of the state machine
replication protocol that  Lamport generalized~\cite{generalizedconsensus} based on the trace theory~\cite{mazurkiewicz:tracetheory}.
Our work aims to model and verify the common properties of  generic leader-based distributed systems;
thus it differs from Lamport's work which focuses on modeling multi-Paxos and consensus.
