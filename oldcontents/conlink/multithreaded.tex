\clearpage


\section{Certified Multithreaded Layer Interface Implementation}
\label{sec:multithreaded-linking-impl}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% 1. similarity and difference bewteen  this one and mutlcore machiens
%     the basic idea is same. But, requires additinal steps (new machine models / context / 
%     and refinement between machine model)
%    
% 2. Key requirements of our thread linking 
%      2-1. It should be done in the logic and the machine level - we should not prove source code correctness again!!
%      2-2. Higher layers should be purely local (do not need to look up and modify other threads'  private datum at all even for 
%             process creation - when the process create its child -)
%      2-3. The intermediate languages that we have introduced should be a operational semantic style for easy refinement proofs
%      2-4. We want to use all benefits of CompCertX, in thread local machines too. So we can use 
%             the behavior preserving between C and Asm, which is guarnateed by CompCertX
%      
% 3. EAsm definitions (and EAsm and LAsm_L refinement)
%     details:
%       abstract data type change (SingleData)
%       our event type and single oracle definitio (SingleOracle)
%       logical context (our ThreadConfigurationOps)
%       relation between multiple languages  (refinement theorems)
%       differences bewteen the external call rule in LAsm_L and the external call rule, the yield rule, the yield back rule in EAsm
%       need to metnion that we will introduce the concrete layer refinement for this stpe (num. 7)
%      
% 4. EAsm_total and EAsm_single refinement 
%    details: 
%       explain the empty step rules in EAsm in here
%       single processor linking (composition theorem)
%      
% 5. EAsm_single and TAsm refinement 
%    details:
%      replace operational style oracle query as a big step style oracle query. 
%      (AsmT2E theorem)
%
% 6. TAsm and HAsm (LAsm_H) refinement 
%    details:
%      initial state and proofs
%      refinement theorem (AsmPHThread2T.v)
%       need to metnion that we will introduce the concrete layer refinement for this stpe (num. 7)
%      
% 7. proving the actual refinement proofs with concrete layer definitions 
%     - instantiation of our single data, single oracle and and other abstract definitions 
%     - defining the simulation relation between layers 
%       1) simulation between LAsm_H and TAsm is straightforward
%       2) simulation between EAsm and LAsm_L is not trivial
%           2-1) scheduling (briefly because we have mentioned it from (num. 3) to (num. 6)
%           2-2) IPC (push and pull model for non-atomic operation)
%           2-3) memory (permission table dijoint property). 
%           2-4) initial state (briefly because we have mentioned it in (num. 6))
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This section shows how we define intermediate machine models to build per-thread machine
model by building 
multiple languages, refining them. 
For that purpose, 
we define three intermediate languages 
and prove simulation among them with the abstract definition 
of any kinds of layers that satisfy a certain properties. 

Those proofs are generic at least all layers can be satisfied by 
the conditions that the proofs are relying on. 

In this section, we provide details of those intermediate languages,
show the refinement proofs,
and also provide conditions that we are relying on.


\begin{figure}
\vspace{-14pt}
\includegraphics[scale=.40]{figs/thread-linking}
\vspace{-5pt}
\caption{Thread Linking}
\label{fig:thread-linking}
\vspace{-5pt}
\end{figure}

The basic structure of multithreaded linking is described in Fig.~\ref{fig:thread-linking}.
To introduced the per-thread layer machine, 
the first thing is dividing a single CPU machine into multithreaded machine models. 
Based on the multithreaded machine model, 
we build a partial machine model, which is quite similar to the intermediate steps in





 shows our key ideas to introduce the thread-local layer interface.
More technical details, such as formal rules, theorems, and proof sketches will be explained in this section.
Introducing the  thread-local layer interface consists of two parts.
The first part is proposing multiple machine models that connect the CPU-local machine to the thread-local one.
Secondly, we have to instantiate the layer  interface$\Lhbthread[c][\threadset]$  for every such machine.

The first part to introduce \emph{multithreaded} layer interface
is similar to that of developing \emph{multicore} layer interface.
However, multithreaded layer interface need to handle
multiple additional challenges:
1) changing an assembly-style context switching as a no-op like operation;
2) dividing CPU-local abstract data into multiple thread-local abstract datum; 
3) merging multiple step evaluations performed by other threads between the thread's yield call and return; 
4) and preserving the same interface with CPU-local layer interface such that thread-local layers can be easily built.


Figure~\ref{fig:thread-linking} shows how we overcome all the listed issues and build a thread local layer based on the 
 concurrent layer interface $\Lbthread$ described in Sec.~\ref{subsec:pbthreadlayer}.
The concurrent layer interface (\cf Fig.~\ref{fig:thread-linking} (1)) is still a CPU-local layer,
and the layer contains only one register set and one private abstract data in its state.
The layer definitely captures the execution of the whole thread set of CPU $c$ 
and does not support thread-local reasoning.
As a first step of building thread-local layer interface, 
we divide our CPU-local private data (a private register set and a private abstract data) into multiple thread-local
private datum (Fig.~\ref{fig:thread-linking}). 
Since the layer contains multiple private datum, we also add the flag for currently-running thread $curid$ in the state. 
By doing this, we can also resolve one challenge in our thread-local machine, which is to replace an assembly style 
context switch with no-op like operation. 
The layer contains per-thread register sets and, thus, the register values do not need to update along the change of the currently-running thread id. By changing the thread id alone, the layer knows which thread-local private data should be 
used during the current evaluation.
Now each thread can use its own private data for its evaluation, but that is not sufficient at all. 
In fact, scheduling switches in this layer has a similar meaning with the ones in the lower layer, 
$\Lbthread$ (i.e., the blue $\yield$) but with differentcontext switching styles.
Ideally, we would like to reason about each thread execution 
independently, and later formally combine the reasoning to obtain a global
property for the full set of threads on the same CPU.
So, we need a machine model that gives semantics to
a partially-composed set of threads to support this.

Therefore,  a new layer (\cf Fig.~\ref{fig:thread-linking} (3)) has to be introduced such that other 
threads' operations can be modeled as input strategies to the layer interface. 
Here, we introduced a new kind of environment context, $\oracle^{t}$, which contains the strategy the environmental threads and is the key to support  thread-local reasoning.
Formally, let $T_c$ be the whole thread set running over CPU $c$.
From a CPU-local layer  $\PLayer{L}{c}{}$,  we construct a 
 \emph{multithreaded} layer $\TLayer{L}{c}{\threadset_a} := (\PLayer{L}{c}{},
 \Rely^t, \Guard^t)$,
which is 
parameterized over an active thread set $\threadset_a \subseteq \fullthreadset$.
The rely condition $\Rely^t$ defines a set of acceptable thread contexts
$\oracle^t$ and the guarantee condition $\Guard^t$ specifies the events generated by active threads. 
Since our machine model does not allow
preemption, $\oracle^t$ will only be queried during the execution of scheduling primitives, 
which have two kinds
of behaviors  depending on whether the \emph{target
thread} is active or not.
\ignore{
%\vspace{-5pt}
\[
\includegraphics[width=.7\textwidth]{figs/thread2}
\]%
%\vspace{-12px}
}
Considering an execution in Fig.~\ref{fig:thread-linking} (3) with active thread set
$\threadset = \{0\}$, whenever an execution switches (by $\yield$ or $\sleep$) 
to a thread outside of $\threadset_a$ (i.e., the yellow $\yield$),
it takes environmental steps (i.e., notated as arrows), repeatedly appending the 
events returned by the environment context $\oracle$ and the thread
context $\oracle^t$ to the log until a $\yield$
event indicates that control switches back to an active thread.


This layer is already a thread local because it only captures the behavior of one thread.
However, the strategy query in this layer follows small-step style, and this is insufficient to build thread-local layer interface because we do not want to query multiple times for a single yield call. 
Therefore, we introduce another  layer to merge those multiple strategy queries into a single big-query (\cf Fig.~\ref{fig:thread-linking} (4)). 
Finally, the last thing to do is to connect the machine state of thread-local layers to our general concurrent layer interface, which has the form of $(\regs, m, a, l)$.
Therefore, we introduced the last layer (Fig.~\ref{fig:thread-linking} (5)) that will become a base to build our multithreaded layers.


\ignore{
\begin{figure}
\vspace{-14pt}
\includegraphics[scale=.40]{figs/thread-linking}
\caption{Thread Linking}
\label{fig:thread-linking}
\vspace{-5pt}
\end{figure}

Key differences of those machine models are described in Fig.~\ref{fig:thread-linking}.
The first step (1) is introducing a CPU local layer described 
in Sec.~\ref{subsec:pbthreadlayer}, $\Lbthread$, which perform context switching 
when a thread tries to give the execution control to an another thread in the same CPU.
The next step (2) is introducing a concurrent machine model, $\EAsmM{[c, \fullthreadset]}$
and the layer, $\Lhbthread$ based on the machine model which parameterized by the current CPU ID 
and the full thread set ($\fullthreadset$) on the CPU ($c$). 
After that (3), we replace other threads' evaluation by using environmental context
, and parameterize the machine model using a partial thread set
$T_a$, $\EAsmM{[c, \threadset_a]}$, an environmental context $\oracle$ for 
the behavior of other CPUs, and $\oracle^{t}$ for the behavior
of other threads, $\fullthreadset - \threadset_a$, in the same CPU.
This step is briefly mentioned in Sec.~\ref{sec:multi-threaded-partial}. 
When the machine is parameterized by only one thread id ($tid$), 
this $\EAsmM{[c, \{tid\}]}$ become a single thread-local machine at this point,
and this machine is already a thread-local machine.
This $\EAsmM{[c, \{tid\}]}$, however, has multiple evaluation rules that cannot be directly 
mapped into the rules in  
our old machine model, $\AsmLM$.
Therefore, we introduce an 
additional intermediate machine model (4), $\TAsmM{[c, tid]}$ 
to make the refinement between different machine models easy as well as 
the layer refinement between thread-local layers and the CPU-local layers possible.
Finally, we can introduce the $\Lhthread$ using the same machine model 
with $\Lbthread$ (5), which is $\AsmHM$, but treat the yield and sleep 
functions as like no-op functions, which only updating the shared log during 
their evaluations.}
In this section, we will first explain  all these machine models that have been introduced in Fig.~\ref{fig:thread-linking}.
We then show hot to prove the compositional thereoms to link these machine models. 
After that, we  explain how we build and refine the concrete layer interface over  them. 
As for the second part, we also show the refinement relation between concrete layer definitions.
Due to the large size of our mechanized Coq proofs, we only provide brief proof sketches for all the theorems.


%%%% PHThread Layer %%%%
\subsection{Low Level Assembly Machine}\label{subsec:lowlevelasm}

As we have discussed in Sec.~\ref{sec:multithreaded-layers}, 
the first step is introducing scheduling primitives in our CPU local layers..
In terms of artifacts, 
The language model that we have used in CPU-local layers is \compcertx\ propposed by \cite{dscal15}, and 
The machine state of it is
\begin{small}
\[
st_{\AsmLM} = (\regs, (m, adt))
\]
\end{small} 
where $\regs$ is a register set, $m$ is a memory, and $adt$ is an abstract data.
To use this existing tool as much as possible, we encapsulate the idea of 
our concurrent machine model (Fig.~\ref{fig:mach:syntax}) in this machine state, 
mostly in the abstract data ($adt$) among the components.
For instance, when looking at the state of the first example (1) in Fig.~\ref{fig:thread-linking}, the state is defined as $st = (\rho, m, a, l)$, but both $a$ and $l$ are actually two components of $adt$ in our implementation level.
By successfully integrating our framework with \compcertx, we do not need to modify the language semantics and machine model
to build CPU local layers.
For example, the external call rule in \compcertx\ $\AsmLM$ machine, 
which is also used for $\yield$ and $\sleep$ functions,  
is defined as follows:
\begin{small}
\[
c, \oracle \vdash_{\AsmLM} \sstepr{\spec_{_{id}}}{args}{\regs, m, adt}{\textit{res}\cup \{\}}{\regs',  m', adt'}
\]
\end{small} 

%%% FULL EASM %%%%%%%%
\subsection{Multithreaded Machine Model}\label{subsec:fulleasm}

When it comes with the multithreaded concurrency, however, 
encapsulating our ideas only in the abstract data 
and thus in the state of their \compcertx\ is insufficient
due to multiple challenges. 
First, we have to replace the actual context switching semantics in Assembly source code with no-op 
like operations in thread-local layers. 
This simplification of yield and sleep behaviors is unclear when we try to enable it 
without touching any definitions in the machine model. 
In addition, thread-local layers should be purely local even for the process create primitive, 
which establishes the initial user context, kernel context, and other dynamic information for its child. 
This implies that our thread-local layer interface should have a method to dynamically 
build its initial state depending on the behavior of its parent. 
Third, each thread can build its stack in its memory, and it will change the next available block in the memory
after it calls  $\yield$  or  $\sleep$ .
Therefore, calling  scheduling primitives can arbitrarily update 
the memory block based on other threads' behavior, and our thread-local machine need to capture this behavior properly. 
We also want to use all benefits of \compcertx, which are not only layered approach 
but also behavior preserving between $C$ and complied $Assembly$ programs.
Lastly, we want a generic and scalable thread-local layer interface as much as possible.
Even if we add or remove multiple primitives in the layer that we want to link multiple 
thread-local layers together to refine it into a single CPU-local layer, 
we want to use the same machine model and reuse mostproofs that we have already done before. 
To fulfill all the above challenges, we have introduced a concurrent machine model, $\EAsmM{}$.
\begin{figure}
\begin{small}
\[
\begin{array}{llll llll}
(\textit{SharedData}) & \dshare & \in & Type &
(\textit{PrivateData}) &  \dproc & \in & Type\\
(\textit{InitSharedData}) & \dshare_{init} & \in & \dshare &
(\textit{ProcessorID}) & \cpuid & \in & \dshare \rightarrow Z\\
(\textit{ThreadID}) & \procid & \in & \dshare \rightarrow Z&
(\textit{BlockNum}) & \blocknum & \in & \mathbb{N} \\
(\textit{Mem}) & m & \in & loc \rightarrow val &
(\textit{NextBlock}) & \nextblockfun & \in & m \rightarrow  \mathbb{N} \\
\end{array}
\]
\begin{center}
(1) Data Types and Auxiliary Functions Related to Data Types
\end{center}
\vspace{-1em}

\[
\begin{array}{llllllll}
(\textit{Lval}) & \lval & \in & Int \cup Ptr  &
(\textit{Largs}) & \largs & \in & list \ \lval  \\
(\textit{Ident}) & \threadfunid & \in & \{\yield,\ \sleep,\ \cdots\}&
(\textit{SnapShot}) & \dsnap & \in & Type  \\
(\textit{SnapShotFun}) & \snapfun & \in &  \dproc \rightarrow \dsnap &
(\textit{SleepEventUnit}) & \primevunit{sleep} & \in & Int \times \blocknum \times \dsnap \\
(\textit{YieldEventUnit}) & \primevunit{yield} & \in & \blocknum \times \dsnap &
(\textit{PrimEventUnit}) & \primevunit{\threadfunid} & \in & \threadfunid \times \largs \times \dsnap \\
(\textit{EventUnit}) &  \primevunit{} & \in &
\multicolumn{5}{l}{
 \{\primevunit{sleep},\ \primevunit{sleep},\  \primevunit{ident},\  \yieldbackunit \} 
 }
 \\
(\textit{Event}) &  \Sevent & \in & tid \times \primevunit{} &
(\textit{Log}) &  \SLog & \in & list\ \Sevent \\
\end{array}
\]
\begin{center}
(2) Event and Log
\end{center}
\vspace{-1em}

\[
\begin{array}{llll llll}
(\textit{ThreadSet}) & \threadset & \in & \{Z\} &
(\textit{FullThreadSet}) & \fullthreadset & \in & \threadset \\
(\textit{InitLog}) & \SLog_{init} & \in & \SLog &
(\textit{InitNb}) & \blocknum_{init} & \in & \blocknum \\
(\textit{EnvContext}) & \oracle^{t} & \in & \threadset \rightarrow \varphi^{\threadset} &
(\textit{Strategy}) & \varphi^{\threadset} & \in & \SLog \rightarrow \Sevent \\
\end{array}
\]
\begin{center}
(3) Environmental Context
\end{center}
\vspace{-1em}

\[
\begin{array}{llllllll}
(\textit{Update}) & \updatefun & \in & \dshare \rightarrow \SLog \rightarrow \dshare &
(\textit{Construct}) & \updatefun_{init} \ l& := & \updatefun\ \dshare_{init} \ l  \ \ \ \ (l \in \SLog) \\
(\textit{StateCheck}) & \statecheck & \in &
\multicolumn{5}{l}{
 \threadfunid \rightarrow \largs \rightarrow \dshare \rightarrow \dsnap \rightarrow \mathrm{Prop}
 }
 \\
 (\textit{EventCheck}) & \haseventfun & \in & \threadfunid \rightarrow bool  &
(\textit{Reg})  &\regs & ::= & \mathsf{EIP} \ | \ \mathsf{EAX} \ | \  \cdots \\
(\textit{ThreadState}) & \threadstate & \in &
\multicolumn{5}{l}{
 \{\mathrm{Environment}, \ \mathrm{Available}, \ \mathrm{Running}\ \regs \} 
  }
\end{array}
\]
\begin{center}
(4) Auxiliary Definitions for $\EAsmM{}$
\end{center}
\vspace{-1em}

\end{small}
\caption{Additional Definitions for Concurrent Machine Model}
\label{fig:mach:thread-syntax}
\vspace{-17pt}
\end{figure}
Figure~\ref{fig:mach:thread-syntax} shows multiple definitions for $\EAsmM{}$ in addition to the several 
shared definitions with our CPU-local layer interface in Fig.~\ref{fig:mach:syntax}, and
with the given definitions, the machine state of $\EAsmM{}$ is defined as
\[
st_{EAsm} = (Z, f_{\threadstate}, m, \SLog, f_{\dproc})
\] 
where the first element implies the currently-running thread that performs the evaluation, 
$f_{\threadstate}$ is a partial map from a thread id to a thread state, 
$m$ ($loc \rightarrow val$) is a memory, $\SLog$ is a single log that is shared by the whole thread, 
$f_{\dproc}$ is a partial map from a thread id to a private state.

The first step to facilitate this concurrent machine model is defining semantics with the full thread set on CPU $c$,
which is notated as $\EAsmM{[c, \fullthreadset]}$ when $\fullthreadset$ is a set of all active threads on CPU $c$.
At this step, key differences between this machine model and the machine model 
(Sec.~\ref{subsec:lowlevelasm}) for CPU-local layers are
1) the machine state contains an explicit set of registers;
2) the machine state has  information of currently-running thread in it; and 
3) the machine state has a log explicity rather than only having it in the abstract data. 
Those concepts works as vital roles when we replace a context switch as a no-op like operation as well as
when will show the thread isolation property.

For example, the first one is replacing our context switch 
in CPU-local layers as a no-op like operation in thread-local layers.
The last one, having an explicit log in the machine itself, gives us 
a generality of our framework that handle multithreaded concurrency. 
When modeling this framework and machine models for multithreaded concurrency, 
we do not need to consider which primitives 
generate the event during their evaluation.
In terms of machine model level, 
we only need to consider a general and abstract method to raise an event and update 
a shared state using that event.
Concrete layers, of course, should be instantiated when we want to link those layers together, but 
this one is an another phase of our thread linking because we want to divide the whole process as 
a machine model level and a concrete layer refinement level. 

Using those definitions, the evaluation rule for the external call of $\EAsmM{}$ will be defined as:
\begin{small}
\begin{mathpar}
\inferrule{
\updatefun_{init}(l) = ds \\
\procid(ds) = curid \\ 
f_{\threadstate}(curid) = \mathrm{Running}\ \regs\\
f_{\dproc}(curid) = Some\ d \\ 
id \neq sleep  \\
id \neq yield \\ 
\spec^{_{def}}_{_{id}}: (largs, \regs, m, ds, d) \ni (\textit{res} \cup \{\}, \regs', m', ds', d') \\
if\ \haseventfun(id)\ then\ l' = (curid, (id, largs, \snapfun(d)))::l  \ else\ l' = l \\
\updatefun_{init}(l') = ds' \\
f_{\threadstate}' = f_{\threadstate}[\mathrm{Running}\ \regs'/curid]\\
f_{\dproc}' = f_{\dproc}[Some\ d'/curid] \\
%\oracle, c\vdash \sstepr{\spec_{id}}{[largs]}{\regs, m, ds, d}{\textit{res}\cup \{\}}{\regs',  m', ds', d'}
}{
\fullthreadset, \oracle^t, c, \oracle\vdash_\comm{EAsm} \sstep{\spec_{id}}{largs}{curid, f_{\threadstate}, m, l, f_{\dproc}}
 {res \cup \{ \}, curid,f_{\threadstate}' , m', l', f_{\dproc}'}
}
\end{mathpar}
\end{small}
When evaluating external calls, 
we first construct the current shared data ($ds$) by replaying the log ($l$), 
and gets the information of the register values and the private abstract data that are mapped with the current 
running thread id.
Then, it evaluates the function, and update the state 
including the log when the external call function generates an event.

Note that the current environmental context is same with that of CPU local layers. 
Since the lowest level $\EAsmM{[c, \fullthreadset]}$, which is just above the $\AsmLM$ for CPU local layers
contains the full thread in the state, 
its environmental context will be identical to the environmental context in 
the highest CPU local layers.
Looking at the external call evaluation rule, however, $\EAsmM{[c, \fullthreadset]}$
filters out the case when the current call is 
$\yield$ or $\sleep$ calls. 
Instead of using one common external call evaluation rule, the machine has introduced the 
specific rule for those scheduling primitives 
which change the current running thread id in the state.
\begin{small}
\begin{mathpar}
\inferrule{
\updatefun_{init}(l) = ds \\
\procid(ds) = curid \\ 
f_{\threadstate}(curid) = \mathrm{Running}\ \regs\\
\statecheck(\yield, [],ds,\snapfun(d)) \\ 
f_{\dproc}(curid) = Some\ d \\ 
\nextblockfun(m) = nb \\ 
l' = (curid, (nb, \snapfun(d)))::l \\
\updatefun_{init}(l') = ds' \\
\procid(ds') = curid' \\ 
%\oracle, c\vdash \sstepr{\spec_{id}}{[largs]}{\regs, m, ds, d}{\textit{res}\cup \{\}}{\regs',  m', ds', d'}
}{
\fullthreadset, \oracle^t, c, \oracle \vdash_\comm{EAsm} \sstep{\yield}{[]}{curid, f_{\threadstate}, m, l, f_{\dproc}}
 {\{ \}, curid', f_{\threadstate}, m', l', f_{\threadstate}}
}
\end{mathpar}
\end{small}
In the yield evaluation rule, the machine does not use any user defined specifications at all. 
Instead of that, the rule contains what $\yield$ should do explicitly. 
It appends a yield event into the current log, and change the currently-running thread id by evaluating the updated log.
In addition to that, it memorizes next block information when the thread calls yield to enable thread-local machines to
find the proper information for its thread-local stack building. 
The rule also contains the condition that checks the current state. 
This check guarantees that the current status of the thread (both shared and private data status) are valid to call $\yield$. 
We can use the whole private data for this status check, but the reason why we use a snapshot is getting a generality in the design. 
For the simplest case, our snapshot function can be defined as an identity function 
that gets a private data and returns the exact same private data as a result.

After that, if the new currently-running thread id is available and it is in the set of our available thread set,
$\EAsmM{}$ needs to resume the evaluation with the newly scheduled thread id. 
Since we are considering $\EAsmM{[c, \fullthreadset]}$, the next running thread will always be 
available and $yieldBack$ rule in $\EAsmM{}$ sets correct register values and memory for the thread as follows:
\begin{small}
\begin{mathpar}
\inferrule{
\updatefun_{init}(l) = ds \\
\procid(ds) = curid \\ 
(f_{\threadstate}(curid) = \mathrm{Running}\ \regs) \vee
(f_{\threadstate}(curid) = \mathrm{Available} \wedge \initregs(curid, l) = Some \ \regs)\\
f_{\dproc}(curid) = Some\ d \\ 
last\_event(l) = ev \\
ev = (\_, (nb, \_)) \vee ev = (\_, (\_, nb, \_))  \\
\liftnextblock{m}{nb - \nextblock{m}} = m' \\
l' = (curid, \yieldbackunit)::l\\
%\oracle, c\vdash \sstepr{\spec_{id}}{[largs]}{\regs, m, ds, d}{\textit{res}\cup \{\}}{\regs',  m', ds', d'}
}{
\fullthreadset, \oracle^t, c, \oracle\vdash_\comm{EAsm} \sstep{yieldBack}{[]}{curid, f_{\threadstate}, m, l, f_{\dproc}}
 {\{ \}, curid, f_{\threadstate}[Running\ \regs/curid], m', l', f_{\dproc}}
}
\end{mathpar}
\end{small}
This rule has two cases. 
The first case is when the thread is already running, and we just need to use the thread state for the newly scheduled thread as it is.
However, if the thread is created recently and have never scheduled yet, 
Our machine checks whether the thread is actually available or not as well as establishes its register values by replaying the current shared log. 
Our abstract definition, 
$\begin{small}(\initregs \in Z \rightarrow \SLog \rightarrow \mathrm{option}\ \regs) \end{small}$ 
is used to check the validity of the thread creation and to build the 
correct register values (including kernel context values) for the initial move of the thread. 
In terms of concrete implementation, the machine always choose either the running thread id or the thread id that is ready to run
because we have already proven the correctness of process creation.
This $yieldBack$ rule also 
adjust the memory by using our \textit{algebraic memory model} discussed in Sec.~\ref{sec:multi-threaded-partial}
to shift the next 
available block to the proper position for the thread. 
Note that this lifting will return the identical memory as a result when all threads are available.


\para{Building initial state}
In this stage, all threads in the CPU ($c$) are in the set of our full thread set ($\fullthreadset$), and this implies that all threads will return a valid private data with $f_{\dproc}$.
However, this private abstract data is purely local, and threads cannot touch 
others' local values, even if other threads are its children.
This implies that each thread has its own responsibility to build its initial state. 
To handle this initial state building, we introduce an abstract definition,
${\small  \initdproc \in Z \rightarrow \mathrm{option}\ \dproc }$,
 that gets a thread id and an initial shared log 
for the thread and returns proper initial values by searching the information inside its initial shared log. 
Definitely, this initial shared log should contain sufficient information to build an initial private state for each thread.
However, like other definitions in our $\EAsmM{}$ machine model, 
we do not have to concretely define this abstract definition at all
at this step. 
We leave them as an abstract one in our language level for us to design a general multithreaded machine model as much as possible.
Then, an initial abstract state ($f_\dproc$) of $\EAsmM{[c, \fullthreadset]}$ will be defined as 
\begin{small}
\[
\mathsf{map}\ (\mathsf{fun}\ i \Rightarrow (\mathsf{Some}\ \initdproc(i))) \ \fullthreadset
\]
\end{small}
, and we show the correctness of this mechanism while proving refinement theorems, 
both in the language level refinement 
and the concrete layer refinement.
Finally, with the whole thread set on CPU $c$, we are able to show the refinement theorem between two different machine models.
\begin{theorem}[$\EAsmM{}$ refines $\AsmLM$]
\label{theorem:easm_refine_lasm}
\begin{small}
Assume that the simulation relation between $\AsmLM$ and $\EAsmM{}$ is $\simrel(st_{\EAsmM{}}, st_{\AsmLM})$.
In addition, suppose that there exists a layer definition, $\mathrm{PH}$, that satisfies an abstract relation, $\absrel(\simrel(st_{\EAsmM{}}, st_{\AsmLM}), \mathrm{PH}, \Lbthread)$. Then,
$$\ltyp{(c, \oracle\vdash_{\AsmLM} L_\comm{bthread})}{\absrel(\simrel(st_{\EAsmM{}}, st_{\AsmLM}), \mathrm{PH}, \Lbthread)}
{\varnothing}{(\fullthreadset, \oracle^t,  c, \oracle  \vdash_{\EAsmM{}} \mathrm{PH})}$$
\end{small}
\end{theorem}

 $\proofcase{initial\_state}$ We show that there exists a valid initial state of $\AsmLM$ which satisfies the simulation relation
$\simrel$ with the initial machine state of $\EAsmM{}$, which is stated as follows:
$$\simrel(init\_st_{\EAsmM{}}, init\_st_{\AsmLM})$$
This proof is based on the induction on our full thread set, $\fullthreadset$. 
The base case is trivial because a thread set in this case is an empty set.
For the inductive case, our proof relies on the abstract relation, $\absrel(\simrel(st_{\EAsmM{}}, st_{\AsmLM}), \mathrm{PH}, \Lbthread)$, which states the fact that
 all thread in the set also satisfies the simulation relation. 
This is because we do not have concrete data type definitions, a concrete layer definition, and other concrete definitions yet. 
Showing the fact that our concrete implementation satisfies  $\absrel(\simrel(st_{\EAsmM{}}, st_{\AsmLM}), \mathrm{PH}, \Lbthread)$ can be done when we introduce actual implementations for all abstract definitions.

$\proofcase{one\_step\_refinement}$
Next step is showing the fact that when $\simrel(st_{\EAsmM{}}, st_{\AsmLM})$ and when we have one step evaluation on $\EAsmM{}$, which is $\fullthreadset, \oracle^t, c, \oracle  \vdash_{\EAsmM{}} st_{\EAsmM{}} \ni st'_{\EAsmM{}} $, 
then there exists a $st'_{\AsmLM}$ that satisfies 
$$c, \oracle, \vdash_{\AsmLM{}} st_{\AsmLM} \ni st'_{\AsmLM} \wedge \simrel(st'_{\EAsmM{}}, st'_{\AsmLM})$$
or when the current evaluation of $\EAsmM{}$ is either $\yield$ or $\sleep$ case, 
$$\vert st_{\EAsmM{}} \vert > \vert st'_{\EAsmM{}} \vert \wedge \simrel(st'_{\EAsmM{}}, st_{\AsmLM})$$
when $\vert st_{\EAsmM{}} \vert$ is defined as $1$ if the type of the last event in the shared log of $st_{\EAsmM{}}$ 
is neither $\primevunit{\yield}$ nor $\primevunit{\sleep}$ and $0$ otherwise.

Proving this property requires case analysis on $\EAsmM{}$ evaluation rules, and it  
also heavily relies on the abstract definition,  $\absrel(\simrel(st_{\EAsmM{}}, st_{\AsmLM}), \mathrm{PH}, \Lbthread)$.
For most cases except $\yield$ and $\sleep$, one step in $\EAsmM{}$ with $\fullthreadset$ 
is exactly matched with one step in $\AsmLM$, and we can show the existence of $st'_{\AsmLM}$ that satisfies 
$c, \oracle\vdash_{\AsmLM{}} st_{\AsmLM} \ni st'_{\AsmLM} \wedge \simrel(st'_{\EAsmM{}}, st'_{\AsmLM})$.

In the $\yield$ case, we delay the evaluation of $\AsmLM$ because there is no evaluation rule in $\AsmLM$
which is exactly matched with this $\yield$ evaluation rule in $\EAsmM{}$. 
This is because we define the context switching behavior 
as two steps in our multithreaded concurrent machine model.
Therefore, instead of providing the next state of $\AsmLM$ and showing the existence of corresponding 
evaluation in $\AsmLM$, 
we show that this 
case satisfies $\vert st_{\EAsmM{}} \vert > \vert st'_{\EAsmM{}} \vert \wedge \simrel(st'_{\EAsmM{}}, st_{\AsmLM})$, 
which delays the evaluation in $\AsmLM$. 
Similar to the $\yield$ case, we show that the $\sleep$ case also 
satisfies $\vert st_{\EAsmM{}} \vert > \vert st'_{\EAsmM{}} \vert \wedge \simrel(st'_{\EAsmM{}}, st_{\AsmLM})$.

In the $yieldBack$ case, the rule guarantees that the previous evaluation rule in $\EAsmM{}$ was either $\yield$ or $\sleep$ 
by its condition (\textit{i.e.} $last\_event(l) = ev \wedge (ev = (\_, (nb, \_)) \vee ev = (\_, (\_, nb, \_)))$).
If the previous evaluation rule was the $\yield$ evaluation rule,
then the $yieldBack$ evaluation combined with the previous $\yield$ evaluation in $\EAsmM{}$
will be matched with the $\yield$ primitive evaluation in $\AsmLM$. 
Therefore, we can provide a valid next state of $\AsmLM$, which satisfies the simulation relation with the next state of 
$\EAsmM{}$. If the previous evaluation on $\EAsmM{}$ was $\sleep$, then the proof will be quite similar.

%%% PARTIAL EASM %%%%%%%%
\subsection{Partial Multithreaded Machine Model and Linking}\label{subsec:singleeasm}

The next step in defining thread-local layer interface
is replacing other threads' evaluation using the strategy as we have already seen in Fig.~\ref{fig:thread-linking}. 
In this step, our machine does not guarantee that the scheduled thread id is always a member 
unning or available threads because the machine is not a total machine on CPU $c$. 
If the thread is not in both cases, we categorize it as a thread with an $\mathrm{Environment}$ state.
To handle the case,
$\EAsmM{}$ has a $\mathrm{Environment}$ rule
\begin{small}
\begin{mathpar}
\inferrule{
\updatefun_{init}(l) = ds \\
\procid(ds) = curid \\ 
f_{\threadstate}(curid) = \mathrm{Environment} \\
f_{\dproc}(curid) = None \\ 
\oracle^{t}(T_a) = \varphi^{T_a}\\
\varphi^{T_a}(l) = ev\\
l' = ev::l\\
\updatefun_{init}(l') = ds' \\
\procid(ds') = curid' \\ 
}{
\threadset_a, \oracle^t, c, \oracle\vdash_\comm{EAsm} \sstep{\empty}{[]}{curid, f_{\threadstate}, m, l, f_{\dproc}}
 {\{ \}, curid', f_{\threadstate}, m, l', f_{\threadstate}}
}
\end{mathpar}
\end{small}
, when $\threadset_a$ is a set of thread that is currently available. 
With a partial thread set, if the current thread $curid$ is in a set of $\fullthreadset - \threadset_a$ 
(\textit{i.e.} $curid \in (\fullthreadset - \threadset_a)$),
we query our strategy using the current log and append the event that are performed by other threads to the current log.
For example, if the current full thread set is $\fullthreadset$ is $\{0, \ 1 \}$,
and we define a partial machine that only has $\{0\}$ as a currently available thread set, 
the environmental context for thread-local machine will be parameterized by $\{0\}$.
After that, the machine becomes a single threaded machine model, 
which contains $\{0\}$ as an only available or a running thread in the set.  
Even for the case with more than 2 threads, applying this step iteratively until the currently available thread set $\threadset_a$ become a singleton set is a key idea of our framework to build a thread-local machine. 

\para{Thread Linking}
To link multiple thread-local machines as one multithreaded concurrent machine,  
we perform the above iteration of building a single-threaded concurrent machine model in a reversed way.
Let us first focus on two single-threaded concurrent machine models, 
$\EAsmM{[c, \{0\}]}$ and $\EAsmM{[c, \{1\}]}$.
Then, partial maps for thread private data ($f_\dproc$) of $\EAsmM{[c, \{0\}]}$ 
and of $\EAsmM{[c, \{1\}]}$ will be defined as\newline
\noindent
\begin{minipage}[t]{.5\textwidth}
\begin{small}
\[
f_{\dproc}(i):=
\begin{cases}
 \comm{Some \ d} & \comm{when} \ i = 0\\
\comm{None} & \text{otherwise}
\end{cases}
\]
\end{small}
\end{minipage}
\begin{minipage}[t]{.5\textwidth}
\begin{small}
\[
f_{\dproc}(i):=
\begin{cases}
 \comm{Some \ d} & \comm{when} \ i = 1\\
\comm{None} & \text{otherwise}
\end{cases}
\]
\end{small}
\end{minipage}
respectively.
Then, merging those two partial maps will be 
\begin{small}
\[
f_{\dproc}(i):=
\begin{cases}
 \comm{Some \ d} & \comm{when} \ i = 0 \vee i = 1\\
\comm{None} & \text{otherwise}
\end{cases}
\]
\end{small}
, which simply merge two maps together. 
For the partial map of the private register set, we can do the similar merging.
In terms of environmental context, both machines have the same environmental context, which is 
$\oracle^{t}$ even though they have different strategies from each other ($\oracle^{t}(\{0\})$ and $\oracle^{t}(\{1\})$).
With those environmental contexts, 
building $\oracle^{t}(\{0, 1\})$ is straightforward. 
We need to either  exclude the event generated by thread 1 from $\oracle^{t}(\{0\})$ or 
exclude the event generated by thread 0 from $\oracle^{t}(\{1\})$.
Then, having those two single-threaded local machines, we can merge their private states, registers, and a environmental context, 
and thus build a two-threaded concurrent machine model, $\EAsmM{[c, \{0, 1\}]}$.
If $\fullthreadset = \{0, 1\}$, then we do not need further merging, 
and the machine directly turns into a total concurrent machine 
model $\EAsmM{[c, \fullthreadset]}$. 
If not, we pick one thread $i$ (\textit{i.e.} $i \in (\fullthreadset - \{0, 1\})$), 
and merge the thread again with the exactly 
same process that we have done for thread $0$ and thread $1$.
Generalizing this method makes our framework link two multithreaded machine models 
when two machines contain disjoint thread sets as their available (or running) thread sets.
When we define the operator for the above merging process as $\join$, which performs the above 
process for merging,
we can show when $\EAsmM{[c, \threadset_{left}]}$ and $\EAsmM{[c, \threadset_{right}]}$,
there always exists a valid composed concurrent machine.
\begin{small}
\[
\EAsmM{[c, \threadset_{left} \cup \threadset_{right}]} = \EAsmM{[c, \threadset_{left}]}\ \join\ \EAsmM{[c, \threadset_{right}]}
 \]
 \end{small}
when $\threadset_{\mathrm{left}}$ and $\threadset_{\mathrm{right}}$ are disjoint with each other.
We have also proved the refinement for this linking too.

\begin{lemma}
\begin{small}
$$\ltyp{(\{\mathrm{left}, \mathrm{right}\}, \oracle^t, c, \oracle  \vdash_{\EAsmM{}} \mathrm{PH})}{}{\varnothing}
{(\{\mathrm{left}\}, \oracle^t, c, \oracle \vdash_{\EAsmM{}} \mathrm{PH}
 \join \{\mathrm{right}\}, \oracle^t, c, \oracle  \vdash_{\EAsmM{}} \mathrm{PH})}
$$
\end{small}
\label{lemma:thread-single-compose}
\end{lemma}%
This lemma requires a lot of auxiliary lemmas and definitions.
Honestly, the proof is one of the most complex one among our whole proofs.
However, the basic idea is simple and really intuitive.


$\proofcase{initial\_state}$ 
Initial states of both machines in the right-hand side of the lemma, 
which are $\EAsmM{[c, \mathrm{\{left\}}]}$ and $\EAsmM{[c, \mathrm{\{right\}}]}$
will have the same shared log ($nil$) and the memory (the clean state). 
Therefore, we can easily  get those fields in the initial state 
of the left hand side machine, $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$.
For private abstract data and thread state pools of $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$, 
we apply our join operation on initial states of $\EAsmM{[c, \mathrm{\{left\}}]}$ and $\EAsmM{[c, \mathrm{\{right\}}]}$. 
By doing that, we can successfully construct an initial state of $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$.

$\proofcase{one\_step\_refinement}$
Assuming that either $\EAsmM{[c, \mathrm{\{left\}}]}$ or  $\EAsmM{[c, \mathrm{\{right\}}]}$  performs one step
evaluation. 
And, the other one of them performs more than zero step evaluation. 
For the simplicity in this proof, we assume that $\EAsmM{[c, \mathrm{\{left\}}]}$ do one step evaluation and $\EAsmM{[c, \mathrm{\{right\}}]}$ do  star step (more than zero step) evaluations.
In this case, we can find at least more than one step evaluation on $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$
that can be matched with both evaluations on the right-hand side. 
Intuitively, this is simply replacing some environment steps in either $\EAsmM{[c, \mathrm{\{left\}}]}$ or $\EAsmM{[c, \mathrm{\{right\}}]}$ into other evaluation steps 
(\textit{i.e.} external, primitive, $\yield$, $\sleep$, and $yieldBack$ steps) in $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$.
To prove this one, we need to do case analysis on the single step evaluation rules in $\EAsmM{[c, \mathrm{\{left\}}]}$.
All cases except the one, an environmental step, we can directly find out the matched state and one step evaluation in
$\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$ because the current running thread is ``$\mathrm{left}$''. 
In the environmental step, $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$ either performs one environmental step or 
replaces the step into other evaluation rules (possibly multiple steps) that are performed by ``$\mathrm{right}$'' 
by additional case analysis on the event generated by the environmental step.
When the event generated by environmental step is not by $\mathrm{right}$, 
then $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$ will also do the single environmental step. 
However, if the event in the environmental step is raised by $\mathrm{right}$, we will replace the environmental step 
with star step evaluations on $\EAsmM{[c, \mathrm{\{right\}}]}$.
This star step may contain multiple silent steps that only affects the private data of $\mathrm{right}$.
In this case, we can update the corresponding private data in $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$ by apply the 
same star steps in $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$.
Therefore, we are always able to provide the matched state and evaluation rules for $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$.

\ignore{
\noindent This theorem guarantees that,
once the multithreaded machine $\TAsm$ consists of
the whole thread set,
 the properties of  threads running on top
can be propagated down to the layer that has concrete
scheduling implementations.
}
By generalizing this lemma, we can prove the general linking theorem. 
\begin{theorem}[Multithreaded Machine Model Linking]
\begin{small}
$$\ltyp{(\fullthreadset, \oracle^t, c, \oracle  \vdash_{\EAsmM{}} \mathrm{PH})}{}
{\varnothing}{\join_{tid \in T_{\mathrm{full}}} ( \{tid\}, \oracle^t, c, \oracle\vdash_{\EAsmM{}} \mathrm{PH})}$$
\end{small}
\label{theorem:thread-full-compose}
\end{theorem}

Proving this theorem is generalization of the previous Lemma (Lemma~\ref{lemma:thread-single-compose}). 
One limitation in our merging operator is one of two partial $\EAsmM{}$ machines that we want to merge should have a singleton set as its available thread set. 
By restricting this aspect, we can 
prove this theorem by doing case analysis on the evaluation rules with singleton $\EAsmM{}$.
The proof is quite similar to the proof for Lemma~\ref{lemma:thread-single-compose}.


\ignore{One more additional theorem that we can easily achieve with this approach is also important for us to build out thread-local layer interface.

\begin{theorem}[Single Threaded $\EAsmM{}$ Refines Full Threaded $\EAsmM{}$]
\begin{small}
$$\forall\ tid,\ tid\ \in\ \fullthreadset,\ (\ltyp{ \fullthreadset, \oracle^{t}, c, \oracle \vdash_{\EAsmM{}} \mathrm{PH})}{}
{\varnothing}{(\{tid\}, \oracle^{t}, c, \oracle \vdash_{\EAsmM{}} \mathrm{PH})})$$
\end{small}
\label{theorem:full-easm-refines-single-easm}
\end{theorem}}

\ignore{
$\proofcase{initial\_state}$ 
The initial shared log and the initial memory will be same in both side. 
And,  the private data pool of $\EAsmM{[c, \fullthreadset]}$ will contain the proper initial private data 
for 

$\proofcase{one\_step\_refinement}$
Assuming that either $\EAsmM{[c, \mathrm{\{left\}}]}$ or  $\EAsmM{[c, \mathrm{\{right\}}]}$  performs one step
evaluation. 
And, the other one of them performs more than zero step evaluation. 
For the simplicity in this proof, we assume that $\EAsmM{[c, \mathrm{\{left\}}]}$ do the one step evaluation and $\EAsmM{[c, \mathrm{\{right\}}]}$ do the star step (more than zero step) evaluation.
In this case, we can find at least more than one step evaluation on $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$
that can be matched with both evaluations on the right-hand side. 
Intuitively, this is simply replacing some environmental steps in either $\EAsmM{[c, \mathrm{\{left\}}]}$ or $\EAsmM{[c, \mathrm{\{right\}}]}$ with other evaluation steps 
(\textit{i.e.} external, primitive, $\yield$, $\sleep$, and $yieldBack$ steps) in $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$.
To prove this one, we need to do the case analysis on the single step evaluation in $\EAsmM{[c, \mathrm{\{left\}}]}$.
All cases except the one, an environmental step, we can directly find out the matched state and one step evaluation in
$\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$ because the current running thread is ``$\mathrm{left}$''. 
In the environmental step, $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$ either performs one environmental step or 
replaces the step with other evaluation rules (possibly multiple steps) that are performed by ``$\mathrm{right}$'' 
by an additional case analysis on the event generated by the environmental step.
When the event generated by environmental step is not by $\mathrm{right}$, 
then $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$ will also do the single environmental step. 
However, if the event in the environmental step is by $\mathrm{right}$, we will replace the environmental step 
with star step evaluations on $\EAsmM{[c, \mathrm{\{right\}}]}$.
This star step may contain multiple silent steps that only affects the private data of $\EAsmM{[c, \mathrm{\{right\}}]}$.
In this case, we can update the corresponding private data in $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$ by apply the 
same star steps in $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$.
Therefore, we are always able to provide the matched state and evaluation rules for $\EAsmM{[c, \mathrm{\{left, rihgt\}}]}$.
}



\subsection{Intermediate Thread-Local Machine Model}\label{subsec:tasm}

Now, we have already gotten a single threaded machine model, which gives us a full isolation.
However, $\EAsmM{}$ itself is quite different with $\AsmLM$ in terms of its state definition and evaluation rules,
so it is hard for us to show the refinement relation between this $\EAsmM{}$ and $\AsmLM$ directly. 
Especially, yield back and environmental steps in $\EAsmM{}$ does not match well with our $\AsmLM$ rules. 
If we keep those operational style strategy query evaluation, it is hard for us to define a single step behavior of 
scheduling primitives in our thread-local layer interface.
To bridge the gap between $\EAsmM{}$ and $\AsmLM$,
we have introduced one more intermediate machine model, $\TAsmM{[c, \curthread]}$. 
In here, the machine is always parameterized by a fixed thread id, which we will always notate as $\curthread$. 
And using this variable, we define this machine's state as
\begin{small}
\[
st_{TAsm} = (\curthread, \ \regs_{\curthread}, \dproc_{\curthread}, \SLog) 
\]
\end{small}
, which has a shared log and only one private data for the thread.
In this machine, all other threads' steps should be replaced by environmental steps
as our single-threaded concurrent machine model, $\EAsmM{[c, \{current\_thread\}]}$, does.
In addition to that, to define a single step behavior of scheduling primitives in our thread-local machine, a big-step style strategy query function has 
been introduced as
\begin{small}
\[{\small
\begin{array}{l}
\oracle^{t} \vdash \getenvlog\ (limit :\mathbb{N})\ (l: \SLog ):  \SLog  \\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ :=
\begin{cases}
\ \ \mathrm{None}\hfill (\mathrm{when} \ limit = 0) \\
\ \ \mathrm{Some} \ l \hfill (\mathrm{when} \ \procid{\updatefun_{init}(l)} = \curthread) \\
\ \ \oracle^{t} \vdash \getenvlog((limit - 1), ((\oracle^{t}(\{\curthread\})(l))::l))\ \ \ \ \  \ \ \ \ \ 
\hfill (\mathrm{Otherwise})\\
\end{cases} 
\end{array}
}\]
\end{small}
, which queries the strategy iteratively until the current thread gets the evaluation control again.

Using the definition, $\TAsmM{[c, current\_thraed]}$ can merge multiple strategy queries during yield call as a single one, 
and the yield evaluation rule for $\TAsmM{[c, current\_thraed]}$ is defined as
\begin{small}
\begin{mathpar}
\inferrule{
\updatefun_{init}(l) = ds \\
\procid(ds) = \curthread \\ 
\statecheck(\yield, [],ds,\snapfun(d)) \\ 
f_{\dproc}(curid) = Some\ d \\ 
\nextblockfun(m) = nb \\ 
l' = (\curthread , ([], nb, \snapfun(d)))::l \\
\oracle^{t} \vdash \getenvlog(limit, l') = l'' \\
last\_event(l) = ev \\
ev = (\_, (nb, \_)) \vee ev = (\_, (\_, nb, \_))  \\
\liftnextblock{m}{nb - \nextblock{m}} = m' \\
l''' = (\curthread , \yieldbackunit)::l''\\
%\oracle, c\vdash \sstepr{\spec_{id}}{[largs]}{\regs, m, ds, d}{\textit{res}\cup \{\}}{\regs',  m', ds', d'}
}{
\curthread, \oracle^{t}, c, \oracle \vdash_\comm{TAsm} \sstep{\yield}{[]}{\curthread, \regs, m', l, d}
 {\{ \}, \curthread, \regs', m', l', d}
}
\end{mathpar}
%\vspace{-5px}
\end{small}%
Intuitively, this rule first updates the current shared log by adding one yield event 
and perform the strategy query using the log.
If the current strategy returns a log as its result,
this yield rule updates the machine state using
the information that the machine has gotten from the querying. 
Note that the currently-running thread information and a private abstract data do not change at all 
during this yield call. 
From $\TAsmM{}$, all machines are thread-local, 
and scheduling primitives will not perform any context switching at all. 
Since the differences between $\TAsmM{}$ and $\EAsmM{}$ are only in the state definition 
and the way to handle yield and sleep evaluations, 
we can easily prove the following theorem by doing case analysis:

\begin{theorem}[$\TAsmM{}$ refines $\EAsmM{}$]
\begin{small}
$$\ltyp{(\{\curthread\}, \oracle^{t}, c, \oracle  \vdash_{\EAsmM{}} \mathrm{PH})}{}{\varnothing}
{(\curthread, \oracle^{t}, c, \oracle \vdash_{\TAsmM{}} \mathrm{PH})}$$
\end{small}
\label{theorem:tasm-refines-easm}
\end{theorem}

With the given simulation relation, $\simrel(st_{\TAsmM{}}, st_{\EAsmM{}})$, we also need to show the following two cases.

$\proofcase{initial\_state}$ 
The proof for this case requires additional lemmas.
This is because in $\TAsmM{}$, a shared log of the initial state is already $\SLog_{init}$ of the current thread.
In the case of $\EAsmM{}$, however, a shared log of the initial state is always $nil$. 
Therefore, we need to prove the statement, which is when we have a $init\_st_\TAsmM{}$ and a $init\_st_\EAsmM{}$, there always exist valid more than zero steps in $\EAsmM{}$ and the state $st_{\EAsmM{}}$ which satisfies
$$ \{\curthread\}, \oracle^{t}, c, \oracle\vdash_{\TAsmM{}} init\_st_{\EAsmM{}} \ni^{*} st_{\EAsmM{}} \wedge \simrel(init\_st_{\TAsmM{}}, st_{\EAsmM{}})$$
Intuitively, the lemma implies that we need to apply $\EAsmM{}$'s evaluation rules to its initial state for environment threads until we get $\SLog_{init}$ as a shared log of the state.

Proofs for this lemma requires us to work with the induction on $\SLog_{init}$ for the current thread.
If the initial log is $nil$, the initial state of $\EAsmM{}$ will be directly matched with the initial state of $\TAsmM{}$, which is $\simrel(init\_st_{\TAsmM{}}, init\_st_{\EAsmM{}})$.
In the inductive case, we use the well-formedness condition of our $\SLog_{init}$. 
This enforces that the initial log should be 
either $nil$ or only contain events generated by other threads except the last one $yieldBack$ event as well as 
the log should have a valid event that creates the current thread at some point.
This well-formedness condition is not a magic in our proof because it can be removed when we link all threads together 
(we already show the way to link multiple threads in the previous section).
Then, we know that all events except the last $yieldBack$ are
 generated by other threads in our environment, and cannot contain
any events raised by the current thread. 
Since the current $\EAsmM{}$ that we are considering is a single threaded machine parameterized by
a singleton set, $\{\curthread\}$, we know that all evaluation to generate the exactly same log with the initial log (for $\curthread$) on $\EAsmM{}$ should be on environment step of $\EAsmM{}$ except the last one $yieldBack$ rule after the current 
thread get a control for its evaluation. 
Therefore, we can provide the $st_{\EAsmM{}}$ which satisfies
$$\{\curthread\}, \oracle^{t}, c, \oracle \vdash_{\TAsmM{}} init\_st_{\EAsmM{}} \ni^{*} st_{\EAsmM{}} \wedge \simrel(init\_st_{\TAsmM{}}, st_{\EAsmM{}})$$


$\proofcase{one\_step\_refinement}$
Next step is showing the fact that when $\simrel(st_{\TAsmM{}}, st_{\EAsmM{}})$ and 
when we have one step evaluation on $\TAsmM{}$, 
which is $\curthread, \oracle^{t}, c, \oracle \vdash_{\TAsmM{}} st_{\TAsmM{}} \ni st'_{\TAsmM{}} $, 
then there exists a $st'_{\EAsmM{}}$ that satisfies 
$$\{\curthread\}, \oracle^{t}, c, \oracle \vdash_{\TAsmM{}} st_{\EAsmM{}} \ni^{+} st'_{\EAsmM{}} \wedge \simrel(st'_{\TAsmM{}}, st'_{\EAsmM{}})$$

Proving this property requires case analysis on $\TAsmM{}$ evaluation rules.

For all cases except scheduling rules in $\TAsmM{}$ (\textit{i.e.} $\yield$ and $\sleep$ rules), 
we can provide a next state in $\EAsmM{}$ ($st'_{\EAsmM{}}$) directly, which satisfies $\{\curthread\}, \oracle^{t}, c,\oracle \vdash_{\EAsmM{}} st_{\EAsmM{}} \ni st'_{\EAsmM{}} \wedge \simrel(st'_{\TAsmM{}}, st'_{\EAsmM{}})$.

In case of the $\yield$ evaluation rule in $\TAsmM{}$, let's assume that 
a shared log in $st_{\TAsmM{}}$ is $l$, and $\oracle^{t} \vdash \getenvlog{}$ returns a shared log $l''$ with an arbitrary big number $limit$ and the 
given argument $l'$ (\textit{i.e.} $l' = (\curthread , ([], nb, \snapfun(d)))::l$) when $d$ is a 
private state of $st_{\TAsmM{}}$ and $nb$ is a next available block of the memory in $st_{\TAsmM{}}$). 
With this result, a shared log in $st'_{\TAsmM{}}$ will be $(\curthread , \yieldbackunit)::l''$.
Then, by its definition, there always exists a valid $l_{added}$ which satisfies $l'' = l_{added} {+\!\!+} l'$.
Therefore, we can prove this case by doing an induction on $l_{added}$. 
If the log ($l_{added}$) is $nil$, then, we simply match this one $\yield$ evaluation rule 
(that updates the log as $l'''$) with one step $yield$ and one step $yieldBack$ rules in $\EAsmM{}$.
Therefore, we can provide a valid $st'_{\EAsmM{}}$ 
which satisfies $\{\curthread\}, \oracle^{t}, c,\oracle \vdash_{\EAsmM{}} st_{\EAsmM{}} \ni^{+} st'_{\EAsmM{}} \wedge \simrel(st'_{\TAsmM{}}, st'_{\EAsmM{}})$.
In the inductive case, $\EAsmM{}$ needs to perform an evaluation with its environment rule which will add one event 
into its shared log at every time. 
Other rules will not be applied to generate the next $\EAsmM{}$ state because all threads except
$\curthread$ are in the state of $\mathrm{Environment}$ now. 
Therefore, we also can provide a valid new state, $st'_{\EAsmM{}}$ that satisfies 
$\{\curthread\}, \oracle^{t}, c,\oracle \vdash_{\EAsmM{}} st_{\EAsmM{}} \ni^{+} st'_{\EAsmM{}} \wedge \simrel(st'_{\TAsmM{}}, st'_{\EAsmM{}})$ and which is doing its evaluation by applying one $\yield$ rule, multiple environment 
rules, and one $yieldBack$ rule of $\EAsmM{}$ on $st_{\EAsmM{}}$.

In the case of the $\sleep$ evaluation rule in $\TAsmM{}$, we also can provide a valid $st'_{\EAsmM{}}$ that satisfies 
$\{\curthread\}, \oracle^{t}, c, \oracle\vdash_{\EAsmM{}} st_{\EAsmM{}} \ni^{+} st'_{\EAsmM{}} \wedge \simrel(st'_{\TAsmM{}}, st'_{\EAsmM{}})$ by using the similar approach with the $\yield$ case.


\subsection{Thread-Local Machine Model}\label{subsec:hasm}
By applying the whole process on $\Lbthread$ that we have mentioned,
we finally can define thread-local layer interface  discussed in Sec.~\ref{subsec:phthreadlayer}.
The machine model for thread-local layer interface is almost same with the machine model of CPU-local layer interface, which is $\AsmLM$.
Therefore, we are able to 
utilize the whole power of \compcertx\ and build thread-local layers both written in C and in Assembly with the guarantee that those layers preserve the same behavior in our CPU-local machine.
This machine model, however, has two differences with  $\AsmLM$.
First, as mentioned in Sec.~\ref{subsec:phthreadlayer}, the evaluation semantics
for $\yield$ and $\sleep$ is totally changed as no-op like evaluations.
This difference is already dealt with multiple steps of refinement with several different machine models. 
In this sense, no additional steps are required to handle this issue.
Second, the machine allows a dynamic initial state for each thread, and this dynamically assigned 
initial state should be satisfied by our system invariant.
To resolve this challenge, 
Our thread-local layer interface provides one abstract definition that will be
instantiated with a concrete layer and a data structure implementation later.

The abstract function, $\composedata$, has a type of
\begin{small}
\[
\composedata : \mathbb{Z} \rightarrow \dshare \rightarrow \dproc \rightarrow adt
\]
\end{small}
which gets the current thread id, a shared data, and a private data as its arguments 
and returns a \textit{abstract data} for $\AsmHM$ with the current thread id.
With this function, an initial state of a thread-local layer interface with the current thread id ($\curthread$) will be 
as
\begin{small}
\[
\composedata(\curthread, \ \updatefun_{init}(\SLog_{init}), init\_dproc(\curthread))
\]
\end{small}
This definition also gives consistency between our multithreaded concurrent machine model 
and this thread-local machine model.
When looking at the initial state definition for $\EAsmM{}$ in Sec.~\ref{subsec:fulleasm},
finding the similarity between both definitions is straightforward.
For the guarantee about preserving our system invariant in the initial state, we only need to prove that 
the calculated initial state satisfies our invariant.

With the all stated ingredients during multiple previous sections, we can prove the following refinement theorem:
\begin{theorem}[$\AsmHM$ Refines $\TAsmM{}$]
\begin{small}
Assume that the simulation relation between $\TAsmM{}$ and $\AsmHM$ is $\simrel(st_{\AsmHM}, st_{\TAsmM{}})$.
In addition, suppose that there exists a layer definition, $\mathrm{PH}$, that satisfies an abstract relation, 
$\absrelt(\simrel(st_{\AsmHM}, st_{\TAsmM{}}), \Lhthread, \mathrm{PH})$. Then,
$$\ltyp{(\curthread, \oracle^{t}, c, \oracle \vdash_{\TAsmM{}} \mathrm{PH})}
{\absrelt(\simrel(st_{\AsmHM}, st_{\TAsmM{}}), \Lhthread, \mathrm{PH})}
{\varnothing}{(\curthread, \oracle^{t}, c, \oracle \vdash_{\AsmHM} \Lhthread)}$$
\end{small}
\label{theorem:hasm-refines_tasm}
\end{theorem}%

$\proofcase{initial\_state}$ We show that there exists a valid initial state of $\TAsmM{}$ which satisfies our simulation relation
$\simrel$ with an initial machine state of $\AsmHM$, which is stated as follows:
$$\simrel(init\_st_{\AsmHM}, init\_st_{\TAsmM{}})$$
This proof relies on the abstract relation $\absrelt(\simrel(st_{\AsmHM}, st_{\TAsmM{}}), \Lhthread, \mathrm{PH})$,
but this case is quite trivial in its essence
because we construct $init\_st_{\AsmHM}$ using a $init\_st_{\TAsmM{}})$ and 
the $\composedata$ function.

$\proofcase{one\_step\_refinement}$
Next step is showing the fact that when $\simrel(st_{\AsmHM}, st_{\TAsmM{}})$ and when we have one step evaluation on $\AsmHM$, which is $\oracle, \ c, \oracle^{t}, \curthread \vdash_{\AsmHM} st_{\AsmHM} \ni st'_{\AsmHM} $, 
then there exists a $st'_{\TAsmM{}}$ that satisfies 
$$\curthread, \oracle^{t}, c, \oracle \vdash_{\TAsmM{}} st_{\TAsmM{}} \ni st'_{\TAsmM{}} \wedge \simrel(st'_{\AsmHM}, st'_{\TAsmM{}})$$

Proving this property requires case analysis on $\AsmHM$ evaluation rules, and it  
also heavily relies on the abstract definition,  $\absrelt(\simrel(st_{\AsmHM}, st_{\TAsmM{}}), \Lhthread, \mathrm{PH})$.

For all cases except the external call evaluation rule in $\AsmHM$, 
we can provide a valid $st'_{\TAsmM{}}$ directly, which satisfies $\curthread, \oracle^{t}, c, \oracle \vdash_{\TAsmM{}} st_{\TAsmM{}} \ni st'_{\TAsmM{}} \wedge \simrel(st'_{\AsmHM}, st'_{\TAsmM{}})$.

For the external call case, we need additional case analysis.
When the primitive is neither $\yield$ nor $\sleep$, then the matched
evaluation rule in $\TAsmM{}$ will also be the external evaluation rule. 
Then, we can provide a next state, $st'_{\TAsmM{}}$, that satisfies $\curthread, \oracle^{t}, c, \oracle \vdash_{\TAsmM{}} st_{\TAsmM{}} \ni st'_{\TAsmM{}} \wedge \simrel(st'_{\AsmHM}, st'_{\TAsmM{}})$.

If the primitive is one of $\yield$ and $\sleep$, we match the evaluation with the $\yield$ evaluation rule in $\TAsmM{}$ or 
the $\sleep$ evaluation rule in $\TAsmM{}$, respectively.
Then, we can also provide a valid $st'_{\TAsmM{}}$ that satisfies $\curthread, \oracle^{t}, c, \oracle \vdash_{\TAsmM{}} st_{\TAsmM{}} \ni st'_{\TAsmM{}} \wedge \simrel(st'_{\AsmHM}, st'_{\TAsmM{}})$.

Now, we can finally prove that our thread-local machine refines our CPU-local machine and our fully linked thread-local machine refines our 
CPU-local machine. 
The first property gives us a source to build thread-local layers and the second one guarantee our thread-local machine behavior is consistent with 

\ignore{
\begin{theorem}[$\AsmHM$ refines $\AsmLM$]
\begin{small}
Assuming two machines, $\AsmHM$ and $\AsmLM$. Then we can show that
$$\ltyp{(c, \oracle \vdash_{\AsmLM} \Lbthread)}
{}
{\varnothing}{(\curthread, \oracle^{t}, c, \oracle \vdash_{\AsmHM} \Lhthread)}$$
when $\curthread$ is a member of threads on CPU $c$, and when we have valid abstract relations
$\absrel$ and $\absrelt$ with the abstract intermediate layer $\mathrm{PH}$ on $\EAsmM{}$ and $\TAsmM{}$.
\end{small}
\label{theorem:tasm_refines_lasm}
\end{theorem}%

By using Theorem~\ref{theorem:easm_refine_lasm},~\ref{theorem:full-easm-refines-single-easm},~\ref{theorem:tasm-refines-easm}~\ref{theorem:hasm-refines_tasm}, we can show that the theorem is correct.
}
The second theorem in here is more detailed version of Theorem~\ref{theorem:thread-full-compose} by exposing several hidden definitions to simplify the theorem. 

\begin{theorem}[Merged $\AsmHM$ refines $\AsmLM$]
\begin{small}
Assuming two machines, $\AsmHM$ and $\AsmLM$ and $\fullthreadset$ contains all available threads on CPU $c$.
. Then we can show that
$$\ltyp{(c, \oracle \vdash_{\AsmLM} \Lbthread)}
{}
{\varnothing}{\join_{tid \in \fullthreadset} (\curthread, \oracle^{t}, c, \oracle \vdash_{\AsmHM} \Lhthread)}$$
when we have valid abstract relations $\absrel$ and $\absrelt$ with the abstract intermediate 
layer $\mathrm{PH}$ on $\EAsmM{}$ and $\TAsmM{}$.
\end{small}
\label{theorem:tasm_refines_lasm}
\end{theorem}%

By using Theorem~\ref{theorem:easm_refine_lasm},~\ref{theorem:thread-full-compose},~\ref{theorem:tasm-refines-easm}~\ref{theorem:hasm-refines_tasm}, we can show that the theorem is correct.



\subsection{Layer Refinement for Thread Linking}\label{subsec:concrete-impl}

From Sec.~\ref{subsec:lowlevelasm} to Sec.~\ref{subsec:hasm} ,
we show the whole process to 
build a thread-local layer interface
that tackles 
multiple challenges stated in Sec.~\ref{subsec:fulleasm}.
However, introducing this interface does not mean that all about building thread-local layers and 
linking multiple thread-local layers are straightforward. 
When looking at the refinement theorems in previous sections,
some are purely logical and only depend on machine model levels, 
but two of them, Theorem~\ref{theorem:easm_refine_lasm} and Theorem~\ref{theorem:hasm-refines_tasm} 
are relying on the abstract relation between two layers. 
To prove them, we have to introduce the instance of $\mathrm{PH}$ which satisfies both 
$\absrel(\simrel(st_{\EAsmM{}}, st_{\AsmLM}), \mathrm{PH}, \Lbthread)$ and 
$\absrelt(\simrel(st_{\AsmHM}, st_{\TAsmM{}}), \Lhthread, \mathrm{PH})$.
This instantiation also includes how we define concrete implementations of
abstract definitions that we have introduced in our multiple machine models. 
In this sense, we introduce a concrete layer $\Lhbthread$, an instance of $\mathrm{PH}$
to give the evidence for the abstract definition in those two refinement theorems.

Instantiating $\Lhbthread$ contains multiple challenges, too.
We first need to divide $adt$ in $\AsmLM$ $\AsmHM$  into two separate data types, $\dshare$ and $\dproc$, and
define specifications  $(\spec^{_{def}}_{_{id}})$  for all primitives (except $\yield$ and $\sleep$) 
and memory access semantics based on the  
newly defined data types. 
Obviously, some data structures, such as a memory page permission table or an IPC (inter process communication) channel, 
cannot be trivially divided into into multiple thread-wise data structures.
In this sense, dividing the whole data structure of concurrent system requires a deep knowledge about how the system works,
and requires an amount of effort. 

In addition, proving concrete implementations for all abstract definitions that we have introduced to model multiple intermediate machines
is an another step of works in this phase. 
For example, $\updatefun$ should have concrete definitions for the primitives that raise events
and the behavior of the function have to be consistent with the specifications of those primitive 
in terms of updating shared data states. 
Also, $\initdproc$ needs to search a proper thread-create event 
and construct a valid initial private data for each thread.
This behavior also keeps a consistent behavior with that of thread creation in CPU-local machine in 
$\Lbthread$. 

When looking at the details of $\absrelt$, which relies on $\simrel(st_{\AsmHM}, st_{\TAsmM{}})$,
most cases in the simulation relation are straightforward because 
the relation is between two thread-local machines even though their machine models are different. 
With the given relation, providing the evidence of $\absrelt$ consists of 
1) all primitive specifications in $\Lhthread$ on $\AsmHM$ is consistent with the all primitive specifications in 
$\Lhbthread$ on $\TAsmM{}$, and
2) all primitive can generate a proper event in $\TAsmM{}$. 

However, $\absrel$ with $\simrel(st_{\EAsmM{}}, st_{\AsmLM})$ contains a plethora of challenges and corner cases. 
Defining a simulation relation between the shared data in $\EAsmM{}$ with the corresponding data in $\AsmLM$ is simple. 
On the other hand, in several cases in the private data, defining a simulation relation 
contains a lot of sophisticated cases because here is the place that we actually link per-thread data structures as 
a single per CPU data structures.
For example, to divide user memory to each thread successfully, 
exclusiveness property of our memory page allocation mechanism should be guaranteed and proved. 
To guarantee the consistent behavior between 
 $\EAsmM{}$ and $\AsmLM$ in user context values, our simulation relation
has to distinguish the case when the thread is not created yet and the case after it is created.
This implies that we have to prove several additional lemmas for all primitives 
including  disjoint property of user memories, 
and correctness of thread-local behavior in thread creation and IPC, etc.
With those auxiliary lemmas and simulation relation, proving the evidence of $\absrel$ consists of 
1) all primitive specifications in $\Lhbthread$ on $\EAsmM{}$ with all threads on CPU $c$ are consistent with  all primitive specifications in $\Lbthread$ on $\AsmLM$ with CPU $c$, and
2) all events have consistent behaviors with corresponding primitive specifications in terms of shared data updating.

By introducing evidences of those two abstract relations, $\absrel$ and $\absrelt$, we finally achieve an instance for a thread-local layer interface, and link multiple thread-local layers to refine it into a single CPU-local layer.
This separation between a machine level and an actual implementation level not only makes us to enable our thread linking but also
gives us generality and scalability 
of our thread-linking framework.
$\Lbthread$ and $\Lhthread$ layers contain more than $35$ primitives. 
If we prove the refinement property for all primitives in all different machine level refinement theorems, 
the proof size will become much bigger than now and 
easily become unmanageable even though we use an interactive theorem prover, Coq, to prove them. 
However, thanks to our decoupling in our modeling and proofs, we can successfully prove these all related proofs about thread linking with reasonable efforts.
In addition to that,
if we want to add more primitives in $\Lbthread$  and $\Lhthread$, we do not need to prove the whole refinement and linking theorems 
that we have stated in previous sections. 
All those theorems will remain as same, and
the thing that we only have to change is updating $\absrel$ and $\absrelt$ instances according to the newly added data structures and primitives.




%\section{Multithreaded Linking}
%\label{sec:multithreaded}
%
%\subsection{Build Environment for Multithreaded Linking}
%\label{subsec:sworacle}
%
%\subsection{Introduce Multithreded Machine} 
%\label{subsec:mt-full-machine}
%
%\subsubsection{Memory Compositionality}
%\label{subsubsec:mt-memory-compositionality}
%
%\subsubsection{Dynamic Initialization}
%\label{subsubsec:mt-dynamic-initialization}
%
%\subsection{Introduce Singlethreaded Machine}
%\label{subsec:mt-single-machine}
%
%\subsection{Link with Compiler}
%\label{subsec:mt-link}
%
%
%\subsection{Thread Linking Example}
%\label{subsec:mt-link-example}
