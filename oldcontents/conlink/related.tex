\section{Related Work and Conclusions}
\label{sec:related}

\paragraph{Certified Abstraction Layers.} \cite{dscal15}
presented the first formal account of certified abstraction layers and
showed how to apply layer-based techniques to build certified system
software. The layer-based approach differs from Hoare-style program
verification~\cite{hoare69,reynolds02,boogie05,nanevski06} in several
significant ways. First, it uses the termination-sensitive forward
simulation techniques~\cite{Lynch95,compcert} and proves a stronger
contextual correctness property rather than simple partial or total
correctness properties (as done for Hoare logics).
%%%%%
Second, the overlay interface of a certified layer object completely
removes the internal concrete memory block (for the object) and
replaces it with an abstract state suitable for reasoning; this
abstract state differs from auxiliary or ghost states (in Hoare
logic) because it is actually used to define the semantics of the
overlay abstract machine and the corresponding contextual refinement
property.
%%%%%
Third, as we move up the abstraction hierarchy by composing more
layers, each layer interface provides a new programming language that gets
closer to the specification language---it can call primitives at
higher abstraction levels while still supporting general-purpose
programming in C and assembly.

Our CCAL toolkit follows the same layer-based methodologies. Each time
we introduce a new concrete concurrent object implementation, we
replace it with an abstract atomic object in its overlay
interface. All shared abstract states are represented as a single
global log, so the semantics of each atomic method call would need to
{\em replay} the entire global log to find out the return value.  This
seemingly ``inefficient'' way of treating shared atomic objects is
actually great for compositional specification. Indeed, it allows us
to apply game-semantic ideas and define a general semantics that
supports parallel layer composition.

\paragraph{Abstraction for Concurrent Objects.}
\cite{herlihy90} introduced {\em linearizability} as a key technique
for building abstraction over concurrent objects. Developing
concurrent software using a stack of shared atomic objects has since
become the best practice in the system
community~\cite{Herlihy08book,ospp11}. Linearizability is quite
difficult to reason about, and it is not until 20 years later that
\cite{filipovic10} showed that linearizability is actually equivalent
to a termination-insensitive version of the contextual refinement
property. \cite{Gotsman12concur} showed that such equivalence also
holds for concurrent languages with ownership
transfers~\cite{ohearn:concur04}.  Liang et al.~\cite{liang13,lili16} showed that linearizability plus various
progress properties~\cite{Herlihy08book} for concurrent objects is
equivalent to various termination-sensitive versions of the contextual
refinement property. These results convinced us that we should prove
termination-sensitive (contextual) simulation when building certified
concurrent layers as well.

\para{RGSim and LiLi.} Building contextual refinement proofs
for concurrent programs (and program transformations) is challenging.
Liang~{et~al.}~\cite{RGSim,Liang14lics,lili16} developed the
Rely-Guarantee-based Simulation (RGSim) that can support both parallel
composition and  contextual refinement of concurrent
objects. Our contextual simulation proofs between two concurrent
layers can be viewed as an instance of RGSim if we extend RGSim with
auxiliary states such as environment contexts and shared logs. This
extension, of course, is the main innovation of our new compositional
layered model. Also, all existing RGSim systems are limited to reasoning
about atomic objects at one layer; their client program context cannot
be the method body of another concurrent object, so they cannot
support the same general vertical layer composition as our work does.

\ifTR{\cite{lili16} also developed a program logic called LiLi that can
directly prove both the linearizability and starvation freedom (or
deadlock-freedom) properties. Their ``rely'' conditions are specified
over shared states only, so they cannot express temporal properties. To
prove progress, they have to introduce a separate temporal ``rely''
condition called {\em definite actions}.  This made it difficult to
provide a standalone (total) specification for each lock acquire
method.  Indeed, all examples in their paper are code fragments that
must acquire a lock, then perform critical-section tasks, and then release the
lock. In contrast, our environment context can specify the full
strategies (i.e., both the past and the future events) of all
environment threads and the scheduler, so we can readily impose
temporal invariants over the environment. Within each thread-modular
layer $L[t]$, we can show that each lock acquire primitive (e.g., for
ticket locks) always returns as long as its environment is cooperative
(e.g., always releases its acquired lock), even if $t$ itself may not
be cooperative.
In other words, the termination of $t$'s lock acquire
operation does not depend on whether $t$ itself will release the lock
after first acquiring it.}{}

\para{Treatment of Parallel Composition.}
Most concurrent languages (including those used by RGSim) use a
parallel composition command $(C_1 \| C_2)$ to create and terminate
new threads.  In contrast, we provide thread spawn and join
primitives, and assign every new thread a unique ID (e.g., $t$, which
must be a member of the full thread-ID domain set $D$). Parallel layer
composition in our work is always done over the whole program $P$ and over
all members of $D$. This allows us to reason about the current
thread's behaviors over the environment's full strategies (i.e., both
past and future events). Even if a thread $t$ is never
created, the semantics for running $P$ over $L[t]$ is still well
defined since it will simply always query its environment context to
construct a global log.

\para{Program Logics for Shared-Memory Concurrency.}
A large body of new program
logics~\cite{ohearn:concur04,brookes:concur04,feng07:sagl,vafeiadis:marriage,LRG,verifast,gotsman13,Turon13popl,Turon13icfp,nanevski13,nanevski14,sergey15,sergey15pldi,pinto14,iris15,civl15,pinto16,xu16}
have been developed to support modular verification of shared-memory
concurrent programs. Most of these follow Hoare-style logics so they
do not prove the same strong contextual simulation properties as RGSim
and our layered framework do. Very few of them (e.g.,~\cite{pinto16})
can reason about progress properties. Nevertheless, many of these
logics support advanced language features such as higher-order functions
and sophisticated non-blocking synchronization, both of which will be
useful for verifying specific concurrent objects within our layered
framework. Our use of a global log is similar to the use of compositional
subjective history traces~\cite{sergey15}; the main difference is
again that our environment context can talk about both past and future
events but a history trace can only specify past events.

Both CIVL~\cite{civl15} and FCSL~\cite{sergey15pldi} attempt to build
proofs of concurrent programs in a ``layered'' way, but their notions
of layers are different from ours in three different ways: (1) they do
not provide formal foundational contextual refinement proofs of
linearizability as shown by \cite{filipovic10} and \cite{liang13};
(2) they do not address the liveness properties; (3) they have not be
connected to any verified compilers.

\para{Compositional CompCert.}
\cite{stewart15} developed a new compositional extension of the
original CompCert compiler~\cite{compcert} with the goal of providing
thread-safe compilation of concurrent Clight programs.  Their
interaction semantics also treats all calls to synchronization
primitives as external calls. Their compiler does not support a layered
ClightX language as our CompCertX does, so they cannot be used
to build concurrent layers as shown in Fig.~\ref{fig:arch}. 

\para{Game Semantics.} Even though we have used
game-semantic concepts (e.g., strategies) to describe our
compositional semantics, our concurrent machine and the layer simulation is still defined using
traditional small-step semantics.  This is in contrast to several past
efforts~\cite{ghica08,nishimura13,rideau11,abramsky99} of modeling
concurrency in the game semantics community which use games to
define the semantics of a complete language. Modeling higher-order
sequential features as games is great for proving full abstraction,
but it is still unclear how it would affect large-scale 
verification as done in the certified software community.  We 
believe there are great potential synergies between the two communities
and hope our work will promote such interaction.

\para{OS Kernel Verification.} There has been a large body
of recent work on OS kernel verification including
seL4~\cite{klein2009sel4,klein14},
%CertiKOS~\cite{dscal15,chen16,costanzo16}, 
Verve~\cite{hawblitzel10},
and Ironclad~\cite{ironclad14}. None of these works have addressed the
issues on concurrency with fine-grained locking. Very recently,
\cite{xu16} developed a new verification framework based on RGSim
and Feng~{et~al.}'s program logic~\cite{feng08:aim} for reasoning
about interrupts; they have successfully verified many key modules
(in C) in the $\mu$C/OS-II kernel, though so far, they have not proved
any progress properties.


\para{Conclusions.}
Abstraction layers are key techniques used in building large-scale
concurrent software and hardware. In this paper, we have presented
CCAL---a novel programming toolkit developed under the CertiKOS project for building certified concurrent
abstraction layers.  We have developed a new compositional model
for concurrency, program verifiers for concurrent C and assembly,
certified linking tools, and a thread-safe verified C compiler. 
We believe these are critical technologies 
for developing large-scale certified system infrastructures in the future.

\section*{Acknowledgments}
We would like to thank our shepherd Grigore Rosu and anonymous
referees for helpful feedbacks that improved this paper significantly.
This research is based on work supported in part by NSF grants 1521523
and 1715154 and DARPA grants FA8750-12-2-0293, FA8750-16-2-0274, and
FA8750-15-C-0082. Tahina Ramananandro's work was completed while he
was employed at Reservoir Labs, Inc. Hao Chen's work is also supported
in part by China Scholarship Council.  The U.S. Government is
authorized to reproduce and distribute reprints for Governmental
purposes notwithstanding any copyright notation thereon. The views and
conclusions contained herein are those of the authors and should not
be interpreted as necessarily representing the official policies or
endorsements, either expressed or implied, of DARPA or the
U.S. Government.



\para{Distributed System Verification} IronFleet~\cite{ironfleet} is built on the Dafny language, 
which allows the developer to annotate functions with pre- and post-conditions that are automatically proved 
by an underlying SMT (satisfiability modulo theories) solver.
Dafny code can be compiled into C\# and eventually into assembly~\cite{ironclad}. 
The verification of distributed protocols in IronFleet requires refinement proofs among three layers: 
implementation, distributed protocol, and high level specifications.
The verification of distributed protocols is not fully machine-checked because
it requires hand written proofs to show that the atomic protocol step of the implementation
is equivalent to the interleaved protocol steps in the real world.
Our framework, on the other hand, enables fully machine-checkable verification and starts from a completely interleaved asynchronous network model.

Verdi~\cite{verdi} presents a distributed system verification tool chain, 
where developers specify and implement a system using a functional language embedded in Coq.
The initial step of the development assumes a perfect network model, and later a transformer
in the tool chain automatically converts the system into one that can handle a more realistic network and fault model.
The tool chain can then extract executable OCaml code from the transformed program.
However, this approach can have limitations when the system to be verified is inherently designed for faulty network models, as is the case for Raft or Paxos.
Our framework is able to handle such systems by starting with very weak network assumptions.
Additionally, we verify C code and link it with a verified compiler~\cite{compcert} so our TCB does not include any compilers or runtime environments.

DISEL~\cite{disel} is another distributed system verification framework developed 
by overlapping authors of Verdi. DISEL enables multiple distributed protocols 
to be composed and verified in a system. 
DISEL allows protocols that touch disjoint states to be verified
separately and later composed by using a send-hook
that restricts the interfering behaviors among protocols. 
Similarly, our framework can verify different protocols in separate layers in isolation and then combine them not only horizontally as DISEL does,
but also vertically to hide verification details from the higher layers while preserving verified properties.

Brisk~\cite{canonical} is a tool that can automatically verify the absence of deadlocks in certain distributed systems
by synthesising the canonical sequentialization of a program.
This is very related to network reductions (discussed in Section \ref{subsec:link-with-low-level-code-verification})
in that it relies on the fact that program behavior sometimes remains the same even when certain network events are rearranged.
In particular, this is true if a program satisfies the symmetric non-determinism condition, which means
that every receive either has a unique corresponding send, or choosing any of multiple possible matching sends results in the same state.
Although Brisk can synthesise canonical sequentializations automatically, it has some limitations compared to manual proofs
of network reductions.
In particular, it cannot handle error cases from an unreliable network such as duplicated packets or timeouts.

\para{Paxos Verification and Deconstruction}
Within the category of distributed system verification, there is a significant amount of work focusing specifically on Paxos.
Lamport's first paper on the protocol~\cite{paxos}, and his second attempt to explain it more clearly~\cite{paxosmadesimple}
present the basic algorithm and give paper proofs of the safety properties.
Since then, many variations have been developed such as Disk Paxos~\cite{diskpaxos}, Egalitarian Paxos~\cite{epaxos},
and Vertical Paxos~\cite{vertpaxos}.
Oftentimes, although these variations seem similar to the original protocol, it is not possible to reuse the original
proof of the safety properties and a significant amount of work is required to re-prove them.
Lampson attempted to distill Paxos into its core components by creating a very high-level Abstract Paxos~\cite{Lampson2001}
and showing how other variants can be derived from it.
Some still felt that this did not get at the essence of the algorithm because at least two works since then \cite{dpaxos, sdpaxos}
have studied other ways of dividing Paxos into simpler components such that proofs of the protocol can be made more modular.
Our write-witness-passing approach also attempts to find a reusable framework for these proofs,
but instead of decomposing Paxos further, we make the key implicit invariants more explicit by passing around
the information needed to prove them.

%Many efforts have been recently made to formally verify distributed systems with machine checkable verification tools. IronFleet~\cite{ironfleet} and Verdi~\cite{verdi} are distributed system verification frameworks that use distributed consensus as a target exampmle for verification. The protocol layer of IronFleet is equivalent to the \globalstate{} of our framework where all proof about distributed protocols take place. In part, due to the limitation of verification tool that IronFleet uses, the network model required pencil and paper proof to show that an arbitrarily interleaved network model refines the IronFleet's network model. Verdi verifies distributed systems under an idealized network model, and presents transformations that preserve correctness to a weaker network model. However, this approach had limitations to fully verify systems that are inherently designed for weak network models. Our framework starts from a fully asynchronous network which is verfied only using machine checkable tools.

%unreliable network to begin with. While both papers propose a systematic way to verify a standalone distributed 
system, we employ a modular layer-based verification approach to enable extensible verification, where the 
proofs can be reused and connected with new verified application layers in the stack. 

%It is well known that modularity leads to ease of verification. DISEL~\cite{disel} verifies independent distributed protocols in isolation and horizontally combines them. Taube et al.~\cite{modular} explores modularity for automated distributed system verification. A modularity based Paxos verification~\cite{dpaxos,sdpaxos} was explored but in pencil and paper proofs. 

%Prior work has examined a layered storage system verification for crash safety~\cite{vijay,fscq, pushbuttonfs}
Prior work has examined layered logical storage stacks to simplify storage system 
verification for crash safety~\cite{fscq, pushbuttonfs,vijay}.
WOR shares the same insight about modularity, 
but leverages contextual refinement to provide incremental and extensible verification; 
enables both vertical and horizontal composition of layers; and verifies correctness 
in a concurrent and distributed environment. 

%Contextual refinement encapsulates proofs in each layer, enables both vertical and 
horizontal composition of layers, and facilitates verifying WOR layer correctness against a 
high-order concurrent and distributed environment, which is simply passed as a context.
Our verification approach can reason about different protocols independently in separate layers;
our layered verification encapsulates the verification details and enable horizontal and vertical compositions. 

%Formal verification plays a key role for guaranteeing 
the correctness of security features~\cite{vale, komodo, ironclad, expressos}. 
While WOR's proof does not focus on security, adding security features to the system 
and guaranteeing the security properties across WOR and application layers is a direction for future work.  

%We uses the same CCAL approach~\cite{deepspec, concurrency} as CertiKOS~\cite{certikos:osdi16}. While CertiKOS first demonstrated the 
power of CCAL by verifying an entire OS, our verification showed that combination of CCAL the witness passing apprach provides a powerful framework for distributed system verification.

%FSCQ filesystem~\cite{fscq} uses a chain of modules to verify . 
While WOR layers mostly depend on only one layer, FSCQ modules often dependend 
on multiple modules for verification. Yggdrasil~\cite{pushbuttonfs} also introduces layers to verify a filesystem. 
While Yggdrasil verifies each layer's implementation refines the specification, 
the refinement relation between layers 

%There have been many efforts to verify distributed systems in the systems and 
programming languages communities. 
The approaches that have been used have different strengths, 
weaknesses and philosophies.


A push button verification approach, which is based on the Z3 SMT solver, 
was used to verify a filesystem and an OS. 
Its primary benefit is a low verification burden: careful writing of the specification for 
the SMT solver can automate the verification process 
and SMT solver yields a counter example for a failed verification. 
Push button verification mostly focuses on the functional correctness proofs and its tool chain
that compiles the code to C or binary is not fully verified. 
The push button approach currently does not support verifying concurrency nor concurrent distributed systems.

\para{Certified Abstraction Layers}
The first formal presentation of how to use certified abstraction layers to verify large systems
was given by \cite{deepspec}.
\cite{concurrency} then showed how the framework could be extended to support concurrency.
One of the key strengths of this approach over other verification frameworks
is its support for contextual refinement.
This enables proofs to be done in a thread-local (or node-local) manner using an environment context to
capture the behavior of the rest of the world.
These proofs can then be linked together to obtain a strong correctness theorem for the entire system.

Our write-witness-passing framework benefits greatly from using CCAL.
By decomposing distributed systems into layers, we reduce the amount of time and effort needed to
prove functional correctness.
By treating each distributed node as a separate thread, we can use the environment context to
prove properties in a local context.
Combining this with write-witness-passing then allows us to bring in information about the global state when necessary.
We also use the environment context to model a realistic, non-deterministic network.
Another advantage afforded by CCAL is that we can lift our safety proofs to higher layers via contextual refinement.
This allows us to implement and verify a system once, and then reuse it as a component in various distributed applications.

%\para{Certified Abstraction Layers} \cite{deepspec}
presented the first formal account of certified abstraction layers and
showed how to apply layer-based techniques to build certified system
software. The layer-based approach differs from Hoare-style program
verification~\cite{hoare69,reynolds02,boogie05,nanevski06} in several
significant ways. First, it uses the termination-sensitive forward
simulation techniques~\cite{Lynch95,compcert} and proves a stronger
contextual correctness property rather than simple partial or total
correctness properties (as done for Hoare logics).
%%%%%
Second, the overlay interface of a certified layer object completely
removes the internal concrete memory block (for the object) and
replaces it with an abstract state suitable for reasoning; this
abstract state differs from auxiliary or ghost states (in Hoare
logic) because it is actually used to define the semantics of the
overlay abstract machine and the corresponding contextual refinement
property.
%%%%%
Third, as we move up the abstraction hierarchy by composing more
layers, each layer interface provides a new programming language that gets
closer to the specification language---it can call primitives at
higher abstraction levels while still supporting general-purpose
programming in C and assembly.

% We follows the same layer-based methodologies. Each time
 we introduce a new concrete concurrent object implementation, we
 replace it with an abstract atomic object in its overlay
 interface. All shared abstract states are represented as a single
 global log, so the semantics of each atomic method call would need to
 {\em replay} the entire global log to find out the return value.  This
 seemingly ``inefficient'' way of treating shared atomic objects is
 actually great for compositional specification. Indeed, it allows us
 to apply game-semantic ideas and define a general semantics that
 supports parallel layer composition.

% \para{Abstraction for Concurrent Objects}
 \cite{herlihy90} introduced {\em linearizability} as a key technique
 for building abstraction over concurrent objects. Developing
 concurrent software using a stack of shared atomic objects has since
 become the best practices in the system
 community~\cite{Herlihy08book,ospp11}. Linearizability is quite
 difficult to reason about, and it is not until 20 years later that
 \cite{filipovic10} showed that linearizability is actually equivalent
 to a termination-insensitive version of the contextual refinement
 property. \cite{Gotsman12concur} showed that such equivalence also
 holds for concurrent languages with ownership
 transfers~\cite{ohearn:concur04}.  Liang et al.~\cite{liang13,lili16} showed that linearizability plus various
 progress properties~\cite{Herlihy08book} for concurrent objects is
 equivalent to various termination-sensitive versions of the contextual
 refinement property. These results convinced us that we should prove
 termination-sensitive (contextual) simulation when building certified
 concurrent layers as well.

\ignore{
\wolf{I'm not sure if this is so relevant to this work. And if it is then I'm not sure how best to rewrite it to make that clear}
\para{RGSim and LiLi}
Building contextual refinement proofs
for concurrent programs (and program transformations) is challenging.
Liang~{et~al.}~\cite{RGSim,Liang14lics,lili16,xu16} developed the
Rely-Guarantee-based Simulation (RGSim) that can support both parallel
composition and  contextual refinement of concurrent
objects. Our contextual simulation proofs between two concurrent
layers can be viewed as an instance of RGSim if we extend RGSim with
auxiliary states such as environment contexts and shared logs. This
extension, of course, is the main innovation of our new compositional
layered model. Also, all existing RGSim systems are limited to reasoning
about atomic objects at one layer; their client program context cannot
be the method body of another concurrent object, so they cannot
support the same general vertical layer composition as our work does.

\cite{lili16} also developed a program logic called LiLi that can
directly prove both the linearizability and starvation-freedom (or
deadlock-freedom) properties. Their ``rely'' conditions are specified
over shared states only, so they cannot express temporal properties. To
prove progress, they have to introduce a separate temporal ``rely''
condition called {\em definite actions}.  This made it difficult to
provide a standalone (total) specification for each lock acquire
method.  Indeed, all examples in their paper are code fragments that
must acquire a lock, then perform critical-section tasks, and then release the
lock. In contrast, our environment context can specify the full
strategies (i.e., both the past and the future events) of all
environment threads and the scheduler, so we can readily impose
temporal invariants over the environment. Within each thread-modular
layer $L[t]$, we can show that each lock acquire primitive (e.g., for
ticket locks) always returns as long as its environment is cooperative
(e.g., always releases its acquired lock), even if $t$ itself may not
be cooperative.
In other words, the termination of $t$'s lock acquire
operation does not depend on whether $t$ itself will release the lock
after first acquiring it.
}

%\para{Treatment of Parallel Composition}
Most concurrent languages (including those used by RGSim) use a
parallel composition command $(C_1 \| C_2)$ to create and terminate
new threads.  In contrast, we provide thread spawn and join
primitives, and assign every new thread a unique ID (e.g., $t$, which
must be a member of the full thread-ID domain set $D$). Parallel layer
composition in our work is always done over the whole program $P$ and over
all members of $D$. This allows us to reason about the current
thread's behaviors over the environment's full strategies (i.e., both
past and future events). Even if a thread $t$ is never
created, the semantics for running $P$ over $L[t]$ is still well
defined since it will simply always query its environment context to
construct a global log.

% \para{Program Logics for Shared-Memory Concurrency}
 A large body of new program
 logics~\cite{ohearn:concur04,brookes:concur04,feng07:sagl,vafeiadis:marriage,LRG,verifast,gotsman13,Turon13popl,Turon13icfp,nanevski13,nanevski14,sergey15,sergey15pldi,pinto14,iris15,civl15,pinto16,xu16}
 have been developed to support modular verification of shared-memory
 concurrent programs. Most of these follow Hoare-style logics so they
 do not prove the same strong contextual simulation properties as RGSim
 and our layered framework do. Very few of them (e.g.,~\cite{pinto16})
 can reason about progress properties. Nevertheless, many of these
 logics support advanced language features such as high-order functions
 and sophisticated non-blocking synchronization, both of which will be
 useful for verifying specific concurrent objects within our layered
 framework. Our use of a global log is similar to the use of compositional
 subjective history traces~\cite{sergey15}; the main difference is
 again that our environment context can talk about both past and future
 events but a history trace can only specify past events.

% Both CIVL~\cite{civl15} and FCSL~\cite{sergey15pldi} attempt to build
 proofs of concurrent programs in a ``layered'' way, but their notions
 of layers are different from ours in three different ways: (1) they do
 not provide formal foundational contextual refinement proofs of
 linearizability as shown by \cite{filipovic10} and \cite{liang13};
 (2) they do not address the liveness properties; (3) they have not be
 connected to any verified compilers.

%\para{Compositional CompCert}
\cite{stewart15} developed a new compositional extension of the
original CompCert compiler~\cite{compcert} with the goal of providing
thread-safe compilation of concurrent Clight programs.  Their
interaction semantics also treats all calls to synchronization
primitives as external calls. Their compiler does not support a layered
ClightX language as our CompCertX does, so they cannot be used
to build concurrent layers as shown in Fig.~\ref{fig:arch}. 

% \para{Game Semantics} Even though we have used
 game-semantic concepts (e.g., strategies) to describe our
 compositional semantics, our concurrent machine and the layer simulation is still defined using
 traditional small-step semantics.  This is in contrast to several past
 efforts~\cite{ghica08,nishimura13,rideau11,abramsky99} of modeling
 concurrency in the game semantics community which use games to
 define the semantics of a complete language. Modeling higher-order
 sequential features as games is great for proving full abstraction,
 but it is still unclear how it would affect large-scale
 verification as done in the certified software community.  We
 believe there are great potential synergies between the two communities
 and hope our work will promote such interaction.

\ignore{
\wolf{this would be mostly redundant with the first two paragraphs if we made it about distributed system verification}
\para{Other Verification Works} There has been a large body
of recent work on  program verification. 
seL4~\cite{klein2009sel4,klein14},
CertiKOS~\cite{certikos-osdi16}, Verve~\cite{hawblitzel10},
and Ironclad~\cite{ironclad}. None of these works have addressed the
issues on concurrency with fine-grained locking. Very recently,
\cite{xu16} developed a new verification framework based on RGSim
and Feng~{et~al.}'s program logic~\cite{feng08:aim} for reasoning
about interrupts; they have successfully verified many key modules
(in C) in the $\mu$C/OS-II kernel, though so far, they have not proved
any progress properties.

\jieung{The following parts are the thing that we have dumped from the OSDI18 paper. we have to 
rephrase the previous part and the following part as well as add some distributed system verification works - 
Especially, PLDI18, OOPSLA17a, OOPSLA17b, (POPL18, ESOP18 - DISEL related), (CPP, PLDI - verdi)}
}

\para{Distributed systems} A number of abstractions similar to the WOR exist in theoretical distributed systems,
 including sticky registers~\cite{stickyregister}, consensus objects~\cite{herlihy1991wait}, and the Paxos register~
 \cite{li2007paxos}; however, these are abstractions for theoretical reasoning, rather than for programming or code 
 verification. Other theoretical work points out the link between fault-tolerant atomic commit and consensus~
 \cite{frolund2001implementing, hadzilacos1990relationship}. SWMR (single writer many reader) registers support a 
 single writer (which can write multiple times) and many readers; they can  be used to implement a WOR using a 
 protocol like Disk Paxos~\cite{diskpaxos}.

A number of abstractions similar to the WOR exist in theoretical distributed systems, including sticky registers~
\cite{stickyregister}, consensus objects~\cite{herlihy1991wait}, and the Paxos register~\cite{li2007paxos}; however, 
these are abstractions for theoretical reasoning, rather than for programming or code verification. Other theoretical 
work points out the link between fault-tolerant atomic commit and consensus~\cite{frolund2001implementing, 
hadzilacos1990relationship}. SWMR (single writer many reader) registers are atomic registers that support a single 
writer (which is allowed to write multiple times) and many readers. SWMRs can be used to implement a WOR using a 
protocol like Disk Paxos~\cite{diskpaxos}.

SWMR (single writer many reader) registers are atomic registers that support a single writer (which is allowed to write 
multiple times) and many readers. SWMRs can be used to implement a WOR using a protocol like Disk Paxos~
\cite{diskpaxos}.

%The Paxos Register~\cite{li2007paxos} -- this looks clearly different from what we do, but how precisely?\\
The Paxos Register~\cite{li2007paxos} presents the classic single-degree non-Byzantine and Byzantine Paxos 
algorithms using the analogy of a ``register". Here, a register corresponds to the
value stored in the acceptors, and reading and writing a register corresponds,
respectively, to the prepare and accept phases of the original algorithm.
Place in context with Fast Paxos~\cite{fastpaxos}, Disk Paxos~\cite{diskpaxos}, Cheap Paxos~\cite{cheappaxos}. Are 
these different implementations of a WOR?

%Distributed applications often use services that embed consensus or replication protocols, 
such as Chubby~\cite{chubby} and Zookeeper~\cite{zookeeper}.
 WOR supports a more primitive abstraction compared to these services.
Horus~\cite{horus} is a modular stack for group communication that led to a verification effort called Ensemble~\cite{ensemble}. 
Distributed transaction systems~\cite{janus, tapir} often 
combine transaction protocols with consensus protocols, 
`opening the Paxos box' to implement different optimizations. 
These could conceivably be implemented over the WOR API in the same manner as the optimizations 
in Section \ref{sec:wormtx}.
The WOR APIs could conceivably be used to implement similar optimizations without rewiring the Paxos protocol.