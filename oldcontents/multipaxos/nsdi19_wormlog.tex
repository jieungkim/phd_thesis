\subsection{WormLog over \sysname{}}

\begin{figure}
\centering
\includegraphics[page=1]{pics/pics-smaller.pdf}
\caption{WormLog: clients can append by obtaining a token from the sequencer and writing to \sysname{}.\label{fig:wormlogarch}}
\vspace{-0.1in}
\end{figure}

A shared log is a shared address space that provides an \api{append} / \api{read} API to clients. CORFU~\cite{corfu} is a system that implements a shared log API over a set of write-once addresses. To append a new entry to the shared log, a client first contacts a centralized sequencer machine to reserve and increment a tail position on the address space. It then issues a write to a write-once address. In CORFU, each write-once address is implemented via a client-driven variant of Chain Replication, where the client writes to each replica in sequence. The write-once semantics are derived by using the head replica of the chain to arbitrate between competing writes to the same address. A key aspect of this design is that the sequencer is merely a soft-state hint about the tail of the log, and does not have to be durable or available. 

Achieving a CORFU-like design over \sysname{} is straightforward: we simply have each client contact a sequencer node when it wants to append an entry, obtain a slot in the \sysname{} address space, and then write to that position (Figure~\ref{fig:wormlogarch}). With this design (which we call WormLog), we obtain the two properties that differentiate a shared log from a Multi-Paxos system~\cite{corfupaxos}: the decoupling of sequencing from I/O, since the sequencer does not see the append payload; and the time-slicing of individual commands over different replica sets, assuming that the \WOS{} size is small compared to the volume of in-flight appends in the system.

WormLog addresses a problem with the CORFU system's use of Chain Replication: appends no longer take latency linear in the number of replicas, since they simply issue a \sysname{} \prepare{}/write, which in turn invokes the Paxos two-phase protocol. However, the WormLog design described thus far takes three round-trips: one to the sequencer, one to \prepare{} the \WOR{}, and one to write to it. By decoupling I/O from sequencing, we lose `sticky leadership'; we can no longer perform a batch \prepare{} on the \WOS{} and write to the \WOR{} in a single round-trip, since multiple clients are writing to a single \WOS{}.

%In a sense, WormLog confirms the observation that the CORFU design is oblivious to the choice of replication protocol used to implement a single write-once slot~\cite{corfu}.

Eliminating this extra round-trip is simple. The sequencer allocates \WOSes{} before handing out sequence numbers to clients. The sequencer also pre-captures the \WOS{} and provides the client with the captureID; the client can then predicate its write with this captureID. Accordingly, WormLog realizes a CORFU-like design that uses Paxos (reducing latency to 2 round-trips from the $N+1$ required by client-driven Chain Replication). \cuttext{Further, it eliminates the extra \prepare{} round-trip despite CORFU's lack of a leader node, leveraging the \sysname{} API in a simple way.}


%Alternatively, we can avoid having the sequencer pre-capture the \WOS{}, and instead have the client use the \unsafewrite{} API to write to the address without preparing it first, since it is guaranteed to be the only client issuing an unsafe write to that \WOR{}. Even if there are somehow multiple sequencers in the system handing out tokens, only one is guaranteed to successfully allocate each segment; as a result, two clients cannot get the same slot.

\cuttext{One option is to have the sequencer allocate \WOSes{} before handing out sequence numbers to clients. The sequencer can also pre-capture the \WOS{} and provide the client with the captureID; the client can then predicate its write with this captureID. Alternatively, we can avoid having the sequencer pre-capture the \WOS{}, and instead have the client use the \unsafewrite{} API to write to the address without preparing it first, since it is guaranteed to be the only client issuing an unsafe write to that \WOR{}. Even if there are somehow multiple sequencers in the system handing out tokens, it is guaranteed that only one will successfully allocate each segment; as a result, two clients cannot get the same slot from some sequencer.

Alternatively, if we have a fencing mechanism to ensure that there is only one active sequencer in the system, clients can obtain a token from the sequencer, allocate the segment themselves if they are the first to write to it, and then use an \unsafewrite{}. This option is preferable if the sequencer is a passive entity (like a counter in shared memory), and it is easier to ensure that a single sequencer exists in the system than to have it interact with \sysname{}. Our implementation uses the first option: the sequencer allocates and pre-captures the \WOS{}.}
