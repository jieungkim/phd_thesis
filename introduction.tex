The goal of this dissertation is to build formal methods for concurrent program verification and apply those techniques to multiple examples,
in such a way that we can guarantee to users that these systems are reliable and trustworthy not only for the functional correctness but also for other high-level progress properties or the protocol correctness of them. 


\section{Challenges in Concurrent Program Verification}
\label{chapter:introduction:sec:challenges-in-concurrent-program-verification}

The prevalence of concurrent environment brings enormous changes in the software. 
With it, achieving higher performance or more functionality in a single software than before is available by
using interactions among several instances (\ie, multiple threads, nodes, I/O devices,
as well as network) in the system,
but it brings the whole new challenges in terms of providing correctness software. 
Obviously, they are well known to be difficult to get right and to debug because of
numerous number (usually unbounded) of interleavings among multiple components of them.
Testing is necessary to avoid the possible faults of them,
but it is not a promising way to provide the high-assurance of those programs. 
%Due to a plethora of possible interleavings, 
Reproducing a bug is unfeasible unless testers know the precise interleaving order of them. 
In this sense, 
Building reliable concurrent programs 
needs verification of them, which formally shows that those programs correct reflects the 
desirable behavior (\textit{i.e.,} that are stated in their specifications) 
without missing any single interleaving cases. 


In addition to that, 
modern software systems consist of multiple sub-modules in it, which are intimately connected with other modules in the system. 
It brings another source of complexity in the verification. 
Those sub-modules highly depends on others;
thus modular reasoning of each component makes hard.
Because of that, 
software verification is considered as a painful work that requires prohibitive associated costs with difficulty of 
achieving scalability, reusability, as well as extensibility.
For example, 
or example, a famous previous by seL4 team~\cite{klein2009sel4} accomplishes
a breakthrough in the software verification 
by providing the first verified (sequential) microkernel with connecting all proofs in  
 a  mechanized proof assistant, 
 but it required a considerable effort. 
The verification took 11 person-years for 7,500 lines of C codes, but still contains unverified parts (\ie, 1,300 lines of C, 500 lines of assembly, and the compiler
to extract the executable code from the verified C codes.)
%When combined with concurrency,
%some modules facilitate
%shared operations of other modules
%to form the new shared services.
%It also provides another challenge 
%in the concurrent program verification, 
%which has to resolve not only the interleaving among the concurrent instances as well as the dependencies among the sub-modules 
%that forms the entire system.



%%%%%%%% isolation is required

Therefore, modular and compositional reasoning is indispensable in
the concurrent program verification.
The verification 
should be able to decompose the entire system 
into a collection of instances (\ie, multiple threads, a set of nodes, \etc), and furthermore into a stack of modules in each instance;
then it needs to be achieved with each module separately without considering 
complex dependencies or interleavings with other modules and instances on the system. 
It, of course, needs to provide evidence about the consistency with the verification of each module and the behavior of the entire system. 
% 
%which decompose 
%of each building stack in each instance of the entire system (\ie, a software stack of single thread or a single node) separately in its verification
%without directly considering complex interleaving 
%with other components in the system. 
Also, 
this modular and compositional reasoning of software not only
provides an efficient tool for verification,
but also opens the possibility of 
proving the correct behavior of system software that is
usually parameterized by other programs running on them. 
%
%This feature is crucial in some sorts 
%of concurrent programs such as 
%operating systems, libraries, or application interfaces because of the
%proof of them usually needs to be parameterized by 
%other programs running on them. 
%In those cases, composition and proof isolation 
%give enough power to state and prove the correctness property 
%of those programs upon any arbitrary context programs run with the targeted programs. 

%%%%%%%v other previous works 
In this sense, 
multiple previous works handle modular and/or compositional reasoning about programs,
either with concurrency or without it. 
% need separation logic????
There are two different traditional approaches,
rely-guarantee~\cite{jones83} and separation logic~\cite{ishtiaq01} 
and many other approaches that stem from either or both of them
~\cite{feng07:sagl,vafeiadis:marriage,LRG,fu10:roch,sergey15, lili16,Vafeiadis11mfps, Yang07relsep,
Liang14lics}
Besides, some of them are not only focusing on the functional correctness but also 
shows liveness~\cite{lili16}.
Most previous works, however, do not provide the programming framework that addresses all the above challenges in concurrent program verification with a capability of extracting the running code from the program written in low-level programming languages such
as C and assembly. 

\section{Verification Toolkit for Concurrent Programs}
\label{chapter:introduction:sec:verification-toolkit-for-concurrent-programs}
%
%\begin{figure}
%\includegraphics[width=\textwidth]{figs/intro}
%\caption{Verification Toolkit Structure}
%\label{chapter:intro:verific	tion-toolkit-structure} 
%\end{figure}
With those investigations, we present the toolkit that supports modular and compostiional 
verification  for concurrent programs. 
The toolkit consists of two parts;
1) propose the method to build  local layer interfaces for concurrent program verification;
and 2) provide concurrent linking framework.
All layers and linking parts are also connected with the tranditional simulation technique~\cite{compcert, deepspec}. 
 
The first part of our toolkit is to construct certified concurrent 
abstraction layers;
a new compositional model for concurrency, program verifier for concurrent C and assembly,
and a verified C compiler.
Each layer interface in our framework 
works as an executable machine which consists of state and multiple transition rules.
To divide the program into fine-grained pieces,
we follow the idea of 
abstraction layers,
that are widely used in modern computer systems.
Our layered approach also reduces
the complex dependency 
among the sub-modules in the entire system.
Besides, we use the verified compiler for this layered approach to minimize the trusted parts between the verified program and the executable code on a bare machine. 
Programs written and verified with our toolkit uses a subset of C language, 
and it can be compiled into $\intelmachine$ assembly language via using $\compcertx$, the variance of verified C compiler $\compcert$. 

This first part of our verification toolkit has several distinctive features which stem from the requirements of a sizeable concurrent system. 
 First, it is suitable for dealing with the low-level code. 
 To make the proofs tractable we mainly work at the C level (relying on the $\compcert$ verified compiler~\cite{compcert}), 
 but sometimes we need to go lower. 
 For example, the MCS algorithm needs to use atomic CPU instructions (fetch-and-store and compare-and-swap), 
 so we need a way to mix C and assembly code. 
 At the same time, C itself is too low-level to reason about conveniently, 
 so we need data abstraction to hide the details about representation in memory.
 Our toolkit provides an efficient tool to verify C and assembly programs as well as to connect the data abstraction with detailed representations in memory. 
Second, to handle large developments we need separation of responsibilities. 
In a small proof of a small concurrent program in isolation, you can state the specification as a single pre- and post-condition 
which specifies the shape and ownership of the data structure, the invariants 
the liveness conditions, and even the behavior of the entire system.
But such a proof is not modular and not re-usable. In our development, these are done as separate refinement steps, 
in separate modules with explicit interfaces, and can even be the responsibility of different software developers.
Finally, the layers approach is a general purpose, in the sense that the same semantic framework can be used for proving all kinds of properties. 
The model of program execution exposed to the programmer is simple, mostly the same as what you would use for sequential code, 
and with a notion of logs of events to model concurrency. 
We did not have to add any special features to the logic in order to show high-level properties (such as a liveness property), 
because we can directly reason in $\coq$ about how long an execution will take.


The other part of our toolkit is to
provide the connection between multiple concurrent instances in the system.
Our certified concurrent abstraction layers 
provides the way to build and verify 
concurrent programs by decoupling complex interleaving form the correctness proof of each layer in the system.
This compositional requires each layer to use assumptions on the environment of the layer interface, behavior of other concurrent components in the system.
Those assumptions inevitably need to be compatible with 
the properties that others concurrent components can guarantee;
thus proving this property is desirable for our concurrent program verification toolkit. 
To full-fill this requirement, 
we provide the concurrent linking library as a part of our toolkit,
which includes 
defining concurrent machine models, providing generic proof methods to show the validity in the parallel composition of multiple instances 
as well as the formal connection between the program on concurrent machine models and 
the program on the local layer interface. 

Our linking library also has several unique aspects to make it be applied to large concurrent system verification.  
First, our concurrent machine semantics are generic enough to be applied to arbitrary programs written in our layered framework. 
We separate the linking process with the concurrent layer building;
thus users do not have to deal with details of linking itself when they build concurrent layers using our framework. 
Second, it also can be linked with the assembly model for the verified compiler $\compcertx$; thus 
It provides the full formal connection between the program written in C and assembly as well as 
the data abstraction for the detailed data representation on the memory. 
Third, providing complex dependencies among multiple data structures in large concurrent programs. 
It is not only related to the dependencies among shared objects in the program but also related to the dependencies between shared and private objects. 
Our toolkit handles all those issues with reasonable restrictions. 

\section{Concurrent Program Verification Examples}
\label{chapter:introduction:sec:concurrent-program-verification-examples}


As examples of the applicability of our framework,
we verified two large-scale concurrent systems, $\certikos$ and $\wormspace$.
Those two examples also represents tow models for concurrent programs, 
the shared memory model of concurrency and the message-passing model.  

A concurrent operating system is a well-known example of the shared memory model for concurrency that multiple threads in the system share the same physical memory or a common file system. 
Operating system verification has been studied for a while 
with achieving impressive results~\cite{klein2009sel4, xu16, hawblitzel10}.
They, however,  are either lack of supporting fine-grained lock control on shared resources or without progress property proofs of their kernels.
On the other hand, $\certikos$ is the first verified concurrent operating system kernel with fine-grained locking. 
The kernel is written in C and assembly and the extracted code of the kernel (via verified compositional compilation)
runs on  $\intelmachine$ multicore machine. 
It consists of 6500 lines of C and
assembly implementation and 200K+ lines of $\coq$ proofs.

In order to manage such a massive verification work, 
we  divide the kernel 
into multiple sub-modules, 
and link them together 
to form the correctness theorem of the kernel. 
This work is not only facilitating the abstraction layer approach 
in our framework, but also using our concurrent linking framework 
to show the simulation relation 
between the program on each instance with its concurrent environment 
and the program runs on the full concurrent machine, $\intelmachine$ multicore machine. 

As a part of it, 
we also built a spinlock module to support fine-grained lock services for multiple shared objects in the kernel 
(\ie, page allocation, atomic queue, \etc).
The MCS lock, one of two lock algorithms that we used, verification
is described in detail in this thesis, 
focusing on how we divide the requirement of 
lock verification into multiple layers, proving liveness of the lock, as well as
providing a simple but common interface of the verified lock for other shared resources. 

The MCS algorithm is well known as scalable fair inter-CPU mutex locks.
Although the program is short, the proof is challenging.
First, the implementation of a lock algorithm can not itself use locks, so it has to rely solely on atomic memory instructions and be robust against any possible interleavings between CPUs. This is the most challenging type of concurrency, so-called lock-free programming.
Second, unlike algorithms which only promise mutual exclusion, the MCS algorithm also aims for fairness among CPUs. To check that it got it right, our correctness theorem needs to guarantee not only mutual exclusion (a safety property) but also bounded waiting time (a liveness property).
We show how we resolve those two challenges in this thesis.

Our verification toolkit is inspired by the $\certikos$ project,
but it is not limited to the operating system verification. 
Distributed systems are well-known as the message-passing model of concurrency;
nodes in distributed systems are connected with others via network communication.
They serve millions of users in important applications these days (\ie, banking, communications, and social networking), 
but they are difficult programs to be correctly implemented due to their concurrency as well as failures.
Local nodes may crash at arbitrary moments and communications may possess failures such as packet reordering, loss, and duplication. 
In this sense, distributed systems is a desirable target for verification, and also an attractive target to show the applicability of our framework. 

To build a trustworthy distributed system,
we first introduce WOR abstraction inherent in many distributed systems and present a simple, data-centric WOR API as a first-class programming abstraction. Second, we implement three distributed applications over this API; for each one, our modular design easily allows new configurations with different performance and availability properties, while matching or surpassing the performance of an existing monolithic implementation in a similar configuration. 
Finally, we applied our verification toolkit into distributed systems by adding non-byzantine band asynchronous network model (which allows packet duplication, delay, and loss)  in it.
We built  $\wormspace$; a distributed system API provides the abstraction of the common interfaces that many distributed systems can use.
The system is implemented via a collection of $\paxos$,
and we prove the functional correctness of it as well as the key safety property of the protocol, immutability. 


\section{Toolkit for Leader-based Distributed Protocols and Systems}
\label{chapter:introduction:sec:toolkit-for-leader-based-distributed-protocols-and-systems}


Verification of distributed systems reveals another challenge beyond showing the functional correctness of those programs; the safety proofs of the underlying protocols of them. 
While even verifying a single distributed system is challenging, in practice
distributed applications rely on several distributed systems. An application
might employ different distributed systems for distinct functionalities (\eg,
consensus~\cite{vivaladifference}, distributed transactions~\cite{gray:2006},
and distributed locks~\cite{chubby, zookeeper} as part of a high reliability
distributed database) or it might use systems that achieve the same goal (\eg,
multi-Paxos~\cite{paxosmadesimple, rvrpaxos} vs. Raft~\cite{raft}) in different
parts of the application depending on performance considerations or simple
preference. Therefore, to realize a verified distributed system environment,
methodologies to extend formal reasoning to multiple distributed systems are
necessary.

We find that distributed systems that realize strong semantics are typically
designed under a common pattern: systems exploit a leader node
(or a centralized coordinator) explicitly or implicitly to coordinate
distributed state changes. Indeed, for simplicity of management and understanding, this leader-based scheme is commonly used to implement critical distributed functions. For example, multi-Paxos and Raft elect a leader to replicate states
across multiple nodes, two-phase commit employs a transaction manager to
coordinate transactions over various resource managers, and coordination
services grant a lock to a requester to have mutually exclusive access to a
distributed shared state.
With this observation, our dissertation proposes our idea that can be used in the distributed system verification,
especially leader-based distributed systems.

\section{Contributions by Collaborators}
\label{chapter:introduction:sec:contributions-by-collaborators}

Works on Chapter~\ref{chapter:ccal},~\ref{chapter:mcs-lock},~\ref{chapter:linking}, and \ref{chapter:certikos} are parts of 
the $\certikos$ project, and are joint works with various members in our group. 
The author collaborated with Ronghui Gu on developing concurrent certified abstraction layers, concurrent linking libraries, and the verification on the verified concurrent OS kernel ($\certikos$).  
The author wrote almost all proofs in linking libraries and concurrent linking proofs for $\certikos$ with some help from 
J{\'e}r{\'e}me Koenig.
Among the entire $\certikos$, 
the author developed the whole MCS Lock module together with Vilhelm Sj{\"o}berg,
and also contributed to many other parts. 
The automation engine for proving the C source program are developed solely by Xiongnan (Newman) Wu, but details of those automation engines are out of scope in this thesis. His thesis illustrates in-depth explanations about the automation engine. 
For the case study of the distributed system verification in Chapter~\ref{chapter:wormspace} ($\wormspace$), Ji-Yong Shin and Wolf Honore worked together to build and verify the system, and the author works as a leading role in designing network models, layers for the target system, 
as well as the safety proof of the system. 
The author also worked with  Ji-Yong Shin and Wolf Honore to provide a verification toolkit for leader-based distributed systems in Chapter~\ref{chapter:witness-passing}.

\section{Contents of the Chapters}
\label{chapter:introduction:sec:contents-of-the-chapters}

The rest of this dissertation is organized as follows. Chapter~\ref{chapter:ccal} focuses 
on the framework to build local layer interfaces of concurrent programs, an abridged version for the related parts of our work in~\cite{concurrency}.
Chapter~\ref{chapter:mcs-lock} is an abridged version of our work from~\cite{mcslock},
a case study that uses the framework in Chapter~\ref{chapter:ccal}. 
Chapter~\ref{chapter:linking} provides 
the details for our concurrent linking,  multicore linking
and multithreaded linking frameworks, 
of which the high-level idea is a part of our work in~\cite{concurrency}.
This chapter, however, differs from our previous publications by providing
in-depth explanations for the parts related to concurrent linking;
thus
addresses how to use our linking framework by presenting formal rules, proofs,  and the true capability of it which 
are addressed in~\cite{concurrency}.
Chapter~\ref{chapter:certikos} shows our work on $\certikos$
closely related to our work in~\cite{certikos:osdi16}. 
It shows an interesting case study that uses all ingredients of our concurrent verification framework as well as 
show the full power of it.
The verification work on distributed systems, $\wormspace$,
is discussed in Chapter~\ref{chapter:wormspace}.
It is an abridged version of our another work~\cite{wormspace}
which shows the applicability of our framework
to distributed systems.
Chapter~\ref{chapter:witness-passing} gives the idea how we provide 
generic toolkit to verify multiple leader-based distributed systems,
which is inspired by the verification work on $\wormspace$.
Chapter~\ref{chapter:related} shows in-depth discussion of related work,
 and Chapter~\ref{chapter:conclusion} mentions limitations and future directions as well as  summarizes this thesis.







% 
%
%\begin{figure}
%\caption{Requirements in Concurrent Program Verification}
%\label{fig:concurrent-verification-challenge}
%\end{figure}
%
%However, even with the importance of concurrent program verification and 
%a large body of recent work on shared-memory concurrency verification ~\jieung{cite},
%there are few certified programming tools for a large scale software due to the requirement of multiple challenges described in Fig.~\ref{fig:concurrent-verification-challenge}.
%
%\jieung{ need to site ESOP papers too}
%
%They first have to 
%provide a way to build the software in multiple layers
%that enable us to build a large scale program as a modular way. 
%For example, 
%operating systems can be divided into multiple parts, 
%memory management, process management, and so on.
%
%They also have to provide \jieung{need different word} a methodology to 
%represent the behavior of other components in the concurrent environment. 
%For the program running on multicore environment, 
%the single instance of the program, which is a program runs on top of 
%a single CPU, has to correctly capture the 
%environmental behavior (the behavior of programs on other CPUs). 
%
%In addition to that, 
%providing the end-to-end theorem also requires us 
%to link the multiple proof instances to 
%form a single proof that is based on
%the concurrent environment itself which does not have 
%any environmental contexts at all. 
%In the example of the operating system on multicore environment,
%the end-to-end theorem 
%has to prove that 
%the program running on the single CPU is correctly refined by 
%the whole thread programs running on the multicore machine. 
%
%Previous works, CertiKOS~\jieung{need cite} and Certified Concurrent Abstraction Layer~\jieung{need cite}, 
%tackles all the above examples.  
%CCAL is a tool to build a certified concurrent layers, which provides 
%a way to build concurrent abstraction layers, 
%
%
%
%However, the paper does not handle how the linking process works with the concrete machine models. 
%It briefly mentions the high level idea of linking and the memory extension for linking framework. 
%
%Therefore, this paper aims the gap between the high level perspective of CCAL and the 
%low level details of concurrent proof linking. 
%This low level details contains two parts. 
%First, it requires us to define and build multiple intermediate languages to connect
%the x86 multicoro machine model with the LAsm, which is the machine model for one single CPU. 
%In addition to that, 
%the framework also needs to show the refinement 
%between layers on those intermediate machine models to formally link
%all those proofs together. 
%CCAL also briefly provide the idea of how they implement the practical machine models that can be used with CompCertX.
%However, only providing few details does not provide 
%the  useful information to show how it works with the actual running large scale software.
%Thus, our paper tackles the issues that CCAL overlooked in the paper 
%by providing the formal rules and proofs.
%The key contribution of this paper is as follows: 
%
%\begin{itemize}
%\item We provide the detailed intermediate language semantics for multicore machine model based on CCAL, 
%and instantiate all those intermediate language semantics and refinement proofs 
%to link them with CompCertX with environmental context 
%\item We provide the intermediate machine models to build single threaded machine model from a single CPU machine model. 
%Based on the machine models, we provide the linking theorem in between 
%two abstraction layers, which contains different semantics for software schedulers. 
%\end{itemize}
%
%The structure of remaining paper is as follows:
%Section~\ref{sec:overview} shows a brief high level idea of CCAL as well as how our linking works. Section~\ref{sec:multicore} shows the details of multicore linking,
%and Sect.~\ref{sec:multithreaded} shows the implementation of our intermediate machine models for our multithreaded environment.
%Section~\ref{sec:multithreaded-linking-impl} shows how are framework 
%can be fitted into the actual concurrent kernel implementations.
%Evaluations about our implementation can be found in Sect.~\ref{sec:evaluation} 
%and the related work and conclusion is in Sect.~\ref{sec:related}.
%
%
%
%\ignore{
%Despite the importance of concurrent layers and a large body of recent work on 
%shared-memory concurrency verification, 
%
%
%there are no certified programming tools that can specify, compose, and compile concurrent layers to form a whole system [6]. Formal reasoning across multiple concurrent layers is challenging because different layers often exhibit different interleaving semantics and have a different set of observable events. For example, the spinlock module in Fig. 1 assumes a multicore model with an overlapped execution of instruction streams from different CPUs. This model differs significantly from the multithreading model for building high-level synchro- nization libraries: each thread will block instead of spinning if a queuing lock or a CV event is not available; and it must count on other threads to wake it up to ensure liveness.
%
%
%
%
%many of these abstraction layers also become concurrent in nature. Their interfaces not only hide the concrete data representations and algorithmic de- tails, but also create an illusion of atomicity for all of their methods: each method call is viewed as if it completes in a single step, even though its implementation contains com- plex interleavings with operations done by other threads. Herlihy et al. [19, 20] advocated using layers of these atomic objects to construct large-scale concurrent software systems.
%
%
%The importance of software systems' accuracy is growing rapidly these days. 
%In addition to that, 
%the concurrent environment, including multicore and device drivers, are ubiquitous in modern periods. 
%Therefore, 
%the verification methodology for concurrent programs is critical now. 
%
%In this sense, several previous works propose
%proof logics and tools for that purpose \jieung{need cite}.
%
%However, few of them are working on the linking multiple instances of 
%verified concurrent programs with concrete machine models that can be run 
%on the bare machines. 
%
%One tool, Certified Concurrent Abstraction Layers, 
%provides the tool that can be used for building a practical concurrent programs 
%such as a small operating system or distributed system. 
%It also provides the tool to link the 



%
%
%Formal verification is a key to secure and reliable software, and  Operating System (OS) kernels and hypervisors form the backbone of every safety-critical software system in the world. 
%Hence it is highly desirable to formally verify the correctness of these programs.
%
%Recent work on $\selfour$~\cite{klein2009sel4,klein14} has shown that it is feasible to formally prove the functional correctness property of a general-purpose microkernel, but the cost of such verification is still quite prohibitive. 
%It took the $\selfour$\ team more than 11 person years (effort for tool development excluded) to verify 7500 lines of sequential C code, yet the resulting kernel still contains 1200 lines of additional C code and 600 lines of assembly code that are not verified. 
%Worse still, even after all these efforts, the current verified $\selfour$\ kernel cannot be used to reason about user-level programs as it does not verify important features such as virtual-memory page faults and address translation.
%
%There are many reasons that make hard to verify the OS kernels formally.
%First, OS kernels are complex artifacts; they contain many interdependent components that are difficult to untangle.
%Their invariants can involve machine level details (e.g., how the virtual memory hardware works) but can also cut across multiple abstraction boundaries (e.g., different views of an address space under kernel/user or host/guest modes).
%Several researchers~\cite{baumann12,vaynberg12} observed that even writing down a good and easy-to-maintain formal specification alone is already a major roadblock for any such verification effort.
%
%Second, OS kernels are often written in C, which only supports limited forms of abstraction.  Verification of C programs is especially hard if they manipulate low-level data structures (e.g., thread queues, allocation tables).  
%The $\selfour$\ effort used an intermediate executable specification (derived from a Haskell prototype) to hide some messy C specifics, but this alone is not enough for enforcing abstraction among different kernel components; $\selfour$\ had to introduce capabilities which add significant implementation complexities to the kernel.
%
%Third, OS kernels are developed for managing and multiplexing hardware, so it is important to have a machine model that can describe hardware details.
%The C language (especially ANSI C) is too high level for this purpose. For example, while most kernel code can be written in C, many key kernel concepts (e.g., context switches, address translation, page fault handling) can only be given accurate semantics at the assembly level. Consequently, we need a formal assembly model to define many kernel behaviors, but we also want to verify most kernel code at a much higher abstraction level.
%
%Fourth, OS kernel verification would not scale if it does not  support extensibility.
%One advantage of a verified kernel is the existence of formal specifications for all of its components. 
%In theory, this would allow us to add certified kernel plug-ins as long as they do not violate any existing kernel invariants.
%In practice, however, if we are unable to decompose kernel invariants into small independent pieces, even modifying an existing (or adding a new) verified component may force us to rewrite the proofs for the entire kernel.
%
%Hence, OS kernel and hypervisor verification needs a novel compositional approach that can handle all of the above challenges successfully. 
%Previous work~\cite{deepspec} in our group presents a verified OS kernel and hypervisor with solving those problems. 
%However, there are still limitations in two verified kernels~\cite{deepspec, klein2009sel4}.
%For example, both of them only support single processor systems.
%%

%%Figure~\ref{chapter:intro:verification-toolkit-structure} shows the 
%%key idea of our toookit,
%
%All of those building stack is connected by 
%the tranditional simulation technique~\cite{compcert, deepspec}.

%
%
%In this thesis, we present a compositional, and powerful automation engine for effectively verifying complex system software. We believe that the aforementioned challenges are not directly tied to the verification of the functional correctness itself, and we think the automation engine should focus solely on providing very strong automation support for proving the functional correctness of each system component, completely separate from the reasoning of aforementioned challenges. We have developed a strong automation tactical libraries that solely focus on proving functional correctness, and provide a separate logical framework to handle memory isolation, i

%
% by following the abstraction layer approach.
%Abstraction layers are common in modern system built 
%by providing 
%the interface of parts of programs 
%
%
%To provide the 
%framework for building certified concurrent programs, 
%we propose 
%a verification toolkit, a certified concurrent abstraction layer. 
%
%
%
%%
%%
%%Modularization and composition is prevalent in modern software systems. 
%%A plethora of modern systems are divided 
%into the modules that are
%
%When it comes with the 
% 
% 
% Abstraction layers are widely used in modern computer systems to help reduce the complex interdependencies among components at different levels of abstraction.
%One famous study presenting verified micro-kernel~\cite{klein2009sel4}, for example
%took 10 person for the its verification. 
%%
%%This compositional support is required 
%%for the verification is not only resolve the issues of concurrency 
%but also 
%related to support scalable verification methodologies 
%by dividing a large-scale into multiple sub-modules.
%The verification is considered as a costly tasks 
%even without concurrency.
%Providing the similar manner is desirable for the verification 
% reduce the cost of the work. 
% 
%
%To reduce the cost of this complexity, 
%%modularization is an another requirement for the verificaiton. 
%%
%An abstraction layer defines an interface that hides the im- plementation details of its underlying software or hardware components. Client programs built on top of each layer are understood solely based on the interface, independent of the layer implementation.
%
%
%%%%% several previous works and machine checkable proof  
%
%
%
%
%Some, CSpec and CCAL, also provides a verified layered structure to build modular verification, an another important 
%feature to build a large scaled program verification in a modular ways.


%%%% several previous works and machine checkable proof  
%
%%%%% CCAL - what is missing 
%Few of them, 
%They, however, overlook the difficulty in one another piece of machine checked concurrent program verification, 
%provide the evidence of concurrent linking.
%The concurrent linking shows 
%the precise evidence of the composition that the underlying logics provide. 
%In this sense, 
%it requires the definition of 
%concurrent machine model that can run multiple instances of concurrent program together (\textit{e.g.,} multicore and multithreaded machine) 
%as well as 
%the linking proofs between the program runs on top of concurrent machine and the composition of multiple single instances together. 
%It also requires the proof that 
%%shows the single instance of the concurrent program correctly reflects
%%the program run on the multicore machine model. 
%%
%%They are necessary to show the full correctness of the program, 
%but providing concurrent machine model is bothersome, especially when the model is close to that of bare machines, 
%and the proof between it wiith the machine that runs the single instance is also a subtle work.
%To handle those challenges,
%CCAL slightly mentioned these issues,
%but it only carries out
%a key idea of
%linking without exposing underlying multiple obstacles.  
%In this sense, 
%providing the information about which steps are necessary for concurrent linking and what kind of things that 
%the users have to fill out is desired.
%In this sense, the idea in the paper is far from 
%the enough idea to achieve how 
%concurrent linking can be worked in such 
%a large scaled concurrent program. 
%

