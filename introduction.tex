
TO BE ADDED

\ignore{
The goal of this dissertation is to build formal methods for concurrent program verification and apply the methods to multiple concurrent programs,
in such a way that we can guarantee to users that these systems are reliable and trustworthy not only for the functional correctness but also for 
other high-level progress properties or the protocol correctness of them. 

\section{Challenges in Concurrent Program Verification}
\label{chapter:introduction:sec:challenges-in-concurrent-program-verification}


Formal verification is a key to secure and reliable software, and  Operating System (OS) kernels and hypervisors form the backbone of every safety-critical software system in the world. 
Hence it is highly desirable to formally verify the correctness of these programs.

Recent work on $\selfour$~\cite{klein2009sel4,klein14} has shown that it is feasible to formally prove the functional correctness property of a general-purpose microkernel, but the cost of such verification is still quite prohibitive. 
It took the $\selfour$\ team more than 11 person years (effort for tool development excluded) to verify 7500 lines of sequential C code, yet the resulting kernel still contains 1200 lines of additional C code and 600 lines of assembly code that are not verified. 
Worse still, even after all these efforts, the current verified $\selfour$\ kernel cannot be used to reason about user-level programs as it does not verify important features such as virtual-memory page faults and address translation.

There are many reasons that make hard to verify the OS kernels formally.
First, OS kernels are complex artifacts; they contain many interdependent components that are difficult to untangle.
Their invariants can involve machine level details (e.g., how the virtual memory hardware works) but can also cut across multiple abstraction boundaries (e.g., different views of an address space under kernel/user or host/guest modes).
Several researchers~\cite{baumann12,vaynberg12} observed that even writing down a good and easy-to-maintain formal specification alone is already a major roadblock for any such verification effort.

Second, OS kernels are often written in C, which only supports limited forms of abstraction.  Verification of C programs is especially hard if they manipulate low-level data structures (e.g., thread queues, allocation tables).  
The $\selfour$\ effort used an intermediate executable specification (derived from a Haskell prototype) to hide some messy C specifics, but this alone is not enough for enforcing abstraction among different kernel components; $\selfour$\ had to introduce capabilities which add significant implementation complexities to the kernel.

Third, OS kernels are developed for managing and multiplexing hardware, so it is important to have a machine model that can describe hardware details.
The C language (especially ANSI C) is too high level for this purpose. For example, while most kernel code can be written in C, many key kernel concepts (e.g., context switches, address translation, page fault handling) can only be given accurate semantics at the assembly level. Consequently, we need a formal assembly model to define many kernel behaviors, but we also want to verify most kernel code at a much higher abstraction level.

Fourth, OS kernel verification would not scale if it does not  support extensibility.
One advantage of a verified kernel is the existence of formal specifications for all of its components. 
In theory, this would allow us to add certified kernel plug-ins as long as they do not violate any existing kernel invariants.
In practice, however, if we are unable to decompose kernel invariants into small independent pieces, even modifying an existing (or adding a new) verified component may force us to rewrite the proofs for the entire kernel.

Hence, OS kernel and hypervisor verification needs a novel compositional approach that can handle all of the above challenges successfully. 
Previous work~\cite{dscal15} in our group presents a verified OS kernel and hypervisor with solving those problems. 
However, there are still limitations in two verified kernels~\cite{dscal15, klein2009sel4}.
For example, both of them only support single processor systems.
%



\begin{itemize}
\item It provides a concrete example of CertiKOS-style verification; in particular we can see how to customize the machine model (Sec.~\ref{subsec:lowestmachinemodel}) and how to split the verification effort into CPU-local reasoning (Sec.~\ref{subsec:eventlogandoracle} and \ref{subsec:abstractoperationlayer}).
  
\item We show a way to prove that an atomic specification refines a concurrent implementation, while still using downward rather than upward simulations. The trick is to provide a \emph{function} from low-level to high-level logs of events. (Sec.~\ref{sec:liveness-atomicity}--\ref{sec:downwards-to-upwards}.)

\item We propose a new way to specify the desired---atomic---behavior of the lock/unlock methods. To ensure liveness, the specification of the lock method itself includes a promise to later call unlock; we do this using a bounding counter. (Sec.~\ref{sec:liveness-atomicity}.)

\item And of course, we provide the first implementation of the MCS algorithm that has been both rigorously verified (with a mechanized proof) and at the same time realized (as part of a running kernel).
\end{itemize}




\section{Verification Toolkit for Concurrent Programs}
\label{chapter:introduction:sec:verification-toolkit-for-concurrent-programs}

\begin{figure}
\includegraphics[width=\textwidth]{figs/intro}
\caption{Verification Toolkit Structure}
\label{chapter:intro:verification-toolkit-structure} 
\end{figure}

Figure~\ref{chapter:intro:verification-toolkit-structure}  shows
the layered approach to verify concurrent  software.



\section{Concurrent Program Verification Examples}
\label{chapter:introduction:sec:concurrent-program-verification-examples}


%%%% From MCSLock
The MCS algorithm for scalable fair inter-CPU mutex locks makes for an interesting case study in program verification.
Although the program is short, the proof is challenging.
First, the implementation of a lock algorithm can not itself use locks, so it has to rely solely on atomic memory instructions and be robust against any possible interleavings between CPUs. This is the most challenging type of concurrency, so-called lock-free programming.
Second, unlike algorithms which only promise mutual exclusion, the MCS algorithm also aims for fairness among CPUs. To check that it got it right, our correctness theorem needs to guarantee not only mutual exclusion (a safety property) but also bounded waiting time (a liveness property).

Previous work~\cite{liang:lili,ogata:mcs-lock} has studied the
correctness of the algorithm itself, but those verification efforts
did not produce executable code, and did not explore how to integrate
the proof of the algorithm into a larger system. We have created a
fully verified implementation and added it as part of the CertiKOS
kernel~\cite{certikos16}, which consists of 6500 lines of C and
assembly implementation and 135K lines of Coq proofs.

In order to manage such a large verification effort, the CertiKOS team developed a methodology known as \emph{certified (concurrent) abstraction layers}, as well as a set of libraries and theorems to support it. Previous papers~\cite{dscal15,ccal16}
described this framework, but many readers found them  dense and hard to follow because they immediately present the formalism at its most abstract and general.
This paper aims to be a complement: by zooming in on the implementation of one small part of the kernel (the MCS Lock module), we illustrate  what it is like to \emph{use} the framework, how to write specifications in the ``layers'' style, and what the corresponding proof obligations are. We hope this paper will be an easier entry point for understanding our verification framework.

As we will see, CertiKOS-style verification has several distinctive features which stem from the requirements of a large kernel. First, it is suitable for {\bf dealing with low-level code}. To make the proofs tractable we mainly work at the C level (relying on the CompCert verified compiler~\cite{Leroy-Compcert-CACM}), but sometimes we need to go lower. For example the MCS algorithm needs to use atomic CPU instructions ({\em fetch-and-store} and {\em compare-and-swap}), so we need a way to  mix C and assembly code, while stating precisely what semantics we assume that the assembly code has. At the same time, C itself is too low-level to conveniently reason about, so we need {\bf data abstraction} to hide the details about representation in memory.

Second, in order to handle large developments we need {\bf separation of responsibilities}. In a small proof of an algorithm in isolation, you can state the specification as a single pre- and post-condition which specifies the shape and ownership of the data structure, the invariants (e.g. mutual exclusion), the liveness conditions, and even the behavior of the lock's client code (the critical section code). But such a proof is not modular and not re-usable. In our development, these are done as separate refinement steps, in separate modules with explicit interfaces, and can even be the responsibility of different software developers. 

Finally, the layers approach is {\bf general purpose}, in the sense
that the same semantic framework can be used for proving all kinds of
properties. The model of program execution exposed to the programmer
is simple, mostly the same as for sequential code and with a notion of logs of events to model concurrency.
Unlike working in a special-purpose program logic, we 
did not have to add any features to show a liveness property, because we can directly reason in Coq about \textbf{how long} an execution will take. 

In the remaining parts of the paper, we first explain the C code that we will be verifying (Sec.~\ref{sec:overview}).
Then in the bulk of the paper, we explain our proof strategy by going through each abstraction layer in turn, concluding with the safety and starvation freedom properties (Sec.~\ref{sec:verification}). Finally we explain how our proofs fit as a part of the larger CertiKOS development (Sec.~\ref{sec:evaluation}) and discuss related and future work (Sec.~\ref{sec:related}).



\section{Toolkit for Leader-based Distributed Protocols and Systems}
\label{chapter:introduction:sec:toolkit-for-leader-based-distributed-protocols-and-systems}

\section{Introduction}
\label{sec:intro}


Distributed systems are challenging to formally model, reason about, and verify
due to their inherent concurrency and weak failure assumptions. Distributed
nodes run concurrently over an asynchronous network and both the node and the
network link can fail at any moment. To clear these hurdles a distributed
protocol must have sophisticated error handling and typically relies on implicit
global invariants, which complicates formal reasoning about the system.


While even verifying a single distributed system is challenging, in practice
distributed applications rely on several distributed systems. An application
might employ different distributed systems for distinct functionalities (e.g.
consensus~\cite{vivaladifference}, distributed transactions~\cite{gray:2006},
and distributed locks~\cite{chubby, zookeeper} as part of a high reliability
distributed database) or it might use systems that achieve the same goal (e.g.
multi-Paxos~\cite{paxosmadesimple, rvrpaxos} vs. Raft~\cite{raft}) in different
parts of the application depending on performance considerations or simple
preference. Therefore, to realize a verified distributed system environment,
methodologies to extend formal reasoning to multiple distributed systems are
necessary.


We find that distributed systems that realize strong semantics are typically
designed under a common pattern: systems exploit a leader node
(or a centralized coordinator) explicitly or implicitly to coordinate
distributed state changes. Indeed, for simplicity of management and understanding,
this leader-based scheme is commonly used to implement critical distributed
functions. For example, multi-Paxos and Raft elect a leader to replicate states
across multiple nodes, two-phase commit employs a transaction manager to
coordinate transactions over multiple resource managers, and coordination
services grant a lock to a requester to have mutually exclusive access to a
distributed shared state.

While the leader-based scheme has a huge presence in the design of distributed systems,
little attention has been paid to formally modeling and studying the common properties
of leader-based distributed systems as a whole. Previous work mostly focused
on verifying individual leader-based distributed systems~\cite{ironfleet, cppraft}
or on general approaches to verify arbitrary distributed systems by relaxing network
models, finding better automation schemes, and isolating and modularizing the
proof structure~\cite{verdi, disel, modular}. We argue that formally
modeling and studying the class of leader-based distributed systems can yield greater
insight into and expedite verification of many systems in that category.


Therefore, we propose \sysname{}, a verification framework for
leader-based distributed systems that promotes the understanding of
a variety of leader-based distributed systems and facilitates the verification
of each system. \sysname{} demonstrates how seemingly very different distributed systems,
such as multi-Paxos, Raft, and distributed locks, can be modeled and verified under
a generic specification as long as they follow the leader-based design.
\sysname{} includes a formal model of leader-based distributed systems and
proofs of generic properties of the model.
It also acts as a proof template that can be instantiated with a particular leader-based
system to show that the general properties hold for it.



We identify a few common characteristics of leader-based distributed systems:
first, they use a logical clock under different names such as round number,
term, timestamp, or epoch, to order operations and to tag the leader's
leadership period;
and second, they take strongly consistent steps in the sense that a
sequence of successful operations by the leader takes effect and is made visible
system-wide in the same sequential order (a linearizable order).
We propose a generic specification that models all leader-based systems using a
term number $\termnum$, template functions $\tplfunction$, and
a version number $\seqnum$. $\termnum$ represents the term in which a leader's leadership is valid,
$\tplfunction$ describes common behaviors of leader-based distributed systems,
and $\seqnum$ is tagged to the system state to order successful calls to $\tplfunction$.


\sysname{} models leader-based systems using two template functions:
1) $\tplldrfunction$, which elects a new leader of the system and
2) $\tplopfunction$, which the elected leader issues over the entire system
to mutate the state. These functions work as a high-level specification or a
template to elect a leader and execute operations over the entire system.
$\tplldrfunction$ and $\tplopfunction$ take the term number $\termnum$ as an identifier
and corresponding state update functions $\gldrfunction$ or
$\gopfunction$ that specify how a system modeled under \sysname{}
actually elects a leader or reaches a new state, respectively (Figure~\ref{fig:process-flow}).
$\tplfunction$ is designed to be generic enough to host most
leader-based distributed system and $\tplfunction$ and $\protocolfunction$
constitute the full specification of a leader-based distributed system.


By making a few assumptions  about $\protocolfunction$
such as monotonic increasing of $\seqnum$ in the distributed object,
the immutability of previous committed values, and atomicity of the resulting
state, \sysname{} provides proofs of few common properties of leader-based distributed systems:
linearizability of state updates and the soundness (uniqueness at term $\termnum$)
of the leader.
Therefore \sysname{} provides a reusable proof template in the sense that these properties
are given ``for free'' once $\protocolfunction$ has been shown to satisfy the assumptions.
In addition to specifying the system behavior,
the state update function $\protocolfunction$ is responsible for exposing necessary
states and information, which we call the witness, to the template for the proof.

A witness is an abstract data structure that simplifies reasoning about and
verifying properties of distributed systems. Although we make use of witnesses
in \sysname{}, they are applicable in more general systems as well. A witness is
a logical component of messages sent between distributed nodes that share what
each node has seen so far. The contents of this data structure are
protocol-specific and could be the sending node's own state or an observed state
of another node. As this information is passed around and accumulates, it can
act as evidence to demonstrate how each node reached its current state and to
justify a node's next decision with respect to the protocol. The behavior of a
node can then easily be verified in relation to the entire distributed system.

Another advantage of witnesses is that they are composable. Witness data
structures that are used to verify different components of the system can be
combined to set the ground for verifying the entire system behavior or the
interaction between system components. For example, $\tplldrfunction$ uses every
node's vote history $\ldrwitness$ as a witness to elect a sound leader and to
justify that leader's use of $\tplopfunction$. Then, the composition of witnesses
$\opwitness$, which is created during the execution of $\tplopfunction$, and
$\ldrwitness$ becomes the source of what function $\protocolfunction$ passes to
the proof template to prove the linearizability of the entire system.


Proving the correctness of the state update function $\protocolfunction$ is equivalent to
verifying a distributed system while leaving the verification for linearizability
and soundness of the leader. However, modeling and verifying different systems
under the same template allows a deeper understanding of subtle differences among systems.
A comparison of commonalities and differences in state update functions
and proofs yields such insight which we outline in Section~\ref{sec:examples}.



\section{Contents of the Chapters}
\label{chapter:introduction:sec:contents-of-the-chapters}




%We revisit several points that have been mentioned in previous publications:
%
%\begin{itemize}
%\item We show how to customize the machine model by adding a trusted specification of particular instructions that we need. (Sec.~\ref{subsec:lowestmachinemodel}.)
%
%\item We locally verify the execution of a single CPU, and treat the rest of the system as an opaque \emph{concurrent context}. (Sec.~\ref{subsec:abstractoperationlayer}.)
%
%\item We illustrate how to abstract away from a C implementation, by refining it into a functional specification which can be conveniently reasoned about. (Sec.~\ref{subsec:atomicoperation}.)
%
%\item Similarly, we show how the same type of refinement can be used to gradually add ghost state to a specification while hiding un-needed details. (Sec.~\ref{sec:representation-ghost}.)
%
}